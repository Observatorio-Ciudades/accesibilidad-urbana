{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c12bb55-64e2-4367-9490-d5ef96f093b8",
   "metadata": {},
   "source": [
    "# __Networks join__ (Boeing+Tessellations networks) Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca5c9b-a3ce-4059-9579-b8305cbc51db",
   "metadata": {},
   "source": [
    "This notebook combines the final process of Notebook 08 and Notebook 09.\n",
    "\n",
    "The code __merges two different street networks into one.__ \n",
    "* Boeing is considered network 01, the base network, only the necessary is modified. \n",
    "* Tessellations is considered the network 02, the complementary network.\n",
    "* Only parts of the complementary network that are not in a zone already covered by the base network are added to the base network.\n",
    "\n",
    "__IMPORTANT: Which one is network 01 and which one is network 02 has an effect on various steps of the process, from deciding what to join to how the final cleaning is performed.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aee1f5-bbea-49ce-8596-b4220df4e324",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a54aa77-acbb-4e76-b26c-154d762cdc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "accesibilidad_urbana = \"../../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da95a1b-9cc4-4ef2-a436-4cd7c85fee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To create Point from coordinates\n",
    "from shapely import Point\n",
    "# For calculate distance between points\n",
    "import math\n",
    "# To know if it is a LineString or a MultiLineString, and create them\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "# To split a line using a point in that line\n",
    "from shapely.ops import split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(accesibilidad_urbana))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    import aup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc0ec2-de9b-4b4b-a118-78cd75a96984",
   "metadata": {},
   "source": [
    "## Notebook config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe6f5b0-c98a-4e32-8d5e-e6892c74acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/external/volvo/input_boeing_network/medellin_nodes.shp\n",
      "../../../data/external/volvo/input_boeing_network/medellin_edges.shp\n",
      "../../../data/external/volvo/output_tessellations_network/medellin_tessellations_nodes_f.gpkg\n",
      "../../../data/external/volvo/output_tessellations_network/medellin_tessellations_edges_f.gpkg\n"
     ]
    }
   ],
   "source": [
    "# ----- ----- ----- Input ----- ----- ----- \n",
    "# Boeing input network\n",
    "# MORAVIA\n",
    "#boeing_nodes_dir = accesibilidad_urbana+ \"data/external/volvo/input_boeing_network/moravia_LH_boeing_nodes.shp\" #From SharePoint\n",
    "#boeing_edges_dir = accesibilidad_urbana+ \"data/external/volvo/input_boeing_network/moravia_LH_boeing_edges.shp\" #From SharePoint\n",
    "# MEDELLÍN\n",
    "boeing_nodes_dir = accesibilidad_urbana+ \"data/external/volvo/input_boeing_network/medellin_nodes.shp\" #From SharePoint\n",
    "boeing_edges_dir = accesibilidad_urbana+ \"data/external/volvo/input_boeing_network/medellin_edges.shp\" #From SharePoint\n",
    "\n",
    "# Tessellations input network\n",
    "# MORAVIA\n",
    "#tess_nodes_dir = accesibilidad_urbana+ \"data/external/volvo/output_tessellations_network/moravia_LH_tessellations_nodes_f.gpkg\" #From ntbk 06.\n",
    "#tess_edges_dir = accesibilidad_urbana+ \"data/external/volvo/output_tessellations_network/moravia_LH_tessellations_edges_f.gpkg\" #From ntbk 06.\n",
    "# MEDELLÍN\n",
    "tess_nodes_dir = accesibilidad_urbana+ \"data/external/volvo/output_tessellations_network/medellin_tessellations_nodes_f.gpkg\" #From ntbk 06.\n",
    "tess_edges_dir = accesibilidad_urbana+ \"data/external/volvo/output_tessellations_network/medellin_tessellations_edges_f.gpkg\" #From ntbk 06.\n",
    "\n",
    "# ----- ----- ----- Projection to be used when needed ----- ----- ----- \n",
    "projected_crs = \"EPSG:32618\"\n",
    "\n",
    "# ----- ----- ----- Output ----- ----- ----- \n",
    "# Save plots in output > figures > volvo > networks_join\n",
    "save_plots = False\n",
    "savefig_dir = accesibilidad_urbana+\"output/figures/volvo/networks_join/final_process/\"\n",
    "\n",
    "# Save output locally?\n",
    "# MORAVIA\n",
    "#output_dir = accesibilidad_urbana + f\"data/external/volvo/output_networks_join/final_process/\"\n",
    "# MEDELLÍN\n",
    "output_dir = accesibilidad_urbana + f\"data/external/volvo/output_networks_join/medellin_final_process/\"\n",
    "\n",
    "# PART 01 STEP 01 - Saves pre-formated Boeing nodes and edges [Base network], and tessellation nodes and edges [Complementary network]\n",
    "# Make sure folder 'part01_step01_preprocess' exists inside output_dir\n",
    "localsave_01_01 = True\n",
    "# PART 01 STEP 02 - Saves the uncovered parts of the complementary network (nodes and edges) and the contact nodes that will be used to connect both networks.\n",
    "# Make sure folder 'part01_step02_identifyuncovered' exists inside output_dir\n",
    "localsave_01_02 = True\n",
    "# PART 02 STEP 01 - Saves both networks (Base, complementary) nodes and edges after being intersected by themselves. Saves the intersection nodes.\n",
    "# Make sure folder 'part02_step01_ntwsintersection' exists inside output_dir\n",
    "localsave_02_01 = True\n",
    "# PART 02 STEP 03 - Saves both networks joined (concatenated_nodes, concatenated_edges)\n",
    "# Make sure folder 'part02_step03_ntwsconcat' exists inside output_dir\n",
    "localsave_02_03 = True\n",
    "# PART 02 STEP 04 - Saves both networks after being joined (joined_nodes_fix, joined_edges_fix)\n",
    "# Make sure folder 'part02_step04_ntwsconnect' exists inside output_dir\n",
    "localsave_02_04 = True\n",
    "# PART 02 STEP 05 - Saves both networks after being cleaned (joined_nodes_clean, joined_edges_clean)\n",
    "# Make sure folder 'part02_step05_ntwsclean' exists inside output_dir\n",
    "localsave_02_05 = True\n",
    "\n",
    "# Show dirs\n",
    "print(boeing_nodes_dir)\n",
    "print(boeing_edges_dir)\n",
    "print(tess_nodes_dir)\n",
    "print(tess_edges_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b271b44a-f3d4-4f4a-ae0a-8d74d8df0c5a",
   "metadata": {},
   "source": [
    "## __Part 01 - Step 00__ - Load and preprocess networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7457dc-f520-4891-82c1-a90747fb0ef4",
   "metadata": {},
   "source": [
    "This step __loads input networks__ (Boeing nodes and edges, Tessellations nodes and edges) __and transforms their ID data (nodes 'osmid', edges 'u' and 'v') into coordinates__ using function aup.create_network(). Inside that function a modification was made so that a unique key is assigned to each edge, starting from 0 and increasing by one each time an edge with the same 'u' and 'v' is found.\n",
    "\n",
    "The resulting networks id data (nodes 'osmid', edges 'u' and 'v') are then modified again to __ensure that there are no duplicates in those columns__, even after concatenating both nodes gdfs and both edges gdfs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a4265-f351-4cb1-a8ee-140b659703b8",
   "metadata": {},
   "source": [
    "### __Input data__ - Boeing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71cbf5de-1fc9-4158-b09c-001c10431bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'coord_X', 'coord_Y', 'coord_Z', 'Type', 'geometry']\n",
      "EPSG:32618\n",
      "(22634, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287291575</td>\n",
       "      <td>POINT (442270.137 701534.148)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287291580</td>\n",
       "      <td>POINT (441354.098 701330.928)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       osmid                       geometry\n",
       "0  287291575  POINT (442270.137 701534.148)\n",
       "1  287291580  POINT (441354.098 701330.928)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load nodes data\n",
    "boeing_nodes = gpd.read_file(boeing_nodes_dir)\n",
    "\n",
    "# Set CRS\n",
    "if boeing_nodes.crs != projected_crs:\n",
    "    try:\n",
    "        boeing_nodes = boeing_nodes.set_crs(projected_crs)\n",
    "    except:\n",
    "        boeing_nodes = boeing_nodes.to_crs(projected_crs)\n",
    "\n",
    "# Filter and rename data\n",
    "print(list(boeing_nodes.columns))\n",
    "boeing_nodes.reset_index(inplace=True)\n",
    "boeing_nodes = boeing_nodes[['ID','geometry']]\n",
    "boeing_nodes.rename(columns={'ID':'osmid'},inplace=True)\n",
    "\n",
    "# Show\n",
    "print(boeing_nodes.crs)\n",
    "print(boeing_nodes.shape)\n",
    "boeing_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "175d939d-e43b-4b7f-8061-589a8e5ca40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'from', 'to', 'length', 'grade_abs', 'speed', 'time', 'Type', 'geometry']\n",
      "EPSG:32618\n",
      "(33114, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>key</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287291575</td>\n",
       "      <td>4408219229</td>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (442270.137 701534.148, 442258.358 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287291575</td>\n",
       "      <td>4408219206</td>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (442270.137 701534.148, 442241.905 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           u           v  key   \n",
       "0  287291575  4408219229    0  \\\n",
       "1  287291575  4408219206    0   \n",
       "\n",
       "                                            geometry  \n",
       "0  LINESTRING (442270.137 701534.148, 442258.358 ...  \n",
       "1  LINESTRING (442270.137 701534.148, 442241.905 ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load edges data\n",
    "boeing_edges = gpd.read_file(boeing_edges_dir)\n",
    "\n",
    "# Set CRS\n",
    "if boeing_edges.crs != projected_crs:\n",
    "    try:\n",
    "        boeing_edges = boeing_edges.set_crs(projected_crs)\n",
    "    except:\n",
    "        boeing_edges = boeing_edges.to_crs(projected_crs)\n",
    "\n",
    "# Filter and rename data\n",
    "print(list(boeing_edges.columns))\n",
    "boeing_edges.reset_index(inplace=True)\n",
    "boeing_edges['key'] = 0\n",
    "boeing_edges = boeing_edges[['from','to','key','geometry']]\n",
    "boeing_edges.rename(columns={'from':'u','to':'v'},inplace=True)\n",
    "\n",
    "# Show\n",
    "print(boeing_edges.crs)\n",
    "print(boeing_edges.shape)\n",
    "boeing_edges.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a2d620-ff16-40a5-950d-024cc4f29b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-registered edge with u 43630626911275 and v 43621476911059 with key 0.\n",
      "Re-registered edge with u 43630626911275 and v 43621476911059 with key 1.\n",
      "Re-registered edge with u 43513986900735 and v 43517976901128 with key 0.\n",
      "Re-registered edge with u 43513986900735 and v 43517976901128 with key 1.\n",
      "Re-registered edge with u 43830956984954 and v 43830596985405 with key 0.\n",
      "Re-registered edge with u 43830956984954 and v 43830596985405 with key 1.\n",
      "Re-registered edge with u 43767666999063 and v 43764266999065 with key 0.\n",
      "Re-registered edge with u 43767666999063 and v 43764266999065 with key 1.\n",
      "Re-registered edge with u 43760626999061 and v 43757116999061 with key 0.\n",
      "Re-registered edge with u 43760626999061 and v 43757116999061 with key 1.\n",
      "Re-registered edge with u 43999387006161 and v 44017597006631 with key 0.\n",
      "Re-registered edge with u 43999387006161 and v 44017597006631 with key 1.\n",
      "Re-registered edge with u 43701827014368 and v 43700827015253 with key 0.\n",
      "Re-registered edge with u 43701827014368 and v 43700827015253 with key 1.\n",
      "Re-registered edge with u 43226026902233 and v 43219096902541 with key 0.\n",
      "Re-registered edge with u 43226026902233 and v 43219096902541 with key 1.\n",
      "Re-registered edge with u 43673987010277 and v 43673957009795 with key 0.\n",
      "Re-registered edge with u 43673987010277 and v 43673957009795 with key 1.\n",
      "Re-registered edge with u 43832467017177 and v 43834277017828 with key 0.\n",
      "Re-registered edge with u 43832467017177 and v 43834277017828 with key 1.\n",
      "Re-registered edge with u 43836046987731 and v 43833556990810 with key 0.\n",
      "Re-registered edge with u 43836046987731 and v 43833556990810 with key 1.\n",
      "Re-registered edge with u 43289086905654 and v 43284076905528 with key 0.\n",
      "Re-registered edge with u 43289086905654 and v 43284076905528 with key 1.\n",
      "Re-registered edge with u 43523166901645 and v 43527916902131 with key 0.\n",
      "Re-registered edge with u 43523166901645 and v 43527916902131 with key 1.\n",
      "Re-registered edge with u 43021356800094 and v 43019686798301 with key 0.\n",
      "Re-registered edge with u 43021356800094 and v 43019686798301 with key 1.\n",
      "Re-registered edge with u 43049446940715 and v 43024786940583 with key 0.\n",
      "Re-registered edge with u 43049446940715 and v 43024786940583 with key 1.\n",
      "Re-registered edge with u 44040316887710 and v 44033456887836 with key 0.\n",
      "Re-registered edge with u 44040316887710 and v 44033456887836 with key 1.\n",
      "Re-registered edge with u 43535836898564 and v 43531906898065 with key 0.\n",
      "Re-registered edge with u 43535836898564 and v 43531906898065 with key 1.\n",
      "Re-registered edge with u 43555036906041 and v 43555926906811 with key 0.\n",
      "Re-registered edge with u 43555036906041 and v 43555926906811 with key 1.\n",
      "Re-registered edge with u 43576546905622 and v 43577876905241 with key 0.\n",
      "Re-registered edge with u 43576546905622 and v 43577876905241 with key 1.\n",
      "Re-registered edge with u 43777576869105 and v 43791956869335 with key 0.\n",
      "Re-registered edge with u 43777576869105 and v 43791956869335 with key 1.\n",
      "Re-registered edge with u 43779806867396 and v 43795386867637 with key 0.\n",
      "Re-registered edge with u 43779806867396 and v 43795386867637 with key 1.\n",
      "Re-registered edge with u 43693916865009 and v 43698586864834 with key 0.\n",
      "Re-registered edge with u 43693916865009 and v 43698586864834 with key 1.\n",
      "Re-registered edge with u 43817556864402 and v 43816446864000 with key 0.\n",
      "Re-registered edge with u 43817556864402 and v 43816446864000 with key 1.\n",
      "Re-registered edge with u 43682696928344 and v 43687276930334 with key 0.\n",
      "Re-registered edge with u 43682696928344 and v 43687276930334 with key 1.\n",
      "Re-registered edge with u 43302006878685 and v 43305516878701 with key 0.\n",
      "Re-registered edge with u 43302006878685 and v 43305516878701 with key 1.\n",
      "Re-registered edge with u 43302006878685 and v 43305516878701 with key 2.\n",
      "Re-registered edge with u 42887536820893 and v 42896316821103 with key 0.\n",
      "Re-registered edge with u 42887536820893 and v 42896316821103 with key 1.\n",
      "Re-registered edge with u 42909296837437 and v 42908466836794 with key 0.\n",
      "Re-registered edge with u 42909296837437 and v 42908466836794 with key 1.\n",
      "Re-registered edge with u 43204926813638 and v 43206736814393 with key 0.\n",
      "Re-registered edge with u 43204926813638 and v 43206736814393 with key 1.\n",
      "Re-registered edge with u 43898866971517 and v 43909446971161 with key 0.\n",
      "Re-registered edge with u 43898866971517 and v 43909446971161 with key 1.\n",
      "Re-registered edge with u 43443386941209 and v 43445566940766 with key 0.\n",
      "Re-registered edge with u 43443386941209 and v 43445566940766 with key 1.\n",
      "Re-registered edge with u 43422146944226 and v 43425366944177 with key 0.\n",
      "Re-registered edge with u 43422146944226 and v 43425366944177 with key 1.\n",
      "Re-registered edge with u 43571116936475 and v 43573706936746 with key 0.\n",
      "Re-registered edge with u 43571116936475 and v 43573706936746 with key 1.\n",
      "Re-registered edge with u 43554206899600 and v 43553916900237 with key 0.\n",
      "Re-registered edge with u 43554206899600 and v 43553916900237 with key 1.\n",
      "Re-registered edge with u 43554756898396 and v 43554486898991 with key 0.\n",
      "Re-registered edge with u 43554756898396 and v 43554486898991 with key 1.\n",
      "Re-registered edge with u 43210786830921 and v 43208786830123 with key 0.\n",
      "Re-registered edge with u 43210786830921 and v 43208786830123 with key 1.\n",
      "Re-registered edge with u 43400526935178 and v 43405796935132 with key 0.\n",
      "Re-registered edge with u 43400526935178 and v 43405796935132 with key 1.\n",
      "Re-registered edge with u 43804976939016 and v 43798736939144 with key 0.\n",
      "Re-registered edge with u 43804976939016 and v 43798736939144 with key 1.\n",
      "Re-registered edge with u 43585406899156 and v 43585126899775 with key 0.\n",
      "Re-registered edge with u 43585406899156 and v 43585126899775 with key 1.\n",
      "Re-registered edge with u 43167336842772 and v 43164826843972 with key 0.\n",
      "Re-registered edge with u 43167336842772 and v 43164826843972 with key 1.\n",
      "Re-registered edge with u 43043436919039 and v 43040636918760 with key 0.\n",
      "Re-registered edge with u 43043436919039 and v 43040636918760 with key 1.\n",
      "Re-registered edge with u 43902326959476 and v 43911436958926 with key 0.\n",
      "Re-registered edge with u 43902326959476 and v 43911436958926 with key 1.\n",
      "Re-registered edge with u 44042916898460 and v 44040476897823 with key 0.\n",
      "Re-registered edge with u 44042916898460 and v 44040476897823 with key 1.\n",
      "Re-registered edge with u 43183316803747 and v 43177326804499 with key 0.\n",
      "Re-registered edge with u 43183316803747 and v 43177326804499 with key 1.\n",
      "Re-registered edge with u 43915256915499 and v 43920116916214 with key 0.\n",
      "Re-registered edge with u 43915256915499 and v 43920116916214 with key 1.\n",
      "Re-registered edge with u 43844386920246 and v 43839646920112 with key 0.\n",
      "Re-registered edge with u 43844386920246 and v 43839646920112 with key 1.\n",
      "Re-registered edge with u 43612396887066 and v 43612996886852 with key 0.\n",
      "Re-registered edge with u 43612396887066 and v 43612996886852 with key 1.\n",
      "Re-registered edge with u 43079086810405 and v 43083306810434 with key 0.\n",
      "Re-registered edge with u 43079086810405 and v 43083306810434 with key 1.\n",
      "Re-registered edge with u 43841936964131 and v 43846906964526 with key 0.\n",
      "Re-registered edge with u 43841936964131 and v 43846906964526 with key 1.\n",
      "Re-registered edge with u 44020636961102 and v 44022486959530 with key 0.\n",
      "Re-registered edge with u 44020636961102 and v 44022486959530 with key 1.\n",
      "Re-registered edge with u 43544406966425 and v 43543426966219 with key 0.\n",
      "Re-registered edge with u 43544406966425 and v 43543426966219 with key 1.\n",
      "Re-registered edge with u 43753286850153 and v 43748066850085 with key 0.\n",
      "Re-registered edge with u 43753286850153 and v 43748066850085 with key 1.\n",
      "Re-registered edge with u 44091536892860 and v 44085576892139 with key 0.\n",
      "Re-registered edge with u 44091536892860 and v 44085576892139 with key 1.\n",
      "Re-registered edge with u 43334316868102 and v 43332566867476 with key 0.\n",
      "Re-registered edge with u 43334316868102 and v 43332566867476 with key 1.\n",
      "Re-registered edge with u 43199596943139 and v 43163306942323 with key 0.\n",
      "Re-registered edge with u 43199596943139 and v 43163306942323 with key 1.\n",
      "Re-registered edge with u 43210936888513 and v 43204706888791 with key 0.\n",
      "Re-registered edge with u 43210936888513 and v 43204706888791 with key 1.\n",
      "Re-registered edge with u 43152786904232 and v 43164356904363 with key 0.\n",
      "Re-registered edge with u 43152786904232 and v 43164356904363 with key 1.\n",
      "Re-registered edge with u 43607446805986 and v 43602816806273 with key 0.\n",
      "Re-registered edge with u 43607446805986 and v 43602816806273 with key 1.\n",
      "Re-registered edge with u 43979486910927 and v 43978446911271 with key 0.\n",
      "Re-registered edge with u 43979486910927 and v 43978446911271 with key 1.\n",
      "Re-registered edge with u 44034726983092 and v 44033386982841 with key 0.\n",
      "Re-registered edge with u 44034726983092 and v 44033386982841 with key 1.\n",
      "Re-registered edge with u 43738007019785 and v 43734937020866 with key 0.\n",
      "Re-registered edge with u 43738007019785 and v 43734937020866 with key 1.\n",
      "Re-registered edge with u 43818177012271 and v 43816437012323 with key 0.\n",
      "Re-registered edge with u 43818177012271 and v 43816437012323 with key 1.\n",
      "Re-registered edge with u 43919257014918 and v 43923267013541 with key 0.\n",
      "Re-registered edge with u 43919257014918 and v 43923267013541 with key 1.\n",
      "Re-registered edge with u 43569026938844 and v 43569436938740 with key 0.\n",
      "Re-registered edge with u 43569026938844 and v 43569436938740 with key 1.\n",
      "Re-registered edge with u 44028776888559 and v 44033806888328 with key 0.\n",
      "Re-registered edge with u 44028776888559 and v 44033806888328 with key 1.\n",
      "Re-registered edge with u 43536996938438 and v 43535676937897 with key 0.\n",
      "Re-registered edge with u 43536996938438 and v 43535676937897 with key 1.\n",
      "Re-registered edge with u 43489266826160 and v 43484366825710 with key 0.\n",
      "Re-registered edge with u 43489266826160 and v 43484366825710 with key 1.\n",
      "Re-registered edge with u 43504106853703 and v 43497206854003 with key 0.\n",
      "Re-registered edge with u 43504106853703 and v 43497206854003 with key 1.\n",
      "Re-registered edge with u 43694016798546 and v 43667216801337 with key 0.\n",
      "Re-registered edge with u 43694016798546 and v 43667216801337 with key 1.\n",
      "Re-registered edge with u 43756086972991 and v 43746456973452 with key 0.\n",
      "Re-registered edge with u 43756086972991 and v 43746456973452 with key 1.\n",
      "Re-registered edge with u 43149596912144 and v 43155186911902 with key 0.\n",
      "Re-registered edge with u 43149596912144 and v 43155186911902 with key 1.\n",
      "Re-registered edge with u 43425946945014 and v 43425016944411 with key 0.\n",
      "Re-registered edge with u 43425946945014 and v 43425016944411 with key 1.\n",
      "Re-registered edge with u 43441696945322 and v 43440686945019 with key 0.\n",
      "Re-registered edge with u 43441696945322 and v 43440686945019 with key 1.\n",
      "Re-registered edge with u 43411166947325 and v 43413926947255 with key 0.\n",
      "Re-registered edge with u 43411166947325 and v 43413926947255 with key 1.\n",
      "Re-registered edge with u 43477656941652 and v 43474116942320 with key 0.\n",
      "Re-registered edge with u 43477656941652 and v 43474116942320 with key 1.\n",
      "Re-registered edge with u 43464626939985 and v 43461486939972 with key 0.\n",
      "Re-registered edge with u 43464626939985 and v 43461486939972 with key 1.\n",
      "Re-registered edge with u 43804916962772 and v 43810736964032 with key 0.\n",
      "Re-registered edge with u 43804916962772 and v 43810736964032 with key 1.\n",
      "Re-registered edge with u 43569336938168 and v 43571966937920 with key 0.\n",
      "Re-registered edge with u 43569336938168 and v 43571966937920 with key 1.\n",
      "Re-registered edge with u 43524196935242 and v 43529986934581 with key 0.\n",
      "Re-registered edge with u 43524196935242 and v 43529986934581 with key 1.\n",
      "Re-registered edge with u 43505326876959 and v 43510196876812 with key 0.\n",
      "Re-registered edge with u 43505326876959 and v 43510196876812 with key 1.\n",
      "Re-registered edge with u 43497686859859 and v 43502976859647 with key 0.\n",
      "Re-registered edge with u 43497686859859 and v 43502976859647 with key 1.\n",
      "Re-registered edge with u 43868486966107 and v 43874986966129 with key 0.\n",
      "Re-registered edge with u 43868486966107 and v 43874986966129 with key 1.\n",
      "Re-registered edge with u 43898386943202 and v 43893926944018 with key 0.\n",
      "Re-registered edge with u 43898386943202 and v 43893926944018 with key 1.\n",
      "Re-registered edge with u 43299626887853 and v 43299796887802 with key 0.\n",
      "Re-registered edge with u 43299626887853 and v 43299796887802 with key 1.\n",
      "Re-registered edge with u 43524426807107 and v 43523106806807 with key 0.\n",
      "Re-registered edge with u 43524426807107 and v 43523106806807 with key 1.\n",
      "Re-registered edge with u 44306287019437 and v 44367907021568 with key 0.\n",
      "Re-registered edge with u 44306287019437 and v 44367907021568 with key 1.\n",
      "Re-registered edge with u 43105856798454 and v 43109686798014 with key 0.\n",
      "Re-registered edge with u 43105856798454 and v 43109686798014 with key 1.\n",
      "Re-registered edge with u 43854556864942 and v 43853686864532 with key 0.\n",
      "Re-registered edge with u 43854556864942 and v 43853686864532 with key 1.\n",
      "Re-registered edge with u 43916056947234 and v 43916186947910 with key 0.\n",
      "Re-registered edge with u 43916056947234 and v 43916186947910 with key 1.\n",
      "Re-registered edge with u 43939476965111 and v 43941406965990 with key 0.\n",
      "Re-registered edge with u 43939476965111 and v 43941406965990 with key 1.\n",
      "Re-registered edge with u 42756996833330 and v 42743296834639 with key 0.\n",
      "Re-registered edge with u 42756996833330 and v 42743296834639 with key 1.\n",
      "Re-registered edge with u 42669186836773 and v 42660646836180 with key 0.\n",
      "Re-registered edge with u 42669186836773 and v 42660646836180 with key 1.\n",
      "Re-registered edge with u 42757956827405 and v 42761106827416 with key 0.\n",
      "Re-registered edge with u 42757956827405 and v 42761106827416 with key 1.\n",
      "Re-registered edge with u 42741986836103 and v 42741716835874 with key 0.\n",
      "Re-registered edge with u 42741986836103 and v 42741716835874 with key 1.\n",
      "Re-registered edge with u 43679766817388 and v 43682276817374 with key 0.\n",
      "Re-registered edge with u 43679766817388 and v 43682276817374 with key 1.\n",
      "Re-registered edge with u 43050576819247 and v 43050566819508 with key 0.\n",
      "Re-registered edge with u 43050576819247 and v 43050566819508 with key 1.\n",
      "Re-registered edge with u 43691906932393 and v 43693996933321 with key 0.\n",
      "Re-registered edge with u 43691906932393 and v 43693996933321 with key 1.\n",
      "Re-registered edge with u 43407606867109 and v 43410236866559 with key 0.\n",
      "Re-registered edge with u 43407606867109 and v 43410236866559 with key 1.\n",
      "Re-registered edge with u 43255586802732 and v 43257016802866 with key 0.\n",
      "Re-registered edge with u 43255586802732 and v 43257016802866 with key 1.\n",
      "Re-registered edge with u 43227636803112 and v 43228456802907 with key 0.\n",
      "Re-registered edge with u 43227636803112 and v 43228456802907 with key 1.\n",
      "Re-registered edge with u 43887316854071 and v 43886686853518 with key 0.\n",
      "Re-registered edge with u 43887316854071 and v 43886686853518 with key 1.\n",
      "Re-registered edge with u 43093576914344 and v 43093756914751 with key 0.\n",
      "Re-registered edge with u 43093576914344 and v 43093756914751 with key 1.\n",
      "Re-registered edge with u 43096626800001 and v 43096026800079 with key 0.\n",
      "Re-registered edge with u 43096626800001 and v 43096026800079 with key 1.\n",
      "Re-registered edge with u 44419627019609 and v 44421327019150 with key 0.\n",
      "Re-registered edge with u 44419627019609 and v 44421327019150 with key 1.\n",
      "Re-registered edge with u 44419627019609 and v 44421327019150 with key 2.\n",
      "Re-registered edge with u 44419627019609 and v 44421327019150 with key 3.\n",
      "Re-registered edge with u 43602426985636 and v 43604426985456 with key 0.\n",
      "Re-registered edge with u 43602426985636 and v 43604426985456 with key 1.\n",
      "Re-registered edge with u 43651266829457 and v 43650866829482 with key 0.\n",
      "Re-registered edge with u 43651266829457 and v 43650866829482 with key 1.\n",
      "Re-registered edge with u 42889896801279 and v 42887756801008 with key 0.\n",
      "Re-registered edge with u 42889896801279 and v 42887756801008 with key 1.\n",
      "Re-registered edge with u 42903926800991 and v 42903986800726 with key 0.\n",
      "Re-registered edge with u 42903926800991 and v 42903986800726 with key 1.\n",
      "Re-registered edge with u 43814456834422 and v 43816416834460 with key 0.\n",
      "Re-registered edge with u 43814456834422 and v 43816416834460 with key 1.\n",
      "Re-registered edge with u 43715286886779 and v 43719706886745 with key 0.\n",
      "Re-registered edge with u 43715286886779 and v 43719706886745 with key 1.\n",
      "Re-registered edge with u 43921416953590 and v 43916446953742 with key 0.\n",
      "Re-registered edge with u 43921416953590 and v 43916446953742 with key 1.\n"
     ]
    }
   ],
   "source": [
    "# Transform Boeing nodes and edges ID data to coordinates\n",
    "boeing_coord_nodes, boeing_coord_edges = aup.create_network(boeing_nodes,boeing_edges,projected_crs,expand_coords=True)\n",
    "# Set projected crs\n",
    "boeing_coord_nodes = boeing_coord_nodes.to_crs(projected_crs)\n",
    "boeing_coord_edges = boeing_coord_edges.to_crs(projected_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f070ede-e9d0-4c29-8419-771d750c5898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22634, 2)\n",
      "EPSG:32618\n",
      "osmid          int64\n",
      "geometry    geometry\n",
      "dtype: object\n",
      "Duplicated osmids on nodes: 0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44227017015341</td>\n",
       "      <td>POINT (442270.137 701534.148)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44135407013309</td>\n",
       "      <td>POINT (441354.098 701330.928)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            osmid                       geometry\n",
       "0  44227017015341  POINT (442270.137 701534.148)\n",
       "1  44135407013309  POINT (441354.098 701330.928)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_nodes_ids = len(boeing_coord_nodes.loc[boeing_coord_nodes.duplicated(subset=['osmid'])])\n",
    "\n",
    "if duplicated_nodes_ids>0:\n",
    "    print(\"\"\"Function aup.create_network() created two nodes with the same osmid. \n",
    "    This is probably due to two nodes being one meter or less apart from each other.\n",
    "    These nodes are duplicated, and the edges comming out of each node are now assigned to an osmid with two nodes.\n",
    "    Development in aup.create_network() is required.\n",
    "    \"\"\")\n",
    "    intended_crash\n",
    "\n",
    "# Show\n",
    "print(boeing_coord_nodes.shape)\n",
    "print(boeing_coord_nodes.crs)\n",
    "print(boeing_coord_nodes.dtypes)\n",
    "print(f\"Duplicated osmids on nodes: {duplicated_nodes_ids}.\")\n",
    "boeing_coord_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf35564-38c5-433a-98a7-4dfe73190591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_nodes_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9125c7e-93b2-4c8f-9c70-ed0654c2ce86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [osmid, geometry]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boeing_coord_nodes.loc[boeing_coord_nodes.duplicated(subset=['osmid'],keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12d43d0-9967-4084-b91d-ff051bec34f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33114, 5)\n",
      "EPSG:32618\n",
      "u              int64\n",
      "v              int64\n",
      "key            int64\n",
      "geometry    geometry\n",
      "length       float64\n",
      "dtype: object\n",
      "Duplicated ids on edges: 0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>key</th>\n",
       "      <th>geometry</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44227017015341</td>\n",
       "      <td>44218757015227</td>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (442270.137 701534.148, 442258.358 ...</td>\n",
       "      <td>83.859717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44227017015341</td>\n",
       "      <td>44211837014599</td>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (442270.137 701534.148, 442241.905 ...</td>\n",
       "      <td>169.322673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                u               v  key   \n",
       "0  44227017015341  44218757015227    0  \\\n",
       "1  44227017015341  44211837014599    0   \n",
       "\n",
       "                                            geometry      length  \n",
       "0  LINESTRING (442270.137 701534.148, 442258.358 ...   83.859717  \n",
       "1  LINESTRING (442270.137 701534.148, 442241.905 ...  169.322673  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_edges_ids = len(boeing_coord_edges.loc[boeing_coord_edges.duplicated(subset=['u','v','key'],keep=False)])\n",
    "\n",
    "# Show\n",
    "print(boeing_coord_edges.shape)\n",
    "print(boeing_coord_edges.crs)\n",
    "print(boeing_coord_edges.dtypes)\n",
    "print(f\"Duplicated ids on edges: {duplicated_edges_ids}.\")\n",
    "boeing_coord_edges.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5b205-9bb6-4b36-b3f5-58b4e034c711",
   "metadata": {},
   "source": [
    "### __Input data__ - Tessellations network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff24113-3aa1-4d74-b059-93f46761948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['osmid', 'streets_count', 'geometry']\n",
      "EPSG:32618\n",
      "(28832, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POINT (429740.185 670967.387)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (429813.859 670940.080)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   osmid                       geometry\n",
       "0      0  POINT (429740.185 670967.387)\n",
       "1      1  POINT (429813.859 670940.080)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load nodes data\n",
    "tess_nodes = gpd.read_file(tess_nodes_dir)\n",
    "\n",
    "# Set CRS\n",
    "if tess_nodes.crs != projected_crs:\n",
    "    try:\n",
    "        tess_nodes = tess_nodes.set_crs(projected_crs)\n",
    "    except:\n",
    "        tess_nodes = tess_nodes.to_crs(projected_crs)\n",
    "\n",
    "# Filter and rename data\n",
    "print(list(tess_nodes.columns))\n",
    "tess_nodes.reset_index(inplace=True)\n",
    "tess_nodes = tess_nodes[['osmid','geometry']]\n",
    "\n",
    "# Show\n",
    "print(tess_nodes.crs)\n",
    "print(tess_nodes.shape)\n",
    "tess_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e87577-6dc7-4805-9e14-da8b946b9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'v', 'key', 'geometry']\n",
      "EPSG:32618\n",
      "(46873, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>key</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (429740.185 670967.387, 429740.238 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (429740.185 670967.387, 429740.138 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u  v  key                                           geometry\n",
       "0  0  1    0  LINESTRING (429740.185 670967.387, 429740.238 ...\n",
       "1  0  5    0  LINESTRING (429740.185 670967.387, 429740.138 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load edges data\n",
    "tess_edges = gpd.read_file(tess_edges_dir)\n",
    "\n",
    "# Set CRS\n",
    "if tess_edges.crs != projected_crs:\n",
    "    try:\n",
    "        tess_edges = tess_edges.set_crs(projected_crs)\n",
    "    except:\n",
    "        tess_edges = tess_edges.to_crs(projected_crs)\n",
    "\n",
    "# Filter and rename data\n",
    "print(list(tess_edges.columns))\n",
    "tess_edges.reset_index(inplace=True)\n",
    "tess_edges = tess_edges[['u','v','key','geometry']]\n",
    "\n",
    "# Show\n",
    "print(tess_edges.crs)\n",
    "print(tess_edges.shape)\n",
    "tess_edges.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "217caf31-4793-4565-bbea-60fcded07e64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Sub-geometries may have coordinate sequences, but multi-part geometries do not",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transform Tessellations nodes and edges ID data to coordinates\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tess_coord_nodes, tess_coord_edges \u001b[38;5;241m=\u001b[39m \u001b[43maup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtess_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtess_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprojected_crs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Set projected crs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tess_coord_nodes \u001b[38;5;241m=\u001b[39m tess_coord_nodes\u001b[38;5;241m.\u001b[39mto_crs(projected_crs)\n",
      "File \u001b[0;32m~/accesibilidad-urbana/aup/analysis.py:386\u001b[0m, in \u001b[0;36mcreate_network\u001b[0;34m(nodes, edges, projected_crs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m##Extract start and end coordinates for [u,v] columns\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m edges\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m--> 386\u001b[0m \tedges\u001b[38;5;241m.\u001b[39mat[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mlist\u001b[39m(\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mlist\u001b[39m(row\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mcoords)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m    387\u001b[0m \tedges\u001b[38;5;241m.\u001b[39mat[index,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mlist\u001b[39m(row\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mcoords)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mlist\u001b[39m(row\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mcoords)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m#Add key column for compatibility with osmnx\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/gds/lib/python3.9/site-packages/shapely/geometry/base.py:927\u001b[0m, in \u001b[0;36mBaseMultipartGeometry.coords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoords\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    928\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSub-geometries may have coordinate sequences, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut multi-part geometries do not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    930\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Sub-geometries may have coordinate sequences, but multi-part geometries do not"
     ]
    }
   ],
   "source": [
    "# Transform Tessellations nodes and edges ID data to coordinates\n",
    "tess_coord_nodes, tess_coord_edges = aup.create_network(tess_nodes,tess_edges,projected_crs,expand_coords=True)\n",
    "# Set projected crs\n",
    "tess_coord_nodes = tess_coord_nodes.to_crs(projected_crs)\n",
    "tess_coord_edges = tess_coord_edges.to_crs(projected_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad098d-1413-4044-8739-a3afbcc16486",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_nodes_ids = len(tess_coord_nodes.loc[tess_coord_nodes.duplicated(subset=['osmid'],keep=False)])\n",
    "\n",
    "if duplicated_nodes_ids>0:\n",
    "    print(\"\"\"Function aup.create_network() created two nodes with the same osmid. \n",
    "    This is probably due to two nodes being one meter or less apart from each other.\n",
    "    These nodes are duplicated, and the edges comming out of each node are now assigned to an osmid with two nodes.\n",
    "    Development in aup.create_network() is required.\n",
    "    \"\"\")\n",
    "    intended_crash\n",
    "\n",
    "# Show\n",
    "print(tess_coord_nodes.shape)\n",
    "print(tess_coord_nodes.crs)\n",
    "print(tess_coord_nodes.dtypes)\n",
    "print(f\"Duplicated osmids on nodes: {duplicated_nodes_ids}.\")\n",
    "tess_coord_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca600c7-fb5f-4415-9767-de6339520f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_edges_ids = len(boeing_coord_edges.loc[boeing_coord_edges.duplicated(subset=['u','v','key'],keep=False)])\n",
    "\n",
    "# Show\n",
    "print(boeing_coord_edges.shape)\n",
    "print(boeing_coord_edges.crs)\n",
    "print(boeing_coord_edges.dtypes)\n",
    "print(f\"Duplicated ids on edges: {duplicated_edges_ids}.\")\n",
    "boeing_coord_edges.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa09cd0-b91e-40f9-859c-aa0b2806d3f9",
   "metadata": {},
   "source": [
    "### __Input data__ - Network revision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16efdb48-ed35-4e1c-9a20-4a105b268d69",
   "metadata": {},
   "source": [
    "This important step ensures that there are __no repeated osmids and__ that each edge has __unique 'u', 'v' and 'key' data__ on both networks (Not only on each network).\n",
    "\n",
    "Repeated IDs occur when a node from network 'a' is located at one meter or less of a node from network 'b'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e970a01-ec34-45fc-9f4c-0b6f4b8fa8b9",
   "metadata": {},
   "source": [
    "#### __Show problem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143117c-f686-489f-b32b-ca47d27cbf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_id = 436813694931 #From Moravia's Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752e6e7-f1c7-46d3-b898-fbba100c1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_coord_nodes.loc[boeing_coord_nodes.osmid==dup_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7fa5e6-7dfc-4a23-a300-074f36cb660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_coord_edges.loc[(boeing_coord_edges.u==dup_id)|(boeing_coord_edges.v==dup_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009027a-e84f-44b5-bcfa-affd64faebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_coord_nodes.loc[tess_coord_nodes.osmid==dup_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059f912-92f1-47e1-9adb-77f2b04e01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_coord_edges.loc[(tess_coord_edges.u==dup_id)|(tess_coord_edges.v==dup_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eaa73c-82d3-49d7-967e-830fc5bfeb9f",
   "metadata": {},
   "source": [
    "#### __Input data - Network revision -__ Nodes 'osmid' revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9571bc-7d9b-4431-935b-eb01403eead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_osmid(nodes_network_1, nodes_network_2, previously_produced):\n",
    "    \n",
    "    stop = False\n",
    "    produced_osmid = previously_produced\n",
    "    \n",
    "    while stop == False:\n",
    "\n",
    "        # Evaluate if fabricated_osmid exists in any network\n",
    "        if (produced_osmid in list(nodes_network_1.osmid.unique())) or (produced_osmid in list(nodes_network_2.osmid.unique())):\n",
    "            # Try the next one\n",
    "            produced_osmid +=1\n",
    "            \n",
    "        else:\n",
    "            # Reached an unique fabricated_osmid\n",
    "            stop = True\n",
    "            return produced_osmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b00d5-d3cd-4842-9816-ede2a8c4a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_nodes = boeing_coord_nodes.copy()\n",
    "boeing_edges = boeing_coord_edges.copy()\n",
    "tess_nodes = tess_coord_nodes.copy()\n",
    "tess_edges = tess_coord_edges.copy()\n",
    "\n",
    "# Make sure all osmids are integers\n",
    "boeing_nodes['osmid'] = boeing_nodes['osmid'].astype('int')\n",
    "tess_nodes['osmid'] = tess_nodes['osmid'].astype('int')\n",
    "\n",
    "# Current existing osmids\n",
    "boeing_nodes_osmids = list(boeing_nodes.osmid.unique())\n",
    "tess_nodes_osmids = list(tess_nodes.osmid.unique())\n",
    "\n",
    "# Find duplicate cases \n",
    "dup_osmids = []\n",
    "for osmid in tess_nodes_osmids:\n",
    "    if osmid in boeing_nodes_osmids:\n",
    "        dup_osmids.append(osmid)\n",
    "\n",
    "if len(dup_osmids) > 0:\n",
    "\n",
    "    # Used in function produce_osmid():\n",
    "    previously_produced = 0 # Must be located before starting iterating over osmids\n",
    "\n",
    "    # For each duplicated node found, modify the tess_nodes and tess_edges:\n",
    "    # (Could modify either network)\n",
    "    for current_osmid in dup_osmids:\n",
    "\n",
    "        # 1.0 --------------- Change the node's osmid\n",
    "        # Produce a unique osmid (That doesn't exist in either network)\n",
    "        produced_osmid = produce_osmid(tess_nodes, boeing_nodes, previously_produced)\n",
    "        # Replace osmid in current tess_node\n",
    "        osmid_idx = tess_nodes.osmid == current_osmid\n",
    "        tess_nodes.loc[osmid_idx,'osmid'] = produced_osmid\n",
    "        print(f\"Changed current existing osmid {current_osmid} for osmid {produced_osmid}.\")\n",
    "        # Save already produced osmid to avoid trying the same numbers again and again unnecessarily\n",
    "        previously_produced = produced_osmid\n",
    "\n",
    "        # 2.0 --------------- Change the 'u' or 'v' data of the edges that connect to that node\n",
    "        # Load the edges where that node is used\n",
    "        u_change_idx = (tess_edges.u==current_osmid)\n",
    "        tess_edges.loc[u_change_idx,'u'] = produced_osmid\n",
    "        print(f\"Updated 'u' on edges with osmid {produced_osmid}.\")\n",
    "\n",
    "        v_change_idx = (tess_edges.v==current_osmid)\n",
    "        tess_edges.loc[v_change_idx,'v'] = produced_osmid\n",
    "        print(f\"Updated 'v' on edges with osmid {produced_osmid}.\")\n",
    "\n",
    "else:\n",
    "    print(\"Found no duplicate osmid in both nodes gdfs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9606e94e-f6e5-4d5d-984e-f5ddd939b647",
   "metadata": {},
   "source": [
    "#### __Show problem solved__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10a997-0df6-49de-9c66-a8e3b9395c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_nodes.loc[boeing_nodes.osmid==dup_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce613e56-0cc8-466b-bd69-2cb8640ce790",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_edges.loc[(boeing_edges.u==dup_id)|(boeing_edges.v==dup_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7afff3-e3ae-4661-bc67-1558ec018a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_nodes.loc[tess_nodes.osmid==dup_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dcaba-673b-4d09-a463-686a4a4ba6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_edges.loc[(tess_edges.u==dup_id)|(tess_edges.v==dup_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eac123-d7bf-4820-81f5-89f6847abb38",
   "metadata": {},
   "source": [
    "#### __Input data - Final network revision -__ Joining as they are revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4f9c8-e481-4cbe-ac81-c4e0658d3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_nodes = pd.concat([boeing_nodes,tess_nodes])\n",
    "duplicated_nodes_ids = len(tess_coord_nodes.loc[tess_coord_nodes.duplicated(subset=['osmid'],keep=False)])\n",
    "print(duplicated_nodes_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152cabf-5a0c-408d-939a-84035e04a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_edges = pd.concat([boeing_edges,tess_edges])\n",
    "duplicated_edges_ids = len(boeing_coord_edges.loc[boeing_coord_edges.duplicated(subset=['u','v','key'],keep=False)])\n",
    "print(duplicated_edges_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb03b1-6981-4ebb-990d-40e280032912",
   "metadata": {},
   "source": [
    "### __Input data__ - Preprocessed input visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69d822-6ca2-4f6b-bc3e-a1b99eb7c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,20))\n",
    "\n",
    "boeing_nodes.plot(ax=ax,zorder=3,color='yellow',markersize=1)\n",
    "boeing_edges.plot(ax=ax,zorder=2,color='yellow',linewidth=1)\n",
    "tess_nodes.plot(ax=ax,zorder=1,color='firebrick',markersize=1)\n",
    "tess_edges.plot(ax=ax,zorder=0,color='firebrick',linewidth=1)\n",
    "\n",
    "# ---------- Save Plot ----------\n",
    "if save_plots:\n",
    "    plt.savefig(savefig_dir + \"part01_step01_preprocess.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d42c3-7b62-4bb9-88b3-08669135e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if localsave_01_01:\n",
    "    boeing_nodes.to_file(output_dir + \"part01_step01_preprocess/boeing_nodes.gpkg\")\n",
    "    boeing_edges.to_file(output_dir + \"part01_step01_preprocess/boeing_edges.gpkg\")\n",
    "    tess_nodes.to_file(output_dir + \"part01_step01_preprocess/tess_nodes.gpkg\")\n",
    "    tess_edges.to_file(output_dir + \"part01_step01_preprocess/tess_edges.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382d762-028d-4ada-9836-be4c41198d4c",
   "metadata": {},
   "source": [
    "## __Part 01 - Step 01__ - Identify the parts of the Tessellations network that should be added to the Boeing network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec811ced-8d9f-43a0-add6-9eb4e5a7d5da",
   "metadata": {},
   "source": [
    "This step identifies identifies the parts of the Tessellations network that should be added to the boeing network through the following steps:\n",
    "\n",
    "base_network: boeing\n",
    "complementary_network: tessellations\n",
    "\n",
    "1. Extract the midpoint of each complementary edge\n",
    "2. Create a contact-analysis buffer around mid_points\n",
    "3. Find mid_points whose buffer does not intersect with any part of the base network\n",
    "4. Select the complementary_nodes that connect to the uncovered edges found\n",
    "5. Find the nodes that would be used to connect the uncovered part of the complementary network to the base network\n",
    "6. Identify and shorten edges that extend into the base network and would be useful to create further connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353892e-41c6-4d8a-8684-c66b68371bcf",
   "metadata": {},
   "source": [
    "### __Part 01 - Step 01 -__ Functions required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354a40f-7454-4e1d-a0fb-30aa928638fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between two points\n",
    "def distance_between_points(point1, point2):\n",
    "    return round(math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40471baa-499f-46c1-95b8-14d99283f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_clipping(starting_point_gdf, edge_gdf, clipping_point_gdf, projected_crs=\"EPSG:6372\", return_all=False, function_logs=False):\n",
    "    \n",
    "    \"\"\" This function clips an edge by considering a starting point and a clipping point.\n",
    "    \n",
    "\tArgs:\n",
    "\t\tstarting_point_gdf (geopandas.GeoDataFrame): GeoDataFrame containing the starting point of the LineString, helps identify each split part. \n",
    "                                                     Requires column 'geometry' with a Point.\n",
    "        edge_gdf (geopandas.GeoDataFrame): GeoDataFrame containing the edge to be clipped. \n",
    "                                           Requires column 'geometry' with a LineString.\n",
    "        clipping_point_gdf (geopandas.GeoDataFrame): GeoDataFrame containing the clipping point of the LineString.\n",
    "                                                     Requires column 'geometry' with a Point.\n",
    "        projected_crs (str, optional): string containing projected crs to be used depending on area of interest. Defaults to \"EPSG:6372\".\n",
    "        return_all (bool,optional): Boolean that defines whether the clipped edge is returned from starting_point to clipping_point only (One line) (False)\n",
    "                                    or returned from starting_point to clipping_point and then from clipping_point to ending_point (Two lines) (True). \n",
    "                                    Defaults to False.\n",
    "        function_logs (bool,optional): Boolean that (if True) prints logs during the functions execution. Defaults to False.\n",
    "                                                 \n",
    "\tReturns:\n",
    "        split_edge_gdf (geopandas.GeoDataFrame): GeoDataFrame with either one (return_all=False) or two (return_all=True) edges.\n",
    "\t\"\"\"\n",
    "    \n",
    "    # 1.0 --------------- Split the edge using the clipping_point. Creates two separate edges.\n",
    "    # Extract the edge's geometry (LineString)\n",
    "    edge_geom = edge_gdf['geometry'].unique()[0]\n",
    "    # Extract the clipping_point's geometry (Point)\n",
    "    clipping_point_geom = clipping_point_gdf['geometry'][0]\n",
    "    # Project the clipping_point onto the edge (In case it's not drawn exactly in the LineString)\n",
    "    projected_point = edge_geom.interpolate(edge_geom.project(clipping_point_geom))\n",
    "    \n",
    "    # ----- ----- Added code since having trouble clipping with a point ----- -----\n",
    "    # Create a VERY SMALL buffer around the projected_point\n",
    "    projected_point = projected_point.buffer(1e-9)\n",
    "    # ----- ----- Added code since having trouble clipping with a point ----- -----\n",
    "    \n",
    "    # Split the edge where the projected clipping_point is\n",
    "    split_lines = split(edge_geom, projected_point)\n",
    "    # Convert the split lines to a GeoDataFrame\n",
    "    split_gdf = gpd.GeoDataFrame(geometry=list(split_lines.geoms), crs=projected_crs)\n",
    "    \n",
    "    # ----- ----- Added code since having trouble clipping with a point ----- -----\n",
    "    # Drop the small split line located inside the VERY SMALL buffer in order to keep the two split lines outside it.\n",
    "    if len(split_gdf) ==3 :\n",
    "        split_gdf['length'] = split_gdf.length\n",
    "        split_gdf = split_gdf.loc[split_gdf.length != split_gdf.length.min()]\n",
    "    split_gdf.reset_index(inplace=True,drop=True)\n",
    "    # ----- ----- Added code since having trouble clipping with a point ----- -----\n",
    "\n",
    "    # 2.0 --------------- Find which split LineString in split_gdf contains the LineString where the starting_point is located\n",
    "    \n",
    "    # Extract the edge's first and last coordinates\n",
    "    edge_coords = list(edge_gdf['geometry'][0].coords)\n",
    "    first_point_coords = edge_coords[0]\n",
    "    last_point_coords = edge_coords[-1]\n",
    "\n",
    "    if function_logs:\n",
    "        print(f\"edge_clipping(): Extracted first_point_coords: {first_point_coords}.\")\n",
    "        print(f\"edge_clipping(): Extracted last_point_coords: {last_point_coords}.\")\n",
    "    \n",
    "    # Extract the starting_point's coordinates (Function input)\n",
    "    starting_point_coords = starting_point_gdf.loc[0,'geometry'].coords[0]\n",
    "    if function_logs:\n",
    "        print(f\"edge_clipping(): Extracted starting_point_coords: {starting_point_coords}.\")\n",
    "        \n",
    "    # Try identifying which (first or last) is the starting_point by checking equality in coordinates\n",
    "    if starting_point_coords == first_point_coords:\n",
    "        # Starting point is first_point\n",
    "        starting_point_coords = first_point_coords\n",
    "    elif starting_point_coords == last_point_coords:\n",
    "        # Starting point is last_point\n",
    "        starting_point_coords = last_point_coords\n",
    "    # Else, measure distance and assume the starting_point is the closest one.\n",
    "    # (this case applies when starting_point is not drawn exactly in the LineString)\n",
    "    else:\n",
    "        # Distance from starting_point to first point\n",
    "        first_point_distance = distance_between_points(first_point_coords, starting_point_coords)\n",
    "        # Distance from starting_point to last point\n",
    "        last_point_distance = distance_between_points(last_point_coords, starting_point_coords)\n",
    "        # Find which one is the starting_point\n",
    "        if first_point_distance < last_point_distance:\n",
    "            # Starting point is first_point\n",
    "            starting_point_coords = first_point_coords\n",
    "        else:\n",
    "            # Starting point is last_point\n",
    "            starting_point_coords = last_point_coords\n",
    "    \n",
    "    # 3.0 --------------- Select split LineString where the starting_point is.\n",
    "    \n",
    "    # Find which line from split_gdf has the starting_point_coords\n",
    "    # Extract both lines (starting and ending line)\n",
    "    if starting_point_coords in list(split_gdf.loc[0,'geometry'].coords):\n",
    "        split_edge_geom_start = split_gdf.loc[0,'geometry'] # Extract first line geometry\n",
    "        split_edge_geom_end = split_gdf.loc[1,'geometry'] # Second line geometry\n",
    "        \n",
    "    elif starting_point_coords in list(split_gdf.loc[1,'geometry'].coords):\n",
    "        split_edge_geom_start = split_gdf.loc[1,'geometry'] # Extract second line geometry\n",
    "        split_edge_geom_end = split_gdf.loc[0,'geometry'] # Second line geometry\n",
    "        \n",
    "    # Convert to a GeoDataFrame\n",
    "    split_edge_gdf = gpd.GeoDataFrame()\n",
    "    split_edge_gdf.loc[0,'geometry'] = split_edge_geom_start\n",
    "    \n",
    "    # 4.0 --------------- (Optional) Include split other LineString.\n",
    "    if return_all:\n",
    "        split_edge_gdf.loc[1,'geometry'] = split_edge_geom_end\n",
    "        split_edge_gdf.loc[0,'relation'] = 'starting'\n",
    "        split_edge_gdf.loc[1,'relation'] = 'ending'\n",
    "\n",
    "    # Final format\n",
    "    split_edge_gdf = split_edge_gdf.set_crs(projected_crs)\n",
    "\n",
    "    return split_edge_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2a6fd-6e96-454e-93b3-76871d85b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unique_edge_id(edges_gdf):\n",
    "    # Turn ID data to string\n",
    "    edges_gdf['u'] = edges_gdf['u'].astype('str')\n",
    "    edges_gdf['v'] = edges_gdf['v'].astype('str')\n",
    "    edges_gdf['key'] = edges_gdf['key'].astype('str')\n",
    "    # Concatenate ID data to create unique edge_id\n",
    "    edges_gdf['edge_id'] = edges_gdf['u']+edges_gdf['v']+edges_gdf['key']\n",
    "    # Turn ID data back to int\n",
    "    edges_gdf['u'] = edges_gdf['u'].astype('int')\n",
    "    edges_gdf['v'] = edges_gdf['v'].astype('int')\n",
    "    edges_gdf['key'] = edges_gdf['key'].astype('int')\n",
    "\n",
    "    return edges_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3eca07-13c6-4fba-9562-5ca0405714d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_uncovered(base_nodes, base_edges, complementary_nodes, complementary_edges, contact_analysis_dist, projected_crs=\"EPSG:6372\"):\n",
    "    \"\"\" This function identifies zones within a complementary network (nodes and edges) where currently there's no coverture in a base network.\n",
    "\tArgs:\n",
    "\t\tbase_nodes (geopandas.GeoDataFrame): GeoDataFrame containing nodes of the base network. \n",
    "        base_edges (geopandas.GeoDataFrame): GeoDataFrame containing edges of the base network. \n",
    "\t\tcomplementary_nodes  (geopandas.GeoDataFrame): GeoDataFrame containing nodes of the complementary network.\n",
    "\t\tcomplementary_edges  (geopandas.GeoDataFrame): GeoDataFrame containing edges of the complementary network.\n",
    "\t\tcontact_analysis_dist (float): Distance (meters) used when deciding which nodes from the complementary network should be added to the base network.\n",
    "                                A buffer of {contact_analysis_dist} is created around all center points of each complementary_edge.\n",
    "                                If the buffer touches any base_edges, the complementary_edge is considered as already covered by the base network. \n",
    "                                If the buffer does not touches any base_edge, the complementary_edge is considered uncovered.\n",
    "\t\tprojected_crs (str, optional): string containing projected crs to be used depending on area of interest. Defaults to \"EPSG:6372\".\n",
    "\n",
    "\tReturns:\n",
    "        complementary_uncovered_nodes (geopandas.GeoDataFrame): GeoDataFrame with nodes from the complementary network that are located \n",
    "                                                                in a zone not covered by the base network.\n",
    "        complementary_uncovered_nodes (geopandas.GeoDataFrame): GeoDataFrame with edges from the complementary network that are located\n",
    "                                                                in a zone not covered by the base network.\n",
    "\t\tcontact_nodes (geopandas.GeoDataFrame): GeoDataFrame with nodes from the complementary network that could be used to \n",
    "                                                connect an uncovered zone to a covered zone.\n",
    "\t\"\"\"\n",
    "\n",
    "    # Turn on or off function logs\n",
    "    function_logs = True\n",
    "    \n",
    "    # 1.0 --------------- Extract mid_point of each complementary edge\n",
    "    if function_logs:\n",
    "        print(\"1.0 - Extracting mid_point point of each complementary edge.\")\n",
    "    # ------------------- INPUT USED - READ COMPLEMENTARY EDGES\n",
    "    complementary_edges = complementary_edges.copy()\n",
    "    complementary_edges = complementary_edges.to_crs(projected_crs)\n",
    "    # ------------------- INPUT USED - READ COMPLEMENTARY EDGES\n",
    "\n",
    "    # Create unique ID for each edge using u+v+key\n",
    "    complementary_edges = create_unique_edge_id(complementary_edges)\n",
    "    # Find mid_point of each edge\n",
    "    complementary_edges['mid_point'] = complementary_edges.interpolate(complementary_edges.length / 2)\n",
    "    # Assign mid_point to its own gdf and drop mid_point from complementary_edges\n",
    "    mid_points = complementary_edges[['edge_id','mid_point']].copy()\n",
    "    mid_points.rename(columns={'mid_point':'geometry'},inplace=True)\n",
    "    complementary_edges.drop(columns=['mid_point'],inplace=True)\n",
    "    \n",
    "    # 2.0 --------------- Create contact-analysis buffer around mid_points using contact_analysis_dist \n",
    "    # ------------------- (keep edge of origin data)\n",
    "    if function_logs:\n",
    "        print(\"2.0 - Creating contact-analysis buffer around each mid_point.\")\n",
    "    \n",
    "    # Reset mid_points's index (Keeps data ordered starting from 0)\n",
    "    mid_points.reset_index(inplace=True,drop=True) #--> Resets index without saving col 'index'\n",
    "    # Save each mid_point's reseted index in a column named 'index'\n",
    "    points_to_buffer = mid_points.copy()\n",
    "    points_to_buffer.reset_index(inplace=True) #--> Also creates a col 'index', same order since it is reseted\n",
    "    # Create a gdf containing the contact-analysis buffer around mid_points\n",
    "    mid_points_buffer = points_to_buffer.buffer(contact_analysis_dist)\n",
    "    mid_points_buffer = gpd.GeoDataFrame(geometry=mid_points_buffer)\n",
    "    mid_points_buffer.reset_index(inplace=True) #--> Also creates a col 'index', same order since it is reseted\n",
    "    # Transfer data from mid_points to it's buffer using the previously reseted index as merge col\n",
    "    points_to_buffer.drop(columns=['geometry'],inplace=True)\n",
    "    mid_points_buffer = pd.merge(mid_points_buffer,points_to_buffer,on='index') #--> Merges using common reseted col 'index'\n",
    "    mid_points_buffer.drop(columns=['index'],inplace=True)\n",
    "\n",
    "    # Save disk space\n",
    "    del points_to_buffer\n",
    "    \n",
    "    # 3.0 --------------- Find mid_points whose buffer does not intersect with any part of the base network (Considering base_edges).\n",
    "    # ------------------- [This step creates COMPLEMENTARY_UNCOVERED_EDGES]\n",
    "    if function_logs:\n",
    "        print(\"3.0 - Extracting complementary_uncovered_edges.\")\n",
    "    \n",
    "    # ------------------- INPUT USED - READ BASE EDGES\n",
    "    base_edges = base_edges.copy()\n",
    "    base_edges = base_edges.to_crs(projected_crs)\n",
    "    # ------------------- INPUT USED - READ BASE EDGES\n",
    "    \n",
    "    # Buffers that touch any base edge\n",
    "    buffer_touch = mid_points_buffer.sjoin(base_edges)\n",
    "    # All unique complementary edge_ids that touched any base_edge\n",
    "    edge_id_touch_lst = list(buffer_touch.edge_id.unique())\n",
    "    # Complementary edges that are NOT(~) near any base edge\n",
    "    complementary_uncovered_edges = complementary_edges.loc[~complementary_edges.edge_id.isin(edge_id_touch_lst)].copy()\n",
    "    complementary_uncovered_edges.reset_index(inplace=True,drop=True) #--> Resets index without saving col 'index'\n",
    "\n",
    "    # 4.0 --------------- Select the complementary_nodes that connect to the complementary_uncovered_edges\n",
    "    # ------------------- [This step creates COMPLEMENTARY_UNCOVERED_NODES]\n",
    "    if function_logs:\n",
    "        print(\"4.0 - Extracting complementary_uncovered_nodes.\")\n",
    "    \n",
    "    # ------------------- INPUT USED - READ COMPLEMENTARY NODES\n",
    "    complementary_nodes = complementary_nodes.copy()\n",
    "    complementary_nodes = complementary_nodes.to_crs(projected_crs)\n",
    "    # ------------------- INPUT USED - READ COMPLEMENTARY NODES \n",
    "    \n",
    "    # List of unique 'u's and 'v's that are connected to the complementary_uncovered_edges \n",
    "    complementary_uncovered_osmid_lst = set(list(complementary_uncovered_edges.u.unique()) + list(complementary_uncovered_edges.v.unique()))\n",
    "    # Select any node where its 'osmid' IS in complementary_uncovered_osmid_lst\n",
    "    complementary_uncovered_nodes = complementary_nodes.loc[complementary_nodes.osmid.isin(complementary_uncovered_osmid_lst)].copy()\n",
    "    # [Note: This nodes won't necessarily be in the uncovered zone since they could belong to \n",
    "    # an edge whose mid_point is far from the base network, but whose path extends into the base network.]\n",
    "\n",
    "    # 5.0 --------------- Find the nodes that would be used to connect the uncovered part of the complementary network to the base network.\n",
    "    # ------------------- [This step creates CONTACT_NODES]\n",
    "    if function_logs:\n",
    "        print(\"5.0 - Extracting contact_nodes.\")\n",
    "\n",
    "    # 5.1 --- Create a buffer around all complementary_uncovered_nodes \n",
    "    # Reset complementary_uncovered_nodes's index\n",
    "    complementary_uncovered_nodes.reset_index(inplace=True,drop=True) #--> Resets index without saving col 'index'\n",
    "    # Save each complementary_uncovered_nodes's reseted index in a column named 'index'\n",
    "    nodes_to_buffer = complementary_uncovered_nodes.copy()\n",
    "    nodes_to_buffer.reset_index(inplace=True) #--> Also creates a col 'index', same order since it is reseted\n",
    "    # Create a gdf containing the buffer around complementary_uncovered_nodes\n",
    "    complementary_uncovered_nodes_buffer = nodes_to_buffer.buffer(contact_analysis_dist)\n",
    "    complementary_uncovered_nodes_buffer = gpd.GeoDataFrame(geometry=complementary_uncovered_nodes_buffer)\n",
    "    complementary_uncovered_nodes_buffer.reset_index(inplace=True) #--> Also creates a col 'index', same order since it is reseted\n",
    "    # Transfer data from complementary_uncovered_nodes to it's buffer using the index as merge col\n",
    "    nodes_to_buffer.drop(columns=['geometry'],inplace=True)\n",
    "    complementary_uncovered_nodes_buffer = pd.merge(complementary_uncovered_nodes_buffer,nodes_to_buffer,on='index') #--> Merges using common reseted col 'index'\n",
    "    complementary_uncovered_nodes_buffer.drop(columns=['index'],inplace=True)\n",
    "\n",
    "    # Save disk space\n",
    "    del nodes_to_buffer\n",
    "    \n",
    "    # 5.2 --- Find complementary_uncovered_nodes whose buffer DOES intersect with any part of the base network (Considering base_edges).\n",
    "    # Buffers that touch any base edge\n",
    "    buffer_touch = complementary_uncovered_nodes_buffer.sjoin(base_edges)\n",
    "    # All unique osmids that touched any base_edge\n",
    "    contact_osmids = list(buffer_touch.osmid.unique())\n",
    "    # Complementary nodes that ARE near any base_edge\n",
    "    contact_nodes = complementary_uncovered_nodes.loc[complementary_uncovered_nodes.osmid.isin(contact_osmids)].copy()\n",
    "    contact_nodes.reset_index(inplace=True,drop=True) #--> Resets index without saving col 'index'\n",
    "\n",
    "    # 6.0 --------------- Identify and shorten edges that extend into the base network and would be usefull to create connections.\n",
    "    # ------------------- (Currently those edges are not being considered since they extend to the base network, its\n",
    "    # ------------------- mid_points_buffer is in contact with the base network. This step takes the edge and shortens (Clips)\n",
    "    # ------------------- the edge until it's mid_point_buffer is no longer in contact with the base network)\n",
    "    # ------------------- [This step updates the uncovered network and the contact nodes]\n",
    "    if function_logs:\n",
    "        print(\"6.0 - Creating missing connections through complementary_edges that travel from the uncovered zone to the base network.\")\n",
    "\n",
    "    # PREPARATION FOR ANALYSIS:\n",
    "\n",
    "    # Keep track of the amount of edges that underwent a shortening process\n",
    "    fabricated_count = 0\n",
    "\n",
    "    # LOG CODE - Progress logs\n",
    "    # Will create progress logs when progress reaches these percentages:\n",
    "    progress_logs = [10,20,30,40,50,60,70,80,90,100] # for log statistics\n",
    "    osmid_count = 0\n",
    "    # LOG CODE - Progress logs\n",
    "\n",
    "    # Create empty GeoDataFrame to store all original_diverging_nodes and original_diverging_edges (For GIS Visualization purposes)\n",
    "    original_diverging_nodes = gpd.GeoDataFrame()\n",
    "    original_diverging_edges = gpd.GeoDataFrame()\n",
    "    \n",
    "    # Find all complementary_uncovered_osmids (from previously created complementary_uncovered_osmid_lst)\n",
    "    # that are NOT a contact osmid (Those that already serve as a connection to the base network)\n",
    "    non_contact_osmids = [osmid for osmid in complementary_uncovered_osmid_lst if osmid not in contact_osmids]\n",
    "    \n",
    "    # Previously produced osmid. Since will be creating non-existing nodes, function produce_osmid() will use a starting number for\n",
    "    # trying to produce unique osmids. That function will check if that osmid already exists in either the base or complementary network.\n",
    "    # Start with number 0.\n",
    "    previously_produced = 0\n",
    "\n",
    "    # Read base_nodes once (will be used to assess if the osmid being produced is unique)\n",
    "    # ------------------- INPUT USED - READ BASE EDGES\n",
    "    base_nodes = base_nodes.copy()\n",
    "    base_nodes = base_nodes.to_crs(projected_crs)\n",
    "    # ------------------- INPUT USED - READ BASE EDGES\n",
    "\n",
    "    # Keep track of which parts of the network where fabricated with the following code.\n",
    "    # All edges that keep its original geometry will be assigned 'clipping_i' = 0.\n",
    "    # All edges whose geometry was clipped will be assigned the amount of shortening (clipping) iterations used in them.\n",
    "    complementary_uncovered_nodes['clipping_i'] = 0\n",
    "    complementary_uncovered_edges['clipping_i'] = 0\n",
    "    complementary_uncovered_edges['original_edge_id'] = np.nan\n",
    "    contact_nodes['clipping_i'] = 0\n",
    "\n",
    "    # Shortening dict\n",
    "    # Sometimes an edge could get shortened from both sides. \n",
    "    # (Clipped with starting point 'u' and then, on another case, clipped with starting point 'u')\n",
    "    # If an edge will be shortened from both sides, make sure that if the edge is shortened just once in both sides \n",
    "    # (Shortened from 'u' to midpoint and from 'v' to midpoint), only one contact_node is created.\n",
    "    # If not considered, this particular situation can create two different edges that coincide in two different contact_nodes exactly in the midpoint.\n",
    "    # This is the main reason why it is necessary to keep track of which edges where shortened and up to which point.\n",
    "    shortening_dict = {}\n",
    "    \n",
    "    # Review each node in the uncovered zone of the complementary network (Previously created complementary_uncovered_osmid_lst)\n",
    "    for osmid in non_contact_osmids:\n",
    "\n",
    "        # Development check\n",
    "        #if osmid != 436813694931:\n",
    "        #    continue\n",
    "        #else:\n",
    "        #    print(osmid)\n",
    "        \n",
    "        # LOG CODE - Progress logs\n",
    "        # Measures current progress, prints if passed a checkpoint of progress_logs list.\n",
    "        current_progress = (osmid_count / len(non_contact_osmids))*100\n",
    "        for checkpoint in progress_logs:\n",
    "            if (current_progress >= checkpoint) and function_logs:\n",
    "                print(f'Exploring osmids. {checkpoint}% done.')\n",
    "                progress_logs.remove(checkpoint)\n",
    "                break\n",
    "        # LOG CODE - Progress logs\n",
    "\n",
    "        # Retrieve it's edges (Will be refered as diverging_edges). \n",
    "        # Must consider all edges (complementary_edges) and not only complementary_uncovered_edges since\n",
    "        # since it's looking to identify if an edge that comes out of that osmid goes towards base_network.\n",
    "        diverging_edges = complementary_edges.loc[(complementary_edges.u==osmid) | (complementary_edges.v==osmid)].copy()\n",
    "        diverging_edges_ids = list(diverging_edges.edge_id.unique())\n",
    "        \n",
    "        # For each edge diverging from current node:\n",
    "        for diverging_edge_id in diverging_edges_ids:\n",
    "            # If the edge DOES touch the base network:\n",
    "            if diverging_edge_id in edge_id_touch_lst: # (Previously created edge_id_touch_lst)\n",
    "                # If an edge reaches this part of the code, it means that it is a complementary_edge that:\n",
    "                # a) Comes out from an node that's located in the uncovered zone (complementary_uncovered_node).\n",
    "                # b) The node it came out from is NOT a contact_node, it is far from the base network (According to contact_analysis_dist)\n",
    "                # c) The edge's current mid_point is located in proximity to the base network (According to contact_analysis_dist)\n",
    "                # --> Between the base_network and this edge itself, a connection point should be identified.\n",
    "                # --> Objective: Identify that connection (new contact_node) between the complementary and base network.\n",
    "\n",
    "                # 6.1 --- Retrieve current diverging_osmid and diverging_node\n",
    "                # Save the osmid from the node which the current edge uses to come out from the uncovered zone into the base network.\n",
    "                diverging_osmid = osmid\n",
    "                # Extract its node\n",
    "                diverging_node = complementary_uncovered_nodes.loc[complementary_uncovered_nodes.osmid == diverging_osmid].copy()\n",
    "                # Reset index (so that accessing its geometry is always .loc[0,'geometry'])\n",
    "                diverging_node.reset_index(inplace=True, drop=True)\n",
    "                # Add current diverging_node to original_diverging_nodes gdf (For GIS visualization purposes)\n",
    "                original_diverging_nodes = pd.concat([original_diverging_nodes, diverging_node])\n",
    "\n",
    "                # 6.2 --- Retrieve current diverging_edge as the connection_edge\n",
    "                # Select the edge that diverts from the diverging_node towards the base_network\n",
    "                connection_edge = complementary_edges.loc[complementary_edges.edge_id == diverging_edge_id].copy()\n",
    "                # Reset index (so that accessing its data is always .loc[0,'data'])\n",
    "                connection_edge.reset_index(inplace=True,drop=True)\n",
    "                # The connection_edge geometry will suffer modifications, save original\n",
    "                original_connection_edge = connection_edge.copy() \n",
    "                # Add current connection_edge to original_diverging_edges gdf (For GIS visualization purposes)\n",
    "                original_diverging_edges = pd.concat([original_diverging_edges, connection_edge])\n",
    "\n",
    "                # 6.3 --- Clip connection_edge until it's mid_point is no longer in proximity to the base network.\n",
    "                # ------- When this point is reached, assign its ending_point (previous mid_point) as a new contact_node.\n",
    "            \n",
    "                # Kickstart while loop for current connection_edge\n",
    "                stop = False\n",
    "                shorten_i = 0\n",
    "                \n",
    "                while (stop == False):\n",
    "\n",
    "                    # Limit of attempts\n",
    "                    limit_of_attempts = 20\n",
    "                    if shorten_i >= limit_of_attempts:\n",
    "                        print(f\"Tried shortening {limit_of_attempts} times edge u {original_connection_edge.u.unique()[0]} and v {original_connection_edge.v.unique()[0]}. Stopped.\")\n",
    "                        break\n",
    "                        \n",
    "                    # 6.3.1 --- Calculate the edge's mid_point.\n",
    "                    # --------- [Will become the clipping_point in function edge_clipping()].\n",
    "                \n",
    "                    # Calculate the connection_edge's mid_point\n",
    "                    connection_edge['mid_point'] = connection_edge.interpolate(connection_edge.length / 2)\n",
    "                    # Assign mid_point to its own gdf and drop mid_point from connection_edge gdf\n",
    "                    edge_mid_point = connection_edge[['edge_id','mid_point']].copy()\n",
    "                    edge_mid_point.rename(columns={'mid_point':'geometry'},inplace=True)\n",
    "                    connection_edge.drop(columns=['mid_point'],inplace=True)\n",
    "                \n",
    "                    # 6.3.2 --- Evaluate if the current mid_point is still in proximity to the base network\n",
    "                    # 6.3.2.a - Create contact-analysis buffer around the edge_mid_point\n",
    "                    # Reset edge_mid_point's index\n",
    "                    edge_mid_point.reset_index(inplace=True,drop=True) #--> Resets index without saving col 'index'\n",
    "                    # Save edge_mid_point's reseted index in a column named 'index'\n",
    "                    point_to_buffer = edge_mid_point.copy()\n",
    "                    point_to_buffer.reset_index(inplace=True) #--> Also creates a col 'index', same order since it is reseted\n",
    "                    # Create a gdf containing the contact-analysis buffer around the edge_mid_point\n",
    "                    mid_point_buffer = point_to_buffer.buffer(contact_analysis_dist)\n",
    "                    mid_point_buffer = gpd.GeoDataFrame(geometry=mid_point_buffer)\n",
    "                    mid_point_buffer.reset_index(inplace=True) #--> Also creates a col 'index', same order since it is reseted\n",
    "                    # Transfer data from edge_mid_point to it's buffer using the previously reseted index as merge col\n",
    "                    point_to_buffer.drop(columns=['geometry'],inplace=True)\n",
    "                    mid_point_buffer = pd.merge(mid_point_buffer,point_to_buffer,on='index') #--> Merges using common reseted col 'index'\n",
    "                    mid_point_buffer.drop(columns=['index'],inplace=True)\n",
    "                    \n",
    "                    # 6.3.2.b - Find if current mid_point it's still in proximity to base network\n",
    "                    # Buffers that touch any base edge\n",
    "                    buffer_touch = mid_point_buffer.sjoin(base_edges)\n",
    "                    \n",
    "                    if len(buffer_touch) > 0:\n",
    "                        \n",
    "                        # 6.3.3 --- If it still touches, reduce in size.\n",
    "                        # If the mid_point_buffer still touches the base edges, the line is most likely still overlaping with the base network.\n",
    "                        # Apply edge_clipping function to shorten the edge up until the current mid_point\n",
    "                        connection_edge = edge_clipping(starting_point_gdf = diverging_node,\n",
    "                                                        edge_gdf = connection_edge,\n",
    "                                                        clipping_point_gdf = edge_mid_point,\n",
    "                                                        projected_crs = projected_crs)\n",
    "                        # Keep connection_edge format\n",
    "                        connection_edge['edge_id'] = diverging_edge_id\n",
    "                        # Count shortening iteration\n",
    "                        shorten_i+=1\n",
    "                    \n",
    "                    else:\n",
    "                        # 6.3.3 --- If the buffer no longer touches any part of the base network, shortening was a success.\n",
    "                        # --------- However, before registering the shortened edge it it necessary to run a test:\n",
    "                        \n",
    "                        # Double-once-shortening test STARTS ### ### ### ### ### ### ### ### ### ### ### ### \n",
    "                        # EXPLANATION:\n",
    "                        # A complementary_edge could be shortened twice, once from each starting_point. This is a \"double shortening\".\n",
    "                        # It occurs when an edge was shortened from node 1 (e.g. from 'u') and now is being shortened from node 2 (e.g. from 'v').\n",
    "                        # This process produces no problems, **unless both shortening processess undergo just 1 iteration**.\n",
    "                        # In that specific case, both lines start in their nodes ('u' or 'v') and end at the original line's midpoint.\n",
    "                        # This produces TWO different contact_nodes in a very similar location, that could result in TWO similar but different treatments and strange geometries.\n",
    "                        # In order to avoid this, this double_shortening check is conduced in order to make sure that \n",
    "                        # at the end of both processes, just ONE contact node is produced and used by both edges ending on it.\n",
    "\n",
    "                        # If this is NOT the first fabrication case and edge AND the current edge was shortened ONLY once:\n",
    "                        if (fabricated_count > 0) and (shorten_i==1):\n",
    "    \n",
    "                            # Load all original edge_ids that have been shortened ONLY once\n",
    "                            already_shortened_once = complementary_uncovered_edges.loc[complementary_uncovered_edges.clipping_i==1].copy()\n",
    "                            already_shortened_once_lst = list(already_shortened_once.original_edge_id.unique())\n",
    "\n",
    "                            # Check if current diverging_edge_id has already been shortened ONLY once\n",
    "                            if diverging_edge_id in already_shortened_once_lst:\n",
    "                                # If an edge reaches this part of the code, the edge was already shortened ONCE from one end, and was being shortened again ONCE from the other end.\n",
    "                                # Next step --> Do NOT produce a new contact osmid and new point for current edge. Use the existing one. \n",
    "                                # ------------> Register the edge under the existing contact_node instead of creating a new one.\n",
    "\n",
    "                                # 6.3.3.a1 - Identify the previously produced middle osmid.\n",
    "                                # Retrieve the ORIGINAL (current original_connection_edge's) 'u' and 'v'\n",
    "                                original_u = original_connection_edge.u.unique()[0]\n",
    "                                original_v = original_connection_edge.v.unique()[0]\n",
    "                                original_osmids = [original_u, original_v]\n",
    "                                print(original_osmids)\n",
    "                                # Retrieve the PREVIOUSLY PRODUCED (previously shortened edge) 'u' and 'v'\n",
    "                                prev_produced_edge = complementary_uncovered_edges.loc[complementary_uncovered_edges.original_edge_id == diverging_edge_id].copy()\n",
    "                                new_u = prev_produced_edge.u.unique()[0]\n",
    "                                new_v = prev_produced_edge.v.unique()[0]\n",
    "                                new_osmids = [new_u, new_v]\n",
    "                                print(new_osmids)\n",
    "                                # Identify which osmid is in the new _osmids but not in the original_osmids \n",
    "                                # (Which osmid was produced here, in step 6.3.3)\n",
    "                                for osmid in new_osmids:\n",
    "                                    if osmid not in original_osmids:\n",
    "                                        produced_osmid = osmid\n",
    "\n",
    "                                # 6.3.3.a2 - Add the connection_edge as a new edge to complementary_uncovered_edges gdf (But not the node, the node is already there).\n",
    "                                # Retrieve the diverging_osmid's position in the ORIGINAL connection_edge. (Whether 'u' or 'v')\n",
    "                                # In order to keep that original diverging_node in its position and add the produced_osmid in the other position.\n",
    "                                if diverging_osmid == original_u:\n",
    "                                    connection_edge_u = diverging_osmid\n",
    "                                    connection_edge_v = produced_osmid\n",
    "                                elif diverging_osmid == original_v:\n",
    "                                    connection_edge_u = produced_osmid\n",
    "                                    connection_edge_v = diverging_osmid\n",
    "                                else:\n",
    "                                    print(f\"ERROR while trying to set 'u' and 'v' for shortened connection edge {diverging_edge_id}.\")\n",
    "                                    intended_crash\n",
    "                                # Use the same key that was used in the original_connection_edge\n",
    "                                connection_edge_key = original_connection_edge.key.unique()[0]\n",
    "                                # Retrieve the modified edge's (connection_edge's) geometry\n",
    "                                connection_edge_geom = connection_edge['geometry'].unique()[0]\n",
    "                                # Find current last position\n",
    "                                iloc_edge = len(complementary_uncovered_edges)\n",
    "                                # Register new edge\n",
    "                                complementary_uncovered_edges.loc[iloc_edge+1,'u'] = connection_edge_u\n",
    "                                complementary_uncovered_edges.loc[iloc_edge+1,'v'] = connection_edge_v\n",
    "                                complementary_uncovered_edges.loc[iloc_edge+1,'key'] = connection_edge_key\n",
    "                                complementary_uncovered_edges.loc[iloc_edge+1,'geometry'] = connection_edge_geom\n",
    "                                complementary_uncovered_edges.loc[iloc_edge+1,'edge_id'] = str(connection_edge_u)+str(connection_edge_v)+str(connection_edge_key)\n",
    "                                complementary_uncovered_edges.loc[iloc_edge+1,'original_edge_id'] = diverging_edge_id\n",
    "                                complementary_uncovered_edges.loc[iloc_edge+1,'clipping_i'] = shorten_i\n",
    "\n",
    "                                # 6.3.3.a3 - Finished registering. Stop while loop. Continue with the next diverging_edge_id of current osmid.\n",
    "                                print(f\"Reused contact node {produced_osmid} for original edge {diverging_edge_id}.\")\n",
    "                                \n",
    "                                fabricated_count += 1\n",
    "                                stop = True\n",
    "                                continue\n",
    "\n",
    "                            # Else, this is the first time that the edge is shortened once. \n",
    "                            # Not relevant, continue as usual.\n",
    "                            else:\n",
    "                                pass\n",
    "                                \n",
    "                        # Else, either this is the first edge to be shortened or shorten_i is not equall to 1. \n",
    "                        # Not relevant, continue as usual.\n",
    "                        else:\n",
    "                            pass\n",
    "                        # Double-once-shortening test ENDS ### ### ### ### ### ### ### ### ### ### ### ### \n",
    "\n",
    "                        # CONTINUATION OF NORMAL PROCESS:\n",
    "                        # The current mid_point is not in proximity to the base network.\n",
    "                        # But the previous mid_point (The current connection_edge's endpoint) WAS KNOWN TO BE in proximity to the base network.\n",
    "                        # Next step --> Transform the last mid_point (The currend endpoint) into a contact_node and update the edge.\n",
    "                \n",
    "                        # 6.3.3.b1 - Produce a unique osmid (That doesn't exist in either network) in order to add the edge and point\n",
    "                        # Produce a unique osmid\n",
    "                        produced_osmid = produce_osmid(base_nodes, complementary_nodes, previously_produced+1)\n",
    "                        # Save produced osmid to avoid trying numbers unnecessarily\n",
    "                        previously_produced = produced_osmid\n",
    "                \n",
    "                        # 6.3.3.b2 - Find the ending_point's coordinates.\n",
    "                        # --------- It is unsure whether the diverging_node is located at the coordinate 0 or at the last coordinate of the connection_edge.\n",
    "                        # --------- So it is necessary to identify which one is which.\n",
    "                        # Extract the edge's coordinates list\n",
    "                        connection_edge_coords = list(connection_edge['geometry'][0].coords)\n",
    "                        # Extract the starting_point's coordinates (Known to be the diverging_node)\n",
    "                        starting_point_coords = diverging_node.loc[0,'geometry'].coords[0]\n",
    "                        # Obtain the ending_point's coordinates (It is the previous iteration edge's mid_point)\n",
    "                        # (It is either the first or last coordinate of the connection_edge)\n",
    "                        if starting_point_coords == connection_edge_coords[0]:\n",
    "                            ending_point_coords = connection_edge_coords[-1]\n",
    "                        elif starting_point_coords == connection_edge_coords[-1]:\n",
    "                            ending_point_coords = connection_edge_coords[0]\n",
    "                        else:\n",
    "                            print(f\"ERROR while trying to find the starting and ending point of shortened connection edge {diverging_edge_id}.\")\n",
    "                            intended_crash\n",
    "                \n",
    "                        # 6.3.3.b3 - Add the ending_point as a node\n",
    "                        # Register to complementary_uncovered_nodes gdf\n",
    "                        iloc_node = len(complementary_uncovered_nodes)+1\n",
    "                        complementary_uncovered_nodes.loc[iloc_node,'osmid'] = produced_osmid\n",
    "                        complementary_uncovered_nodes.loc[iloc_node,'geometry'] = Point(ending_point_coords)\n",
    "                        complementary_uncovered_nodes.loc[iloc_node,'clipping_i'] = shorten_i\n",
    "                        # Register to contact_nodes gdf\n",
    "                        iloc_node = len(contact_nodes)+1\n",
    "                        contact_nodes.loc[iloc_node,'osmid'] = produced_osmid\n",
    "                        contact_nodes.loc[iloc_node,'geometry'] = Point(ending_point_coords)\n",
    "                        contact_nodes.loc[iloc_node,'clipping_i'] = shorten_i\n",
    "                \n",
    "                        # 6.3.3.b4 - Add the connection_edge as a new edge to complementary_uncovered_edges gdf\n",
    "                        # Retrieve the diverging_osmid its position in the ORIGINAL connection_edge. (Whether 'u' or 'v')\n",
    "                        # In order to keep that original diverging_node in its position and add the produced_osmid in the other position.\n",
    "                        original_u = original_connection_edge.u.unique()[0]\n",
    "                        original_v = original_connection_edge.v.unique()[0]\n",
    "                        if diverging_osmid == original_u:\n",
    "                            connection_edge_u = diverging_osmid\n",
    "                            connection_edge_v = produced_osmid\n",
    "                        elif diverging_osmid == original_v:\n",
    "                            connection_edge_u = produced_osmid\n",
    "                            connection_edge_v = diverging_osmid\n",
    "                        else:\n",
    "                            print(f\"ERROR while trying to set 'u' and 'v' for shortened connection edge {diverging_edge_id}.\")\n",
    "                            intended_crash\n",
    "                        # Use the same key that was used in the original connection_edge\n",
    "                        connection_edge_key = original_connection_edge.key.unique()[0]\n",
    "                        # Retrieve the modified edge's (connection_edge's) geometry\n",
    "                        connection_edge_geom = connection_edge['geometry'].unique()[0]\n",
    "                        # Find last position\n",
    "                        iloc_edge = len(complementary_uncovered_edges)+1\n",
    "                        # Register new edge\n",
    "                        complementary_uncovered_edges.loc[iloc_edge,'u'] = connection_edge_u\n",
    "                        complementary_uncovered_edges.loc[iloc_edge,'v'] = connection_edge_v\n",
    "                        complementary_uncovered_edges.loc[iloc_edge,'key'] = connection_edge_key\n",
    "                        complementary_uncovered_edges.loc[iloc_edge,'geometry'] = connection_edge_geom\n",
    "                        complementary_uncovered_edges.loc[iloc_edge,'edge_id'] = str(connection_edge_u)+str(connection_edge_v)+str(connection_edge_key)\n",
    "                        complementary_uncovered_edges.loc[iloc_edge,'original_edge_id'] = diverging_edge_id\n",
    "                        complementary_uncovered_edges.loc[iloc_edge,'clipping_i'] = shorten_i\n",
    "                        \n",
    "                        # 6.3.3.b5 - Finished registering. Stop while loop. Continue with the next diverging_edge_id of current osmid.\n",
    "                        fabricated_count += 1\n",
    "                        stop = True\n",
    "        \n",
    "        # LOG CODE - Progress logs\n",
    "        # Finished reviewing current osmid. Continue with next osmid in non_contact_osmids.\n",
    "        osmid_count+=1\n",
    "        # LOG CODE - Progress logs\n",
    "\n",
    "    print(f\"Finished. Fabricated {fabricated_count}.\")\n",
    "                \n",
    "    return complementary_uncovered_nodes, complementary_uncovered_edges, contact_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39511d-553c-4186-a4c3-a34b9156df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run identify_uncovered function\n",
    "distance = 10\n",
    "complementary_uncovered_nodes, complementary_uncovered_edges, contact_nodes = identify_uncovered(base_nodes = boeing_nodes,\n",
    "                                                                                                 base_edges = boeing_edges,\n",
    "                                                                                                 complementary_nodes = tess_nodes,\n",
    "                                                                                                 complementary_edges = tess_edges,\n",
    "                                                                                                 contact_analysis_dist = distance,\n",
    "                                                                                                 projected_crs = projected_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854627e-e97a-4a66-814d-8f7e11886e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if localsave_01_02:\n",
    "    complementary_uncovered_nodes.to_file(output_dir + \"part01_step02_identifyuncovered/complementary_uncovered_nodes.gpkg\")\n",
    "    complementary_uncovered_edges.to_file(output_dir + \"part01_step02_identifyuncovered/complementary_uncovered_edges.gpkg\")\n",
    "    contact_nodes.to_file(output_dir + \"part01_step02_identifyuncovered/contact_nodes.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd116ec1-e4ac-4c4f-a63b-6c2ce231830f",
   "metadata": {},
   "source": [
    "## __Part 02 - Step 01 -__ Networks intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20cbdc-4967-4bb2-9878-680091eb866c",
   "metadata": {},
   "source": [
    "This step __finds the intersection points existing__ between the base network and the uncovered parts of the complementary network, and then modifies both network in order to __incorporate the intersection points as new nodes__ on both networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cee364-43bf-4da1-af26-0b5194b5c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection_nodes(ntw_01_nodes, ntw_01_edges, ntw_02_nodes, ntw_02_edges, projected_crs):\n",
    "\n",
    "    \"\"\" This function finds the intersection points existing between two different networks, and turns them\n",
    "        into nodes by assigning them a unique osmid.\n",
    "    \n",
    "\tArgs:\n",
    "\t\tntw_01_nodes (geopandas.GeoDataFrame): GeoDataFrame containing the nodes from network 01.\n",
    "                                                Requires a unique identifier 'osmid'.\n",
    "        ntw_01_edges (geopandas.GeoDataFrame): GeoDataFrame containing the edges from network 01. \n",
    "                                                   Requires the unique identifiers 'u ,'v' and 'key'.\n",
    "        ntw_02_nodes (geopandas.GeoDataFrame): GeoDataFrame containing the nodes from network 02.\n",
    "                                                Requires a unique identifier 'osmid'.\n",
    "        ntw_02_edges (geopandas.GeoDataFrame): GeoDataFrame containing the edges from network 02. \n",
    "                                                   Requires the unique identifiers 'u ,'v' and 'key'.\n",
    "        projected_crs (str, optional): String containing projected crs to be used depending on area of interest. \n",
    "                                        Defaults to \"EPSG:6372\".\n",
    "                                                 \n",
    "\tReturns:\n",
    "        intersection_nodes (geopandas.GeoDataFrame): GeoDataFrame containing the new nodes where both networks intersect.\n",
    "        \n",
    "\t\"\"\"\n",
    "    \n",
    "    # 1.0 --------------- Intersect both network's edges to create the intersection_points.\n",
    "    # ------------------- These nodes contain data from the edges that were intersected.\n",
    "\n",
    "    # ------------------- INPUT USED - READ AND FILTER EDGES\n",
    "    ntw_01_edges = ntw_01_edges.copy()\n",
    "    ntw_01_edges = ntw_01_edges.to_crs(projected_crs)\n",
    "    ntw_01_edges = ntw_01_edges[['u','v','key','geometry']]\n",
    "\n",
    "    ntw_02_edges = ntw_02_edges.copy()\n",
    "    ntw_02_edges = ntw_02_edges.to_crs(projected_crs)\n",
    "    ntw_02_edges = ntw_02_edges[['u','v','key','geometry']]\n",
    "    # ------------------- INPUT USED - READ AND FILTER EDGES\n",
    "    \n",
    "    # Intersect ntw_01_edges and ntw_02_edges to create intersection_points\n",
    "    # Each intersection_point contains data from the edges being intersected.\n",
    "    # For ntw_01_edges, columns: u_1, v_1, key_1\n",
    "    # For ntw_02_edges, columns: u_2, v_2, key_2\n",
    "    intersection_points = ntw_01_edges.overlay(ntw_02_edges,how='intersection',keep_geom_type=False)\n",
    "    # Explode multipoints\n",
    "    # If an edge from network \"x\" cuts an edge from network \"y\" twice or more [e.g. a straight edge cutting a curved edge], \n",
    "    # the resulting geometry is a MultiPoint (One point in the first intersection, another for the second and so on).\n",
    "    # In order to avoid assigning the same data to both points, exploding is neccesary.\n",
    "    intersection_points = intersection_points.explode(index_parts=False)\n",
    "    intersection_points.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    print(\"Intersected networks and created intersection_points.\")\n",
    "\n",
    "    # 2.0 --------------- Assign unique osmid to each new intersection_point to turn it into a intersection_node.\n",
    "\n",
    "    # ------------------- INPUT USED - READ AND FILTER EDGES\n",
    "    ntw_01_nodes = ntw_01_nodes.copy()\n",
    "    ntw_01_nodes = ntw_01_nodes.to_crs(projected_crs)\n",
    "    ntw_01_nodes = ntw_01_nodes[['osmid','geometry']]\n",
    "\n",
    "    ntw_02_nodes = ntw_02_nodes.copy()\n",
    "    ntw_02_nodes = ntw_02_nodes.to_crs(projected_crs)\n",
    "    ntw_02_nodes = ntw_02_nodes[['osmid','geometry']]\n",
    "    # ------------------- INPUT USED - READ AND FILTER EDGES\n",
    "\n",
    "    intersection_nodes = intersection_points.copy()\n",
    "    del intersection_points\n",
    "    # Set all osmids to 0\n",
    "    intersection_nodes['osmid'] = 0\n",
    "    # Restart previously_produced\n",
    "    previously_produced = 0\n",
    "    # For each intersection between networks (new node)\n",
    "    for index,row in intersection_nodes.iterrows():\n",
    "        # Produce a unique osmsid (That doesn't exist in either network)\n",
    "        produced_osmid = produce_osmid(ntw_01_nodes, ntw_02_nodes, previously_produced)\n",
    "        # Assign osmid to current intersection_node\n",
    "        intersection_nodes.loc[index,'osmid'] = produced_osmid\n",
    "        # Since ntw_01_nodes and ntw_02_nodes are not being updated, next time try with next possible osmid\n",
    "        previously_produced = produced_osmid+1\n",
    "\n",
    "    print(\"Set unique osmids to all intersection_points. Turned into intersection_nodes.\")\n",
    "\n",
    "    # Set unique identifiers to int\n",
    "    intersection_nodes['u_1'] = intersection_nodes['u_1'].astype('int')\n",
    "    intersection_nodes['v_1'] = intersection_nodes['v_1'].astype('int')\n",
    "    intersection_nodes['key_1'] = intersection_nodes['key_1'].astype('int')\n",
    "    intersection_nodes['u_2'] = intersection_nodes['u_2'].astype('int')\n",
    "    intersection_nodes['v_2'] = intersection_nodes['v_2'].astype('int')\n",
    "    intersection_nodes['key_2'] = intersection_nodes['key_2'].astype('int')\n",
    "    intersection_nodes['osmid'] = intersection_nodes['osmid'].astype('int')\n",
    "\n",
    "    return intersection_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a937f-1e35-4299-b728-e15fba8f9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_nodes = find_intersection_nodes(ntw_01_nodes = boeing_nodes,\n",
    "                                             ntw_01_edges = boeing_edges,\n",
    "                                             ntw_02_nodes = complementary_uncovered_nodes,\n",
    "                                             ntw_02_edges = complementary_uncovered_edges,\n",
    "                                             projected_crs = projected_crs)\n",
    "\n",
    "# Show\n",
    "print(intersection_nodes.shape)\n",
    "intersection_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc53ca-8014-40a9-9687-883a566f8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_intersections_update(current_ntw_nodes, current_ntw_edges, intersection_nodes, projected_crs, function_logs=False):\n",
    "\n",
    "    \"\"\" This function takes points with osmid located over existing edges (intersection_nodes) and updates\n",
    "        a network. The intersection_nodes become new nodes and each intersected edge get split \n",
    "        into two separate edges with new 'u', 'v' and 'key' data.\n",
    "    \n",
    "\tArgs:\n",
    "\t\tcurrent_ntw_nodes (geopandas.GeoDataFrame): GeoDataFrame containing the nodes from the network to update.\n",
    "                                                    Requires a unique identifier 'osmid'.\n",
    "        current_ntw_edges (geopandas.GeoDataFrame): GeoDataFrame containing the edges from the network to update.\n",
    "                                                    Requires the unique identifiers 'u ,'v' and 'key'.\n",
    "        intersection_nodes (geopandas.GeoDataFrame): GeoDataFrame containing the points in where each split is performed.\n",
    "                                                    Requires points with 'osmid', and the edge to split ('u','v' and 'key').\n",
    "        projected_crs (str, optional): String containing projected crs to be used depending on area of interest. \n",
    "                                        Defaults to \"EPSG:6372\".\n",
    "        function_logs (bool,optional): Boolean that (if True) prints logs during the functions execution. Defaults to False.\n",
    "\n",
    "                                                 \n",
    "\tReturns:\n",
    "        updated_ntw_nodes (geopandas.GeoDataFrame): GeoDataFrame containing the updated nodes for the network.\n",
    "        updated_ntw_edges (geopandas.GeoDataFrame): GeoDataFrame containing the updated edges for the network. \n",
    "        \n",
    "\t\"\"\" \n",
    "    print(f\"Updating network...\")\n",
    "    \n",
    "    # ------------------- INPUT USED - READ AND FILTER EDGES\n",
    "    current_ntw_nodes = current_ntw_nodes.copy()\n",
    "    current_ntw_nodes = current_ntw_nodes.to_crs(projected_crs)\n",
    "    # Set an identifier to make it easier to locate nodes that resulted from an intersection between networks\n",
    "    current_ntw_nodes['intersecting'] = 0\n",
    "\n",
    "    current_ntw_edges = current_ntw_edges.copy()\n",
    "    current_ntw_edges = current_ntw_edges.to_crs(projected_crs)\n",
    "    # Set an identifier to make it easier to locate edges that were split\n",
    "    current_ntw_edges['intersecting'] = 0\n",
    "    # ------------------- INPUT USED - READ AND FILTER EDGES\n",
    "\n",
    "    # Iterate over each intersection between both networks (intersection_nodes)\n",
    "    for idx, node in intersection_nodes.iterrows():\n",
    "        \n",
    "        # 3.1 --------------- Split the current_ntw intersected edge using the intersection_node as clipping_point. \n",
    "        # ------------------- This split (Using function edge_clipping()) creates two separate edges:\n",
    "        # ------------------- The first edge will be related to the starting_point_gdf (We'll set intersected edge 'u')\n",
    "        # ------------------- The second edge will be related to the opposite side (Will be intersected edge 'v')\n",
    "    \n",
    "        # Current intersection_node's data\n",
    "        intersection_node_osmid = node['osmid']\n",
    "        intersected_u = node['u']\n",
    "        intersected_v = node['v']\n",
    "        intersected_key = node['key']\n",
    "        intersected_retain_how = node['retain_how']        \n",
    "\n",
    "        if function_logs:\n",
    "            print(f\"network_intersections_update(): Iterating over intersection node osmid {intersection_node_osmid}.\") #Debugging check\n",
    "            print(f\"network_intersections_update(): Intersected edge with u {intersected_u} type {type(intersected_u)}.\") #Debugging check\n",
    "            print(f\"network_intersections_update(): Intersected edge with v {intersected_v} type {type(intersected_v)}.\") #Debugging check\n",
    "            print(f\"network_intersections_update(): Intersected edge with key {intersected_key} type {type(intersected_key)}.\") #Debugging check\n",
    "            \n",
    "        # Extract current intersection node as a gdf (Becomes clipping_point_gdf in function edge_clipping)\n",
    "        intersection_node = intersection_nodes.loc[intersection_nodes.osmid == intersection_node_osmid].copy()\n",
    "        intersection_node.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "        # Extract current_ntw intersected edge (Becomes edge_gdf in function edge_clipping)\n",
    "        try:\n",
    "            # Try loading the edge registered as intersected in the intersection_nodes gdf.\n",
    "            # ('intersected_u', 'intersected_v' and 'intersected_key')\n",
    "            intersected_edge = current_ntw_edges.loc[(current_ntw_edges['u'] == intersected_u) & \n",
    "                                                     (current_ntw_edges['v'] == intersected_v) &\n",
    "                                                     (current_ntw_edges['key'] == intersected_key)].copy()\n",
    "            intersected_edge.reset_index(inplace=True,drop=True)\n",
    "            # If it has len=0, it failed.\n",
    "            if len(intersected_edge) == 0:\n",
    "                fail_try\n",
    "                \n",
    "        except:\n",
    "            # If it doesn't work, it means that the edge no longer exists (deleted in following steps in this function)\n",
    "            # This happens because that edge had another intersection along its lenght and \n",
    "            # that original unsplit edge was split and deleted.\n",
    "            # Now a new already split edge lies underneath the current intersection_node.\n",
    "            # --> Find that split edge's data\n",
    "            if function_logs:\n",
    "                print(f\"\"\"network_intersections_update(): Searching for already split edge originating from edge with u {intersected_u}, v {intersected_v} and key {intersected_key}.\"\"\")\n",
    "            # Create a VERY SMALL buffer around the intersection_node\n",
    "            intersection_node_buffer = intersection_node.buffer(1e-9)\n",
    "            intersection_node_buffer = gpd.GeoDataFrame(geometry=intersection_node_buffer)\n",
    "            # Find and rewrite the data of the split edge underneath the intersection_node\n",
    "            edge_data = intersection_node_buffer.sjoin(current_ntw_edges)\n",
    "            if len(edge_data) == 1:\n",
    "                intersected_u = edge_data.u.unique()[0]\n",
    "                intersected_v = edge_data.v.unique()[0]\n",
    "                intersected_key = edge_data.key.unique()[0]\n",
    "            else:\n",
    "                print(\"Multi-intersection crash\")\n",
    "                # If this happens, it means the intersection_node is located exactly over two edges of the same network\n",
    "                # It is very unlikely, but if it happens the code-to-write should identify the edge from edge_data \n",
    "                # that contains in either its 'u' or 'v' the same node as the current intersected_u or intersected_v.\n",
    "                # This way we'll identify the edge to be split.\n",
    "\n",
    "            # Retrieve intersected edge\n",
    "            intersected_edge = current_ntw_edges.loc[(current_ntw_edges['u'] == intersected_u) & \n",
    "                                                     (current_ntw_edges['v'] == intersected_v) &\n",
    "                                                     (current_ntw_edges['key'] == intersected_key)].copy()\n",
    "            intersected_edge.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "        # Extract current_ntw intersected edge's u node \n",
    "        # (Always becomes starting_point_gdf in function edge_clipping when using 'return_all')\n",
    "        u_node = current_ntw_nodes.loc[(current_ntw_nodes['osmid'] == intersected_u)].copy()\n",
    "        u_node.reset_index(inplace=True,drop=True)\n",
    "\n",
    "        # Extract current_ntw intersected edge's v node \n",
    "        # (Always becomes starting_point_gdf in function edge_clipping when using 'return_all')\n",
    "        v_node = current_ntw_nodes.loc[(current_ntw_nodes['osmid'] == intersected_v)].copy()\n",
    "        v_node.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "        # Apply edge_clipping function and assign the corresponding 'u', 'v' or 'key' data.\n",
    "        if intersected_retain_how == 'both':\n",
    "            # Clip edge\n",
    "            split_edge_gdf = edge_clipping(starting_point_gdf = u_node,\n",
    "                                           edge_gdf = intersected_edge,\n",
    "                                           clipping_point_gdf = intersection_node,\n",
    "                                           projected_crs = projected_crs,\n",
    "                                           return_all = True,\n",
    "                                           function_logs = function_logs)\n",
    "            # Assign data\n",
    "            # When return_all=True in function edge_clipping, \n",
    "            # assigns 'starting' to the edge related to the starting_point_gdf\n",
    "            # and 'ending' to edge on the opposite side.\n",
    "            u_idx = split_edge_gdf.relation=='starting'\n",
    "            split_edge_gdf.loc[u_idx,'u'] = intersected_u # We assigned 'u' as starting_point_gdf\n",
    "            split_edge_gdf.loc[u_idx,'v'] = intersection_node_osmid # Intersection\n",
    "            split_edge_gdf.loc[u_idx,'key'] = 0 #Since this 'u' and 'v' relation is new, key=0\n",
    "        \n",
    "            v_idx = split_edge_gdf.relation=='ending'\n",
    "            split_edge_gdf.loc[v_idx,'u'] = intersection_node_osmid # Intersection\n",
    "            split_edge_gdf.loc[v_idx,'v'] = intersected_v # Opposite side\n",
    "            split_edge_gdf.loc[v_idx,'key'] = 0 #Since this 'u' and 'v' relation is new, key=0\n",
    "        \n",
    "        elif intersected_retain_how == 'u':\n",
    "            # Clip edge\n",
    "            split_edge_gdf = edge_clipping(starting_point_gdf = u_node,\n",
    "                                           edge_gdf = intersected_edge,\n",
    "                                           clipping_point_gdf = intersection_node,\n",
    "                                           projected_crs = projected_crs,\n",
    "                                           return_all = False)\n",
    "            # Assign data\n",
    "            split_edge_gdf.loc[0,'u'] = intersected_u\n",
    "            split_edge_gdf.loc[0,'v'] = intersection_node_osmid # Intersection\n",
    "            split_edge_gdf.loc[0,'key'] = 0 #Since this 'u' and 'v' relation is new, key=0\n",
    "            \n",
    "        elif intersected_retain_how == 'v':\n",
    "            # Clip edge\n",
    "            split_edge_gdf = edge_clipping(starting_point_gdf = v_node,\n",
    "                                           edge_gdf = intersected_edge,\n",
    "                                           clipping_point_gdf = intersection_node,\n",
    "                                           projected_crs = projected_crs,\n",
    "                                           return_all = False)\n",
    "            # Assign data\n",
    "            split_edge_gdf.loc[0,'u'] = intersection_node_osmid # Intersection\n",
    "            split_edge_gdf.loc[0,'v'] = intersected_v\n",
    "            split_edge_gdf.loc[0,'key'] = 0 #Since this 'u' and 'v' relation is new, key=0\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error splitting edge with u {intersected_u}, v {intersected_v} and key {intersected_key}.\")\n",
    "            print(\"Make sure to include in gdf intersection_nodes column 'retain_how' with either 'u','v' or 'both'.\")\n",
    "            intended_crash    \n",
    "    \n",
    "        # 3.2 --------------- Register changes on current_ntw\n",
    "        # Set an identifier to make it easier to locate nodes that resulted from an intersection between networks\n",
    "        intersection_node['intersecting'] = 1\n",
    "        # Prepare node for concatenation\n",
    "        intersection_node = intersection_node[['osmid','intersecting','geometry']]\n",
    "        # Add new node\n",
    "        current_ntw_nodes = pd.concat([current_ntw_nodes,intersection_node])\n",
    "        # Reset index\n",
    "        current_ntw_nodes.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "        # Keep all edges except the edge that was split\n",
    "        # (Must remove to avoid duplicating edge's geometries)\n",
    "        current_ntw_edges = current_ntw_edges.loc[~((current_ntw_edges['u'] == intersected_u) &\n",
    "                                                    (current_ntw_edges['v'] == intersected_v) &\n",
    "                                                    (current_ntw_edges['key'] == intersected_key))].copy()\n",
    "        # Prepare edges for concatenation\n",
    "        split_edge_gdf = split_edge_gdf[['u','v','key','geometry']]\n",
    "        # Set an identifier to make it easier to locate edges that were split\n",
    "        split_edge_gdf['intersecting'] = 1\n",
    "        # Add new edge\n",
    "        current_ntw_edges = pd.concat([current_ntw_edges,split_edge_gdf])\n",
    "        # Reset index\n",
    "        current_ntw_edges.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    print(f\"Updated network.\")\n",
    "    updated_ntw_nodes = current_ntw_nodes[['osmid','intersecting','geometry']].copy()\n",
    "    # Set unique identifiers to int\n",
    "    updated_ntw_nodes['osmid'] = updated_ntw_nodes['osmid'].astype('int')\n",
    "    del current_ntw_nodes\n",
    "    updated_ntw_edges = current_ntw_edges[['u','v','key','intersecting','geometry']].copy()\n",
    "    # Set unique identifiers to int\n",
    "    updated_ntw_edges['u'] = updated_ntw_edges['u'].astype('int')\n",
    "    updated_ntw_edges['v'] = updated_ntw_edges['v'].astype('int')\n",
    "    updated_ntw_edges['key'] = updated_ntw_edges['key'].astype('int')\n",
    "    del current_ntw_edges\n",
    "\n",
    "    # After iterating over both networks, return result\n",
    "    return updated_ntw_nodes, updated_ntw_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e37261f-8f2a-42c6-9c7a-046e0e1b2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate intersection_nodes in order to apply function network_intersections_update() for network 01.\n",
    "intersection_nodes_boeing = intersection_nodes[['osmid','u_1','v_1','key_1','geometry']].copy()\n",
    "intersection_nodes_boeing.rename(columns={'u_1':'u',\n",
    "                                          'v_1':'v',\n",
    "                                          'key_1':'key'},inplace=True)\n",
    "# Specify which edge to keep after spliting each edge with the intersection_nodes_boeing\n",
    "# ('both' keeps both sides of split, 'u' or 'v' only keeps the side connected to that node.)\n",
    "# ('both' activates 'return_all' in function edge_clipping())\n",
    "intersection_nodes_boeing['retain_how'] = 'both'\n",
    "\n",
    "# Apply network_intersections_update() function\n",
    "boeing_nodes_i, boeing_edges_i = network_intersections_update(current_ntw_nodes = boeing_nodes,\n",
    "                                                              current_ntw_edges = boeing_edges,\n",
    "                                                              intersection_nodes = intersection_nodes_boeing,\n",
    "                                                              projected_crs = projected_crs,\n",
    "                                                              function_logs = False)\n",
    "\n",
    "# Show\n",
    "print(boeing_nodes_i.shape)\n",
    "boeing_nodes_i.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e979620-d1c4-414b-bad8-2a7598f42a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_edges_i.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891ee48-4395-41e7-b68e-615b72ee4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate intersection_nodes in order to apply function network_intersections_update() for network 02.\n",
    "intersection_nodes_comp = intersection_nodes[['osmid','u_2','v_2','key_2','geometry']].copy()\n",
    "intersection_nodes_comp.rename(columns={'u_2':'u',\n",
    "                                        'v_2':'v',\n",
    "                                        'key_2':'key'},inplace=True)\n",
    "\n",
    "# Specify which edge to keep after spliting each edge with the intersection_nodes_comp\n",
    "# ('both' keeps both sides of split, 'u' or 'v' only keeps the side connected to that node.)\n",
    "# ('both' activates 'return_all' in function edge_clipping())\n",
    "intersection_nodes_comp['retain_how'] = 'both'\n",
    "\n",
    "# Apply network_intersections_update() function\n",
    "comp_nodes_i, comp_edges_i = network_intersections_update(current_ntw_nodes = complementary_uncovered_nodes,\n",
    "                                                          current_ntw_edges = complementary_uncovered_edges,\n",
    "                                                          intersection_nodes = intersection_nodes_comp,\n",
    "                                                          projected_crs = projected_crs,\n",
    "                                                          function_logs=False)\n",
    "\n",
    "# Show\n",
    "print(comp_nodes_i.shape)\n",
    "comp_nodes_i.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fbe7f-4efa-4949-bdf8-86637ecc82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_edges_i.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ebc7f-7c00-4b19-990a-4278d024bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if localsave_02_01:\n",
    "    intersection_nodes.to_file(output_dir + \"part02_step01_ntwsintersection/networks_intersections.gpkg\") \n",
    "    boeing_nodes_i.to_file(output_dir + \"part02_step01_ntwsintersection/intersected_boeing_nodes.gpkg\")\n",
    "    boeing_edges_i.to_file(output_dir + \"part02_step01_ntwsintersection/intersected_boeing_edges.gpkg\")\n",
    "    comp_nodes_i.to_file(output_dir + \"part02_step01_ntwsintersection/intersected_comp_nodes.gpkg\")\n",
    "    comp_edges_i.to_file(output_dir + \"part02_step01_ntwsintersection/intersected_comp_edges.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed726c72-cdd3-46ad-9c23-4c284e3d7fff",
   "metadata": {},
   "source": [
    "## __Part 02 - Step 02 -__ Connection identification between networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e1001-5939-4c08-8202-439f1b84d538",
   "metadata": {},
   "source": [
    "Through identifying the __nearest boeing_nodes_i and nearest edges_boeing_i to each contact_node__, this section creates a gdf that __stablishes the relationships__ between each contact_node (That all derive complementary network) and the node or edge on the boeing network were the connection will be later created.\n",
    "\n",
    "If the connection is to be made __from contact_node to boeing_edge__, it identifies the best intersection point and saves the point with a new osmid in order to split the boeing_edge and __create a new boeing node__ there in an update network process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb9e4d-ab0d-4844-9dc4-cc8712f59db3",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 02 -__ Find nearest boeing_nodes_i and nearest edges_boeing_i to each contact_node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd051128-7a58-479e-bbaa-a7318b7ca67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve contact_nodes\n",
    "print(contact_nodes.shape)\n",
    "contact_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96976026-bd8e-478f-aed9-118f2a30ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate nearest nodes\n",
    "nearest_nodes = gpd.sjoin_nearest(contact_nodes, boeing_nodes_i, distance_col='node_distance')\n",
    "# Merge nearest data\n",
    "contact_nodes_1 = contact_nodes.merge(nearest_nodes[['osmid_right','node_distance']],left_index=True,right_index=True,how='outer')\n",
    "# Save disk space\n",
    "del nearest_nodes\n",
    "\n",
    "# Show\n",
    "print(contact_nodes_1.dtypes)\n",
    "print(contact_nodes_1.shape)\n",
    "contact_nodes_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acc450-5468-4222-bfea-2315cb2c96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest edges\n",
    "nearest_edges = gpd.sjoin_nearest(contact_nodes, boeing_edges_i, distance_col='edge_distance')\n",
    "# It is unlikely that two edges are exacly at the same distance,\n",
    "# unless they are at the same distance because they meet at a node.\n",
    "# Keep the first occurance\n",
    "nearest_edges = nearest_edges.drop_duplicates(subset='osmid')\n",
    "\n",
    "# Merge nearest data\n",
    "contact_nodes_2 = contact_nodes_1.merge(nearest_edges[['u','v','key','edge_distance']],left_index=True,right_index=True,how='outer')\n",
    "# Save disk space\n",
    "del nearest_edges\n",
    "\n",
    "# Show\n",
    "print(contact_nodes_2.dtypes)\n",
    "print(contact_nodes_2.shape)\n",
    "contact_nodes_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89ff71-874e-42d2-8954-418efd79ba27",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 02 -__ Stablish best relation between networks for each contact_node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa7a51-6d32-4dbc-9046-210b4c62583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find individual relations between contact_nodes_2 (renamed as connecting_nodes) and network 01 (boeing).\n",
    "# (Produces \"connected_nodes\" gdf, where these relations are saved, and also\n",
    "# produces \"intersection_nodes_2\" gdf, which stores new nodes and edges to be split on network 01)\n",
    "\n",
    "# Rename gdfs to keep original (Used during Dev)\n",
    "ntw_01_nodes = boeing_nodes_i.copy()\n",
    "ntw_01_edges = boeing_edges_i.copy()\n",
    "ntw_02_nodes = comp_nodes_i.copy()\n",
    "ntw_02_edges = comp_edges_i.copy()\n",
    "connecting_nodes = contact_nodes_2.copy()\n",
    "\n",
    "# Reset produced osmids\n",
    "previously_produced = 0\n",
    "\n",
    "# List of nodes created by intersecting both networks\n",
    "intersecting_idx = ntw_01_nodes.intersecting==1\n",
    "intersecting_osmids = list(ntw_01_nodes.loc[intersecting_idx].osmid.unique())\n",
    "\n",
    "# GeoDataFrame that will store the connections between networks\n",
    "connected_nodes = pd.DataFrame()\n",
    "\n",
    "# Second round of intersections to be created on network_01 (after this process)\n",
    "intersection_nodes_2 = gpd.GeoDataFrame()\n",
    "new_node_idx = 0 #idx of the gdf\n",
    "\n",
    "extended_logs = False\n",
    "\n",
    "i = 0\n",
    "# Iterate over each connecting_node\n",
    "for idx, node in connecting_nodes.iterrows():\n",
    "\n",
    "    # Extract current connecting_node's data\n",
    "    # Current connecting_node data\n",
    "    cn_osmid = node.osmid \n",
    "    cn_geometry = node.geometry\n",
    "    # nearest_node data\n",
    "    cn_nearest_osmid = node.osmid_right\n",
    "    cn_node_distance = node.node_distance \n",
    "    #nearest_edge data\n",
    "    cn_nearest_u = node.u\n",
    "    cn_nearest_v = node.v\n",
    "    cn_nearest_key = node.key\n",
    "    cn_edge_distance = node.edge_distance\n",
    "\n",
    "    # Development checks -----------------------------------\n",
    "    #osmid_checks = [1089,1090]\n",
    "    #if cn_osmid not in osmid_checks:\n",
    "    #    continue\n",
    "    #else:\n",
    "    #    print(cn_osmid)\n",
    "    # Development checks -----------------------------------\n",
    "    \n",
    "    # Register current connecting_node\n",
    "    connected_nodes.loc[i,'connecting_ntw02_osmid'] = cn_osmid\n",
    "    \n",
    "    # 1.0 --------------- CASE 1: Close intersection\n",
    "    # ------------------- Analyse the edges that connect to the current connecting_node.\n",
    "    # ------------------- If any given edge connects to the base network through an existing network intersection\n",
    "    # ------------------- in a distance of 20 meters or less, assume there's already an existing connection nerby.\n",
    "    # ------------------- --> ignore conecting_node (continue).\n",
    "\n",
    "    # Identify the edges that connect to the current connecting_node\n",
    "    connecting_node_edges = ntw_02_edges.loc[(ntw_02_edges.u==cn_osmid) | (ntw_02_edges.v==cn_osmid)].copy()\n",
    "    # Extract the list of nodes ('u' and 'v') that those edges connect to\n",
    "    connecting_node_osmids = set(list(connecting_node_edges.u.unique()) + list(connecting_node_edges.v.unique()))\n",
    "    connecting_node_osmids.remove(cn_osmid) #Remove itself\n",
    "    # Filter for opposite_osmids that are also an intersecting_osmid\n",
    "    # (Nodes created when intersecting both networks)\n",
    "    opposite_intersecting_osmid = [osmid for osmid in connecting_node_osmids if osmid in intersecting_osmids]\n",
    "    # If they exist:\n",
    "    if len(opposite_intersecting_osmid)>0:\n",
    "        existing_connection = False\n",
    "        # Analyse the length of the edges connecting to the opposite_intersecting_osmids. \n",
    "        # For any edge connecting to an intersecting_node, if the length of that edge is less than 20 meters, \n",
    "        # register that there's already an existing connection nerby.\n",
    "        edges_to_analyse = connecting_node_edges.loc[(connecting_node_edges.u.isin(opposite_intersecting_osmid)) | \n",
    "                                                     (connecting_node_edges.v.isin(opposite_intersecting_osmid))].copy()\n",
    "        edges_to_analyse['length'] = edges_to_analyse.length\n",
    "        for edge_length in list(edges_to_analyse.length.unique()):\n",
    "            if edge_length < 20:\n",
    "                existing_connection = True\n",
    "                break\n",
    "        # If the process found an existing connection, skip current connecting_node\n",
    "        if existing_connection == True:\n",
    "            connected_nodes.loc[i,'connection_type'] = 'existing'\n",
    "            i+=1\n",
    "            if extended_logs:\n",
    "                print(f\"CASE 1: Connecting node {cn_osmid} already connects to an existing intersection in less than 20 meters.\")\n",
    "            continue # Next connecting_node\n",
    "    \n",
    "    # 2.0 --------------- CASE 2: Distance analysis\n",
    "    # ------------------- If there's no existing intersection nerby, register connection to be created.\n",
    "    \n",
    "    # 2.1 --------------- New nodes check\n",
    "    # ------------------- The for loop iterating over connecting_nodes has a code section where new nodes can be created.\n",
    "    # ------------------- This happens when a connection between a conecting_node and a ntw_01_edge is stablished.\n",
    "    # ------------------- New nodes can also serve as a connection with between networks\n",
    "    # ------------------- Considering them prevents multiple connections being created when an existing can be used.\n",
    "\n",
    "    # IN CASE OF OTHER APPROACH NEEDED STARTS\n",
    "    # If the case appears, where connecting_node could have had a better connection with a\n",
    "    # new_node, but it was not considered because the new_node was not located in the nearest edge,\n",
    "    # consider editing this part of the code so that the check for new nodes is made through a buffer.\n",
    "    # 1. Find if there are any new nodes in a __x__ meter buffer.\n",
    "    # 2. If there are, measure distance to all of them and choose the min distance\n",
    "    # 3. Compare min distance to current distance to nearest node\n",
    "    # 4. If less, assign new_node as new nearest node.\n",
    "    # IN CASE OF OTHER APPROACH NEEDED ENDS\n",
    "    \n",
    "    # nearest edge unique id\n",
    "    cn_edge_id = str(cn_nearest_u)+str(cn_nearest_v)+str(cn_nearest_key)\n",
    "\n",
    "    # If there are already new_nodes registered:\n",
    "    if new_node_idx > 0:\n",
    "\n",
    "        # If this edge was already registered as to-be-edited by a new node created on this section of code,\n",
    "        # check if the new node's distance is lesser than the current nearest node's distance. If so, update.\n",
    "        intersected_edges = list(intersection_nodes_2['edge_id'].unique())\n",
    "        if cn_edge_id in intersected_edges:\n",
    "            # Obtain current conecting_node's coordinates\n",
    "            conecting_nodes_coords = cn_geometry.coords[0]\n",
    "            \n",
    "            # Analyse distance to each newly created node (Created over the nearest edge to current connecting_node)\n",
    "            registered_nodes = intersection_nodes_2.loc[intersection_nodes_2['edge_id'] == cn_edge_id].copy()\n",
    "            registered_nodes.reset_index(inplace=True,drop=True)\n",
    "            for node_idx in range(len(registered_nodes)):\n",
    "                # Obtain registered node's coords\n",
    "                registered_node = registered_nodes.iloc[node_idx]\n",
    "                registered_node_coords = registered_node.geometry.coords[0]\n",
    "                # Calculate distance between nodes\n",
    "                new_node_distance = distance_between_points(conecting_nodes_coords, registered_node_coords)\n",
    "                # If new_node_distance is less than distance to current nearest node, update nearest node data\n",
    "                if new_node_distance < cn_node_distance:\n",
    "                    cn_nearest_osmid = registered_node.osmid\n",
    "                    cn_node_distance = new_node_distance\n",
    "    \n",
    "    # 2.2 --------------- CASE 2a: Close node connection\n",
    "    # If distance to nearest node is less than 5 meters, register that connection\n",
    "    if cn_node_distance<5:\n",
    "        # Connection registration\n",
    "        connected_nodes.loc[i,'connection_type'] = 'node'\n",
    "        connected_nodes.loc[i,'connection_ntw01_osmid'] = cn_nearest_osmid\n",
    "        i+=1\n",
    "        if extended_logs:\n",
    "            print(f\"CASE 2a: Connecting node {cn_osmid} connects to a node in less than 5 meters.\")\n",
    "        continue # Next connecting_node\n",
    "\n",
    "    # If distance to nearest node is greater than 5 meters, analyse distance to edge\n",
    "    elif cn_node_distance>5:\n",
    "        \n",
    "        # 2.3 --------------- CASE 2a: Edge connection\n",
    "        # If the nearest_edge is closer than the (nearest_node-5 meters)\n",
    "        # (Meaning, if the nearest_edge is closer even when we give 5 meter preference to the node over the edge) \n",
    "        # --> Create and register join with nearest_edge.\n",
    "        node_distance_pref = cn_node_distance-5\n",
    "        if cn_edge_distance < node_distance_pref:\n",
    "\n",
    "            # 2.3.a) ------------ Create new node\n",
    "            # Extract the nearest edge's geometry (LineString)\n",
    "            nearest_edge = ntw_01_edges.loc[(ntw_01_edges.u==cn_nearest_u) & \n",
    "                                            (ntw_01_edges.v==cn_nearest_v) &\n",
    "                                            (ntw_01_edges.key==cn_nearest_key)].copy()\n",
    "            nearest_edge.reset_index(inplace=True,drop=True)\n",
    "            edge_geom = nearest_edge['geometry'].unique()[0]\n",
    "            # Project current connecting_node into the edge's geometry\n",
    "            projected_point = edge_geom.interpolate(edge_geom.project(cn_geometry))\n",
    "            # Produce unique osmid\n",
    "            produced_osmid = produce_osmid(ntw_01_nodes, ntw_02_nodes, previously_produced)\n",
    "            # Since ntw_01_nodes and ntw_02_nodes are not being updated, next time try with next possible osmid\n",
    "            previously_produced = produced_osmid+1\n",
    "            # Create new node on projected point\n",
    "            new_node = gpd.GeoDataFrame()\n",
    "            new_node.loc[0,'osmid'] = produced_osmid\n",
    "            new_node.loc[0,'geometry'] = projected_point\n",
    "            new_node = new_node.set_crs(projected_crs)\n",
    "            \n",
    "            # 2.3.b) ------------ Register new_node and edge to be split by it.\n",
    "            # ------------------- Will be used in function network_intersections_update()\n",
    "            # Node that is the intersection (clipping point)\n",
    "            intersection_nodes_2.loc[new_node_idx,'osmid'] = produced_osmid\n",
    "            intersection_nodes_2.loc[new_node_idx,'geometry'] = projected_point\n",
    "            # Edge that is intersected\n",
    "            intersection_nodes_2.loc[new_node_idx,'u'] = cn_nearest_u\n",
    "            intersection_nodes_2.loc[new_node_idx,'v'] = cn_nearest_v\n",
    "            intersection_nodes_2.loc[new_node_idx,'key'] = cn_nearest_key\n",
    "            # Edge id that is intersected (for 2.1 -- New nodes check)\n",
    "            intersection_nodes_2.loc[new_node_idx,'edge_id'] = cn_edge_id\n",
    "            \n",
    "            # Register crs (one time)\n",
    "            if new_node_idx==0:\n",
    "                intersection_nodes_2 = intersection_nodes_2.set_crs(projected_crs)\n",
    "            # Next idx\n",
    "            new_node_idx+=1\n",
    "\n",
    "            # 2.3.c) ------------ Connection registration\n",
    "            connected_nodes.loc[i,'connection_type'] = 'node'\n",
    "            connected_nodes.loc[i,'connection_ntw01_osmid'] = produced_osmid\n",
    "            i+=1\n",
    "            if extended_logs:\n",
    "                print(f\"CASE 2b: Connecting node {cn_osmid} produced a new node in an edge of the network 01.\")\n",
    "            continue # Next connecting_node\n",
    "\n",
    "        # 2.4 --------------- CASE 2c: Node connection\n",
    "        # If the (nearest_node-5 meters) is closer than the nearest_edge\n",
    "        # --> Register node connection\n",
    "        else:\n",
    "            # Connection registration\n",
    "            connected_nodes.loc[i,'connection_type'] = 'node'\n",
    "            connected_nodes.loc[i,'connection_ntw01_osmid'] = cn_nearest_osmid\n",
    "            i+=1\n",
    "            if extended_logs:\n",
    "                print(f\"CASE 2c: Connecting node {cn_osmid} connects to a node in less than 5 meters.\")\n",
    "            continue # Next connecting_node\n",
    "\n",
    "# Set unique identifiers to int\n",
    "connected_nodes['connecting_ntw02_osmid'] = connected_nodes['connecting_ntw02_osmid'].astype('int')\n",
    "connected_nodes['connection_ntw01_osmid'].fillna(value=0, inplace=True)# Existing connections do not register osmid, set to 0\n",
    "connected_nodes['connection_ntw01_osmid'] = connected_nodes['connection_ntw01_osmid'].astype('int')\n",
    "# Set unique identifiers to int\n",
    "intersection_nodes_2['osmid'] = intersection_nodes_2['osmid'].astype('int')\n",
    "intersection_nodes_2['u'] = intersection_nodes_2['u'].astype('int')\n",
    "intersection_nodes_2['v'] = intersection_nodes_2['v'].astype('int')\n",
    "intersection_nodes_2['key'] = intersection_nodes_2['key'].astype('int')\n",
    "\n",
    "# Show\n",
    "print(connected_nodes.dtypes)\n",
    "print(connected_nodes.shape)\n",
    "connected_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8beea-f284-4128-a897-cf7f4f0077a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show gdf that will be used to update network 01 (Boeing)\n",
    "print(intersection_nodes_2.dtypes)\n",
    "print(intersection_nodes_2.shape)\n",
    "intersection_nodes_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c91f9fe-8b78-4705-ba15-06a80a3048b6",
   "metadata": {},
   "source": [
    "## __Part 2 - Step 03 -__ Network concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632a642-f59b-4165-93b9-6351d47abc1b",
   "metadata": {},
   "source": [
    "This step __updates the boeing network__ (In order to include the new nodes created in order to join a contact_node and a boeing edge) and __joins (concatenates) both network's nodes and edges__ into a single gdf each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c78a36-02e0-47ec-9049-59f9d0eca540",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 03 -__ Re-update the network 01 (Boeing network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78554f6c-b8a8-46eb-9702-dea78be558bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply network_intersections_update() function \n",
    "\n",
    "# Specify which edge to keep after spliting each edge with the intersection_nodes_2\n",
    "# ('both' keeps both sides of split, 'u' or 'v' only keeps the side connected to that node.)\n",
    "# ('both' activates 'return_all' in function edge_clipping())\n",
    "intersection_nodes_2['retain_how'] = 'both'\n",
    "\n",
    "# (Second round of intersections, derived from new nodes created from network_02 to edges on network_01)\n",
    "boeing_nodes_i2, boeing_edges_i2 = network_intersections_update(current_ntw_nodes = boeing_nodes_i,\n",
    "                                                                current_ntw_edges = boeing_edges_i,\n",
    "                                                                intersection_nodes = intersection_nodes_2,\n",
    "                                                                projected_crs = projected_crs)\n",
    "\n",
    "# Nodes marked as \"intersecting\" on this round are nodes created specifically in order to connect the\n",
    "# network_02 to an edge on network_01. Distinguish them (For GIS visualization)\n",
    "boeing_nodes_i2.rename(columns={'intersecting':'ntw_join'},inplace=True)\n",
    "\n",
    "# Show\n",
    "print(boeing_nodes_i2.dtypes)\n",
    "print(boeing_nodes_i2.shape)\n",
    "boeing_nodes_i2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e31817-7ebb-472c-a39c-dbf31ac67c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_nodes_i2.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3832e0-42b5-4625-8e24-687fa3610a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detail\n",
    "print(boeing_edges_i2.dtypes)\n",
    "boeing_edges_i2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dc260-f077-4cf6-82d5-5e9413a49612",
   "metadata": {},
   "outputs": [],
   "source": [
    "boeing_edges_i2.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1096a-301b-475f-b140-929d8f0e30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "print(comp_nodes_i.shape)\n",
    "comp_nodes_i.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285af67-eed3-4fa5-88f0-3e45935a5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "print(comp_edges_i.shape)\n",
    "comp_edges_i.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218c80c-6aa5-4b40-a12e-437d259186f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_nodes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9f990-4b00-41b3-aceb-309491575c98",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 03 -__ Concatenate both networks (Not yet physically connected by edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0c48c-9570-4716-ade0-240dcde4b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate nodes\n",
    "\n",
    "# Prepare data for concatenation\n",
    "ntw_01_nodes_prep = boeing_nodes_i2[['osmid','ntw_join','geometry']].copy()\n",
    "ntw_02_nodes_prep = comp_nodes_i[['osmid','geometry']].copy()\n",
    "\n",
    "# Add missing 'ntw_join' col to ntw_02_nodes_prep\n",
    "ntw_02_nodes_prep['ntw_join'] = 0\n",
    "\n",
    "# Differenciate networks\n",
    "ntw_01_nodes_prep['ntw_origin'] = 'ntw_01'\n",
    "ntw_02_nodes_prep['ntw_origin'] = 'ntw_02'\n",
    "\n",
    "# Concatenate nodes\n",
    "concatenated_nodes = pd.concat([ntw_01_nodes_prep,ntw_02_nodes_prep])\n",
    "node_count_1 = len(joined_nodes)\n",
    "\n",
    "# Drop duplicated nodes\n",
    "concatenated_nodes.drop_duplicates(subset=['osmid','geometry'],inplace=True)\n",
    "node_count_2 = len(concatenated_nodes)\n",
    "print(f\"Dropped {node_count_1-node_count_2} nodes duplicated when intersecting networks.\")\n",
    "\n",
    "# Reset index\n",
    "concatenated_nodes.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# Show\n",
    "print(concatenated_nodes.dtypes)\n",
    "print(concatenated_nodes.shape)\n",
    "concatenated_nodes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4827429d-d84d-4bdc-a921-1adc035f266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate edges\n",
    "\n",
    "# Prepare data for concatenation\n",
    "ntw_01_edges_prep = boeing_edges_i2[['u','v','key','geometry']].copy()\n",
    "ntw_02_edges_prep = comp_edges_i[['u','v','key','geometry']].copy()\n",
    "\n",
    "# Add missing 'ntw_join' col to both gdfs\n",
    "ntw_01_edges_prep['ntw_join'] = 0\n",
    "ntw_02_edges_prep['ntw_join'] = 0\n",
    "\n",
    "# Differenciate networks\n",
    "ntw_01_edges_prep['ntw_origin'] = 'ntw_01'\n",
    "ntw_02_edges_prep['ntw_origin'] = 'ntw_02'\n",
    "\n",
    "# Concatenate edges\n",
    "concatenated_edges = pd.concat([ntw_01_edges_prep,ntw_02_edges_prep])\n",
    "edge_count_1 = len(joined_edges)\n",
    "\n",
    "# Drop duplicated edges (There should be 0)\n",
    "concatenated_edges.drop_duplicates(subset=['u','v','key','geometry'],inplace=True)\n",
    "edge_count_2 = len(concatenated_edges)\n",
    "print(f\"There should be 0 duplicated edges. Dropped {edge_count_1-edge_count_2}.\")\n",
    "\n",
    "# Reset index\n",
    "concatenated_edges.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# Show\n",
    "print(concatenated_edges.dtypes)\n",
    "print(concatenated_edges.shape)\n",
    "concatenated_edges.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ed308-fcbe-4ac9-b6a4-75a6e13c3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "if localsave_02_03:\n",
    "    concatenated_nodes.to_file(output_dir + \"part02_step03_ntwsconcat/concatenated_nodes.gpkg\")\n",
    "    concatenated_edges.to_file(output_dir + \"part02_step03_ntwsconcat/concatenated_edges.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae91405-93f7-47b7-9d73-092ae86bf4ff",
   "metadata": {},
   "source": [
    "## __Part 02 - Step 04 -__ Connect networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7d6f4-0ad6-4d37-956b-1b0c5ef32481",
   "metadata": {},
   "source": [
    "Using the connected_nodes df (Created in Part 02 - Step 02), which stablishes the relations between conection_nodes (from network 02, tessellations) and nodes in network 01 (boeing), in this step __new edges that connect both networks are drawn.__\n",
    "\n",
    "After that __undesired intersections__ (Which occur when the drawn edge crosses another edge in its way to connect network 01 and 02) __are fixed__ according to its nature (CASE A, CASE B or CASE C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a5e8e-f8e0-49db-936f-0965f97a821e",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 04 -__ Draw new edges and identify undesired intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe654c8e-8650-473c-8a57-7a9790332b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset previously_produced osmids\n",
    "previously_produced = 0\n",
    "\n",
    "# Store the fixes to be performed (Used to fix undesired intersections)\n",
    "intersection_nodes_3 = gpd.GeoDataFrame()\n",
    "fix_idx = 0\n",
    "\n",
    "# Store the osmids and edge_ids created to join both networks (To identify them after the process)\n",
    "all_join_osmids = []\n",
    "all_join_edgeids = []\n",
    "\n",
    "# The first connected_node (from df with node relations) will explore undesired_intersections with a copy of concatenated_edges.\n",
    "# The copy is named 'joined_edges_concat', and after the first iteration it will store all edges and all new drawn edges.\n",
    "# This way the subsequent connected_nodes will explore undesired_intersections with the updated version of concatenated_edges.\n",
    "# And can identify if a drawn edge also intersects another drawn edge.\n",
    "\n",
    "# Create joined_edges_concat with a column for edge_id\n",
    "joined_edges_concat = create_unique_edge_id(concatenated_edges)\n",
    "\n",
    "# Iterate over each relation stablished\n",
    "for idx, connected_node in connected_nodes.iterrows():\n",
    "\n",
    "    # Development checks -----------------------------------\n",
    "    current_osmid = connected_node.connecting_ntw02_osmid\n",
    "    #osmid_checks = [1089,1090,1086,999,1027,229]\n",
    "    #if current_osmid not in osmid_checks:\n",
    "    #    continue\n",
    "    #else:\n",
    "    #    print(current_osmid)\n",
    "    # Development checks -----------------------------------\n",
    "    \n",
    "    # Extract relation's data\n",
    "    # 'connection' refers to the data from network 01,\n",
    "    # while 'connecting' referes to data from network 02.\n",
    "    # Network 02 is ---connecting--> to network 01. \n",
    "    connection_ntw01_osmid = connected_node.connection_ntw01_osmid\n",
    "    connection_type = connected_node.connection_type\n",
    "    connecting_ntw02_osmid = connected_node.connecting_ntw02_osmid\n",
    "\n",
    "    # If the connection for the current connecting_node was identified to already exist (Part 02 - Step 02)\n",
    "    # skip (continue)\n",
    "    if connection_type == 'existing':\n",
    "        continue # Next nodes_relation\n",
    "\n",
    "    # Identify the node's coordinates on ntw_01 that's going to get connected to the node on ntw_02\n",
    "    connection_node_gdf = concatenated_nodes.loc[concatenated_nodes.osmid==connection_ntw01_osmid].copy()\n",
    "    connection_node_geom = connection_node_gdf.geometry.unique()[0]\n",
    "    connection_node_coords = connection_node_geom.coords[0]\n",
    "    \n",
    "    # Identify the node's coordinates on ntw_02 that's going to get connected to the node on ntw_01\n",
    "    connecting_node_gdf = concatenated_nodes.loc[concatenated_nodes.osmid==connecting_ntw02_osmid].copy()\n",
    "    connecting_node_geom = connecting_node_gdf.geometry.unique()[0]\n",
    "    connecting_node_coords = connecting_node_geom.coords[0]\n",
    "\n",
    "    # Create LineString between connection_node and connecting_node\n",
    "    line_geom = LineString([[connection_node_coords[0],connection_node_coords[1]],[connecting_node_coords[0],connecting_node_coords[1]]])\n",
    "    \n",
    "    # Store new LineString to concat to joined_edges_concat and to analyse undesired intersections\n",
    "    new_edge = gpd.GeoDataFrame()\n",
    "    new_edge.loc[0,'u'] = connecting_ntw02_osmid\n",
    "    new_edge.loc[0,'v'] = connection_ntw01_osmid\n",
    "    new_edge.loc[0,'key'] = 0\n",
    "    new_edge.loc[0,'geometry'] = line_geom\n",
    "    new_edge.loc[0,'ntw_join'] = 1\n",
    "    new_edge.loc[0,'ntw_origin'] = 'ntw_join'\n",
    "    new_edge = new_edge.set_crs(projected_crs)\n",
    "    \n",
    "    # Create unique edge_id for new_edge (requires input ID cols as int)\n",
    "    new_edge['u'] = new_edge['u'].astype('int')\n",
    "    new_edge['v'] = new_edge['v'].astype('int')\n",
    "    new_edge['key'] = new_edge['key'].astype('int')\n",
    "    new_edge = create_unique_edge_id(new_edge)\n",
    "\n",
    "    # Store the edge_ids created to join both networks (To identify them after the process)\n",
    "    join_edge_ids = list(new_edge.edge_id.unique())\n",
    "    all_join_edgeids = all_join_edgeids + join_edge_ids\n",
    "    \n",
    "    # Find all intersections that the new edge creates on the current network edges\n",
    "    # (Will search for undesired intersections)\n",
    "    produced_intersections = joined_edges_concat.overlay(new_edge,how='intersection',keep_geom_type=False)\n",
    "    \n",
    "    # Concatenate new_edge to joined_edges_concat gdf \n",
    "    # (It is after .overlay(), else the LineString intersects with itself)\n",
    "    joined_edges_concat = pd.concat([joined_edges_concat,new_edge])\n",
    "    joined_edges_concat.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    # UNDESIRED INTERSECTIONS ANALYSIS    \n",
    "    # Explode the produced_intersections\n",
    "    # (If the new edge intersected the same edge twice or more, it produces MultiPoints)\n",
    "    produced_intersections = produced_intersections.explode(index_parts=False)\n",
    "    produced_intersections.reset_index(inplace=True,drop=True)\n",
    "    # Remove from the produced_intersections the nodes that are currently being joined\n",
    "    # (Obviously, the line that connects them intersects with them)\n",
    "    joined_nodes_lst = [connection_node_geom,connecting_node_geom]\n",
    "    produced_intersections = produced_intersections.loc[~produced_intersections['geometry'].isin(joined_nodes_lst)].copy()\n",
    "    \n",
    "    # If there are any intersections remaining, they are undesired intersections.\n",
    "    # (Meaning, the drawn line is intersecting with other lines in an undesired way)\n",
    "    if len(produced_intersections)>0:\n",
    "        # Rename gdf as \"undesired_intersections\"\n",
    "        undesired_intersections = produced_intersections.copy()\n",
    "        undesired_intersections.reset_index(inplace=True,drop=True)\n",
    "        del produced_intersections\n",
    "\n",
    "        # Rename columns to distinguish network origin\n",
    "        # (Overlay produced _1 for joined_edges_concat data and _2 for new_edge data)\n",
    "        undesired_intersections.rename(columns={'edge_id_1':'intersected_edge_id',\n",
    "                                                'edge_id_2':'drawn_edge_id'},inplace=True)\n",
    "        \n",
    "        # Load network 01 edges related to the connection\n",
    "        # (Network 01 edges that are related to the current connection_node)\n",
    "        connection_idx = ((joined_edges_concat.u==connection_ntw01_osmid)|(joined_edges_concat.v==connection_ntw01_osmid)) & (joined_edges_concat.ntw_origin=='ntw_01')\n",
    "        related_ntw01_edges = joined_edges_concat.loc[connection_idx].copy()\n",
    "        related_ntw01_edges_ids = list(related_ntw01_edges['edge_id'].unique())\n",
    "        \n",
    "        # Load network 02 edges related to the connection\n",
    "        # (Network 02 edges that are related to the current connecting_node)\n",
    "        connecting_idx = ((joined_edges_concat.u==connecting_ntw02_osmid)|(joined_edges_concat.v==connecting_ntw02_osmid)) & (joined_edges_concat.ntw_origin=='ntw_02')\n",
    "        related_ntw02_edges = joined_edges_concat.loc[connecting_idx].copy()\n",
    "        related_ntw02_edges_ids = list(related_ntw02_edges['edge_id'].unique())\n",
    "        \n",
    "        # Iterate over unexpected_intersections:\n",
    "        for idx,intersection in undesired_intersections.iterrows():\n",
    "    \n",
    "            # Extract intersection's data\n",
    "            # Edge that was intersected\n",
    "            intersected_u = int(intersection.u_1)\n",
    "            intersected_v = int(intersection.v_1)\n",
    "            intersected_key = intersection.key_1\n",
    "            intersected_edge_id = intersection.intersected_edge_id\n",
    "            # Drawn edge that is intersecting\n",
    "            drawn_edge_u = int(intersection.u_2)\n",
    "            drawn_edge_v = int(intersection.v_2)\n",
    "            drawn_edge_key = intersection.key_2\n",
    "            drawn_edge_id = intersection.drawn_edge_id\n",
    "\n",
    "            # The intersection (In any studied case) will become a new node.\n",
    "            # Extract its geometry and produce a unique osmid\n",
    "            intersectionpoint_geom = intersection.geometry\n",
    "            produced_osmid = produce_osmid(concatenated_nodes, concatenated_nodes, previously_produced)\n",
    "            # Since concatenated_nodes are not being updated, next time try with next possible osmid\n",
    "            previously_produced = produced_osmid+1 \n",
    "\n",
    "            # Store the osmids created to join both networks (To identify them after the process)\n",
    "            all_join_osmids.append(produced_osmid)\n",
    "\n",
    "            if intersected_edge_id in related_ntw01_edges_ids:\n",
    "                # CASE A: The new edge intersects network 01 at an edge comming out of the node \n",
    "                #         TO where the connection was being performed.\n",
    "                # --> CASE A will draw the connection from the connecting_node on ntw02 to the intersection point ONLY.\n",
    "                # -->        because thats were there's already a known connection with ntw01.\n",
    "                # -->        ntw01 edge gets split to add a new node, keeping both sides of the edge.\n",
    "                # -->        drawn edge gets split at the intersection, keeping one side of the edge.\n",
    "                case = 'CASE A'\n",
    "            elif intersected_edge_id in related_ntw02_edges_ids:\n",
    "                # CASE B: The new edge intersects network 02 at an edge comming out of the node \n",
    "                #         FROM where the connection was being performed.\n",
    "                # --> CASE B will draw the connection from the intersection point to the connection_node on ntw_01 ONLY.\n",
    "                # -->        because the rest (from intersection point to ntw02) is redundant.\n",
    "                # -->        ntw02 edge gets split to add a new node, keeping both sides of the edge.\n",
    "                # -->        drawn edge gets split at the intersection, keeping one side of the edge.\n",
    "                case = 'CASE B'\n",
    "            else:\n",
    "                # CASE C: The new edge intersects with either network 01 or network 02 at an UNRELATED edge.\n",
    "                #         (Or at a related ntw02 edge, but one that shouldn't be cut)\n",
    "                # --> CASE C will draw only create a new node on the intersection and split the edges, \n",
    "                # -->        keeping both sides on both split edges.\n",
    "                # -->        ntw01 or ntw02 edge gets split to add a new node, keeping both sides of the edge.\n",
    "                # -->        drawn edge gets split at the intersection, keeping both sides of the edge.\n",
    "                case = 'CASE C'\n",
    "    \n",
    "            # n.n --------------- CASE A\n",
    "            if case == 'CASE A':\n",
    "                print(f\"CASE A: New edge from connecting node {connecting_ntw02_osmid} intersects network 01 at an edge comming out of the node TO where the connection was being performed.\")\n",
    "    \n",
    "                # Register how the intersected edge (from network 01) will be clipped\n",
    "                # (In the intersection, keeping both ends)\n",
    "                intersection_nodes_3.loc[fix_idx,'osmid'] = produced_osmid\n",
    "                intersection_nodes_3.loc[fix_idx,'geometry'] = intersectionpoint_geom\n",
    "                intersection_nodes_3.loc[fix_idx,'u'] = intersected_u\n",
    "                intersection_nodes_3.loc[fix_idx,'v'] =  intersected_v\n",
    "                intersection_nodes_3.loc[fix_idx,'key'] = intersected_key\n",
    "                intersection_nodes_3.loc[fix_idx,'retain_how'] = 'both' #Sets retain_all=True\n",
    "                intersection_nodes_3.loc[fix_idx,'edge_origin'] = 'ntw_01' #Helps divide network_intersections_update() process\n",
    "                # Register crs (one time)\n",
    "                if fix_idx==0:\n",
    "                    intersection_nodes_3 = intersection_nodes_3.set_crs(projected_crs)\n",
    "                \n",
    "                fix_idx+=1\n",
    "            \n",
    "                # Register how the drawn edge will be clipped\n",
    "                # (From the connecting_ntw02_node to the intersection, keeping just that segment)\n",
    "                intersection_nodes_3.loc[fix_idx,'osmid'] = produced_osmid\n",
    "                intersection_nodes_3.loc[fix_idx,'geometry'] = intersectionpoint_geom\n",
    "                intersection_nodes_3.loc[fix_idx,'u'] = drawn_edge_u # u is from ntw02\n",
    "                intersection_nodes_3.loc[fix_idx,'v'] = drawn_edge_v # v is from ntw01\n",
    "                intersection_nodes_3.loc[fix_idx,'key'] = drawn_edge_key\n",
    "                intersection_nodes_3.loc[fix_idx,'retain_how'] = 'u' #Sets retain_all=False, states which part to keep (u, comming from ntw02)\n",
    "                intersection_nodes_3.loc[fix_idx,'edge_origin'] = 'ntw_join' #Helps divide network_intersections_update() process\n",
    "                \n",
    "                fix_idx+=1\n",
    "    \n",
    "            # CASE B\n",
    "            elif case == 'CASE B':\n",
    "                print(f\"CASE B: New edge from connecting node {connecting_ntw02_osmid} intersects network 02 at an edge comming out of the node FROM where the connection was being performed.\")\n",
    "                \n",
    "                # Register how the intersected edge (from network 02) will be clipped\n",
    "                # (In the intersection, keeping both ends)\n",
    "                intersection_nodes_3.loc[fix_idx,'osmid'] = produced_osmid\n",
    "                intersection_nodes_3.loc[fix_idx,'geometry'] = intersectionpoint_geom\n",
    "                intersection_nodes_3.loc[fix_idx,'u'] = intersected_u\n",
    "                intersection_nodes_3.loc[fix_idx,'v'] =  intersected_v\n",
    "                intersection_nodes_3.loc[fix_idx,'key'] = intersected_key\n",
    "                intersection_nodes_3.loc[fix_idx,'edge_origin'] = 'ntw_02' #Helps divide network_intersections_update() process\n",
    "                intersection_nodes_3.loc[fix_idx,'retain_how'] = 'both' #Sets retain_all=True\n",
    "                # Register crs (one time)\n",
    "                if fix_idx==0:\n",
    "                    intersection_nodes_3 = intersection_nodes_3.set_crs(projected_crs)\n",
    "                \n",
    "                fix_idx+=1\n",
    "                \n",
    "                # Register how the drawn edge will be clipped\n",
    "                # (From the connection_ntw01_node to the intersection, keeping just that segment)\n",
    "                intersection_nodes_3.loc[fix_idx,'osmid'] = produced_osmid\n",
    "                intersection_nodes_3.loc[fix_idx,'geometry'] = intersectionpoint_geom\n",
    "                intersection_nodes_3.loc[fix_idx,'u'] = drawn_edge_u # u is from ntw02\n",
    "                intersection_nodes_3.loc[fix_idx,'v'] = drawn_edge_v # v is from ntw01\n",
    "                intersection_nodes_3.loc[fix_idx,'key'] = drawn_edge_key\n",
    "                intersection_nodes_3.loc[fix_idx,'edge_origin'] = 'ntw_join' #Helps divide network_intersections_update() process\n",
    "                # Keep starting point from the connection_ntw01_osmid\n",
    "                if drawn_edge_u == connection_ntw01_osmid:\n",
    "                    intersection_nodes_3.loc[fix_idx,'retain_how'] = 'u' #Sets retain_all=False, states which part to keep\n",
    "                elif drawn_edge_v ==connection_ntw01_osmid:\n",
    "                    intersection_nodes_3.loc[fix_idx,'retain_how'] = 'v' #Sets retain_all=False, states which part to keep\n",
    "                else:\n",
    "                    intented_crash\n",
    "                            \n",
    "                fix_idx+=1\n",
    "                \n",
    "            # CASE C\n",
    "            elif case == 'CASE C':\n",
    "                print(f\"CASE C: New edge from connecting node {connecting_ntw02_osmid} intersects with either network 01 or network 02 at an UNRELATED edge.\")\n",
    "    \n",
    "                # Register how the intersected edge (from network 01 or 02) will be clipped\n",
    "                # (In the intersection, keeping both ends)\n",
    "                intersection_nodes_3.loc[fix_idx,'osmid'] = produced_osmid\n",
    "                intersection_nodes_3.loc[fix_idx,'geometry'] = intersectionpoint_geom\n",
    "                intersection_nodes_3.loc[fix_idx,'u'] = intersected_u\n",
    "                intersection_nodes_3.loc[fix_idx,'v'] =  intersected_v\n",
    "                intersection_nodes_3.loc[fix_idx,'key'] = intersected_key\n",
    "                intersection_nodes_3.loc[fix_idx,'retain_how'] = 'both' #Sets retain_all=True\n",
    "                intersection_nodes_3.loc[fix_idx,'edge_origin'] = 'ntw_01_or_02' #Helps divide network_intersections_update() process\n",
    "                # Register crs (one time)\n",
    "                if fix_idx==0:\n",
    "                    intersection_nodes_3 = intersection_nodes_3.set_crs(projected_crs)\n",
    "                \n",
    "                fix_idx+=1\n",
    "            \n",
    "                # Register how the drawn edge will be clipped\n",
    "                # (From the connecting_ntw02_node to the intersection, keeping just that segment)\n",
    "                intersection_nodes_3.loc[fix_idx,'osmid'] = produced_osmid\n",
    "                intersection_nodes_3.loc[fix_idx,'geometry'] = intersectionpoint_geom\n",
    "                intersection_nodes_3.loc[fix_idx,'u'] = drawn_edge_u # u is from ntw02\n",
    "                intersection_nodes_3.loc[fix_idx,'v'] = drawn_edge_v # v is from ntw01\n",
    "                intersection_nodes_3.loc[fix_idx,'key'] = drawn_edge_key\n",
    "                intersection_nodes_3.loc[fix_idx,'retain_how'] = 'both' #Sets retain_all=True\n",
    "                intersection_nodes_3.loc[fix_idx,'edge_origin'] = 'ntw_join' #Helps divide network_intersections_update() process\n",
    "                \n",
    "                fix_idx+=1\n",
    "\n",
    "# Set unique identifiers to int for both outputs\n",
    "joined_edges_concat['u'] = joined_edges_concat['u'].astype('int')\n",
    "joined_edges_concat['v'] = joined_edges_concat['v'].astype('int')\n",
    "joined_edges_concat['key'] = joined_edges_concat['key'].astype('int')\n",
    "\n",
    "intersection_nodes_3['u'] = intersection_nodes_3['u'].astype('int')\n",
    "intersection_nodes_3['v'] = intersection_nodes_3['v'].astype('int')\n",
    "intersection_nodes_3['key'] = intersection_nodes_3['key'].astype('int')\n",
    "\n",
    "# Fix edge_origin 'ntw_01_or_02' assignment in intersection_nodes_3\n",
    "print(\"Finding origin for edges assigned 'ntw_01_or_02'.\")\n",
    "# Extract list of edge_ids that are known to be either ntw_01 or ntw_02\n",
    "ntw01_edges_ids = list(joined_edges_concat.loc[joined_edges_concat.ntw_origin=='ntw_01'].edge_id.unique())\n",
    "ntw02_edges_ids = list(joined_edges_concat.loc[joined_edges_concat.ntw_origin=='ntw_02'].edge_id.unique())\n",
    "# Create a edge_id col for the intersected edges registered for each intersection on intersection_nodes_3 gdf\n",
    "intersection_nodes_3 = create_unique_edge_id(intersection_nodes_3)\n",
    "# Fix edge_origin 'ntw_01_or_02'\n",
    "idx_01 = (intersection_nodes_3.edge_origin=='ntw_01_or_02') & (intersection_nodes_3.edge_id.isin(ntw01_edges_ids))\n",
    "intersection_nodes_3.loc[idx_01,'edge_origin'] = 'ntw_01'\n",
    "idx_02 = (intersection_nodes_3.edge_origin=='ntw_01_or_02') & (intersection_nodes_3.edge_id.isin(ntw02_edges_ids))\n",
    "intersection_nodes_3.loc[idx_02,'edge_origin'] = 'ntw_02'\n",
    "\n",
    "# Show\n",
    "print(joined_edges_concat.shape)\n",
    "joined_edges_concat.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bc00e-6b03-40cc-a72a-c5bac635b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_nodes_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa828fbb-bf90-4fc3-bcec-b517d789d928",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 04 -__ Fix undesired intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f3721-7f9c-4084-b2a5-4e6975b7b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply network_intersections_update() function\n",
    "# Splitting the process in using col 'edge_origin' was necessary because function network_intersections_update\n",
    "# iterates over each osmid. intersection_nodes_3 can have 2 rows for each osmid.\n",
    "# (e.g. a undesired intersection cuts 1 ntw_01 edge and 1 ntw_join edge in a point that's better suited for being the\n",
    "#  connection point, so both edges get cut at that intersection point).\n",
    "\n",
    "# Nodes get updated every time network_intersections_update runs (Creates node duplicates, will remove)\n",
    "joined_nodes_fix = concatenated_nodes.copy()\n",
    "# Gets updated by concatenating each iteration's joined_edges_current.\n",
    "# Each iteration updates the edges from each origin.\n",
    "# (Prevents crash from trying to split multiple close edges with the same node at once)\n",
    "joined_edges_fix = gpd.GeoDataFrame()\n",
    "\n",
    "edge_origins = ['ntw_01','ntw_02','ntw_join']\n",
    "\n",
    "for current_edge_origin in edge_origins:\n",
    "    print(f\"Fixing edges from edge_origin {current_edge_origin}.\")\n",
    "    # Isolate current origin\n",
    "    current_edges = joined_edges_concat.loc[joined_edges_concat.ntw_origin==current_edge_origin]\n",
    "    # Intersecting edges that were originaly located in edge_origin\n",
    "    intersection_nodes_3_current = intersection_nodes_3.loc[intersection_nodes_3.edge_origin==current_edge_origin]\n",
    "    # (Second round of intersections, derived from new nodes created from network_02 to edges on network_01)\n",
    "    joined_nodes_fix, joined_edges_current = network_intersections_update(current_ntw_nodes = joined_nodes_fix,\n",
    "                                                                          current_ntw_edges = current_edges,\n",
    "                                                                          intersection_nodes = intersection_nodes_3_current,\n",
    "                                                                          projected_crs = projected_crs)\n",
    "    \n",
    "    # Store the edge_ids created to join both networks\n",
    "    joined_edges_current = create_unique_edge_id(joined_edges_current)\n",
    "    join_idx = joined_edges_current.intersecting==1\n",
    "    edge_ids = list(joined_edges_current.loc[join_idx].edge_id.unique())\n",
    "    all_join_edgeids = all_join_edgeids + edge_ids\n",
    "    \n",
    "    # Concatenate resulting edges\n",
    "    joined_edges_fix = pd.concat([joined_edges_fix,joined_edges_current])\n",
    "\n",
    "# Drop node duplicates and cols 'intersecting'\n",
    "joined_nodes_fix.drop(columns=['intersecting'],inplace=True)\n",
    "joined_nodes_fix.drop_duplicates(inplace=True)\n",
    "joined_edges_fix.drop(columns=['intersecting'],inplace=True)\n",
    "\n",
    "# Reset indexes\n",
    "joined_nodes_fix.reset_index(inplace=True,drop=True)\n",
    "joined_edges_fix.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# Show\n",
    "print(joined_nodes_fix.dtypes)\n",
    "print(joined_nodes_fix.shape)\n",
    "joined_nodes_fix.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440b3e2-21a9-48d9-ae3f-c3f0ad2bcdef",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 04 -__ Retrieve origin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4c46b-6020-4d01-94f9-212885ceca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes from ntw_01\n",
    "ntw01_nodes_osmid = list(concatenated_nodes.loc[concatenated_nodes.ntw_origin=='ntw_01'].osmid.unique())\n",
    "join_idx = joined_nodes_fix.osmid.isin(ntw01_nodes_osmid)\n",
    "joined_nodes_fix.loc[join_idx,'ntw_origin'] = 'ntw_01'\n",
    "\n",
    "# Nodes from ntw_02\n",
    "ntw02_nodes_osmid = list(concatenated_nodes.loc[concatenated_nodes.ntw_origin=='ntw_02'].osmid.unique())\n",
    "join_idx = joined_nodes_fix.osmid.isin(ntw02_nodes_osmid)\n",
    "joined_nodes_fix.loc[join_idx,'ntw_origin'] = 'ntw_02'\n",
    "\n",
    "# Nodes used to join both networks (all_join_osmids)\n",
    "join_idx = joined_nodes_fix.osmid.isin(all_join_osmids)\n",
    "joined_nodes_fix.loc[join_idx,'ntw_origin'] = 'ntw_join'\n",
    "\n",
    "# Origin assignment test\n",
    "len_ntw01_nodes = len(joined_nodes_fix.loc[joined_nodes_fix.ntw_origin=='ntw_01'])\n",
    "len_ntw02_nodes = len(joined_nodes_fix.loc[joined_nodes_fix.ntw_origin=='ntw_02'])\n",
    "len_ntwjoin_nodes = len(joined_nodes_fix.loc[joined_nodes_fix.ntw_origin=='ntw_join'])\n",
    "print(f\"Identified origin of {len_ntw01_nodes + len_ntw02_nodes + len_ntwjoin_nodes} nodes.\")\n",
    "\n",
    "# Show\n",
    "print(joined_nodes_fix.shape)\n",
    "joined_nodes_fix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a18256-7610-4d7c-bfb0-9b69196bd6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detail\n",
    "print(joined_nodes_fix.crs)\n",
    "print(joined_nodes_fix.dtypes)\n",
    "joined_nodes_fix.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e784268f-8a1d-4445-bde1-aa2ec3862c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges from ntw_01\n",
    "ntw01_edges_ids = list(joined_edges_concat.loc[joined_edges_concat.ntw_origin=='ntw_01'].edge_id.unique())\n",
    "join_idx = joined_edges_fix.edge_id.isin(ntw01_edges_ids)\n",
    "joined_edges_fix.loc[join_idx,'ntw_origin'] = 'ntw_01'\n",
    "\n",
    "# Edges from ntw_02\n",
    "ntw02_edges_ids = list(joined_edges_concat.loc[joined_edges_concat.ntw_origin=='ntw_02'].edge_id.unique())\n",
    "join_idx = joined_edges_fix.edge_id.isin(ntw02_edges_ids)\n",
    "joined_edges_fix.loc[join_idx,'ntw_origin'] = 'ntw_02'\n",
    "\n",
    "# Edges used to join both networks (all_join_edgeids)\n",
    "join_idx = joined_edges_fix.edge_id.isin(all_join_edgeids)\n",
    "joined_edges_fix.loc[join_idx,'ntw_origin'] = 'ntw_join'\n",
    "\n",
    "# Origin assignment test\n",
    "len_ntw01_edges = len(joined_edges_fix.loc[joined_edges_fix.ntw_origin=='ntw_01'])\n",
    "len_ntw02_edges = len(joined_edges_fix.loc[joined_edges_fix.ntw_origin=='ntw_02'])\n",
    "len_ntwjoin_edges = len(joined_edges_fix.loc[joined_edges_fix.ntw_origin=='ntw_join'])\n",
    "print(f\"Identified origin of {len_ntw01_edges + len_ntw02_edges + len_ntwjoin_edges} edges.\")\n",
    "\n",
    "# Show\n",
    "print(joined_edges_fix.shape)\n",
    "joined_edges_fix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc2656-e52c-4c0b-b0cc-7edd38fb2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detail\n",
    "print(joined_edges_fix.crs)\n",
    "print(joined_edges_fix.dtypes)\n",
    "joined_edges_fix.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f79d1-1e4e-4eed-8e66-2ad1d8a58e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if localsave_02_04:\n",
    "    joined_nodes_fix.to_file(output_dir + \"part02_step04_ntwsconnect/joined_nodes_fix.gpkg\")\n",
    "    joined_edges_fix.to_file(output_dir + \"part02_step04_ntwsconnect/joined_edges_fix.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e70c3-9b6b-4efd-82a7-25bd2b63ecb9",
   "metadata": {},
   "source": [
    "## __Part 02 - Step 05 -__ Network cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9105346d-d82c-42c0-97ed-d47712d93a43",
   "metadata": {},
   "source": [
    "This step cleans the joined network (nodes and edges) by analysing the number of edges that use each node (osmid).\n",
    "\n",
    "1. Osmids that recieve __0 edges__ should be __deleted__. They are unconnected.\n",
    "2. Osmids that recieve __1 edge__ will be __deleted__ (Along with that edge) __IF__ their ntw origin is __not ntw_01.__ (ntw_01 is the 'reliable' network from Boeing, deleting osmids and edges this way would remove dead end streets).\n",
    "3. Osmids that recieve __2 edges__ will be __joined__ (Shouldn't be an intersection, but a continous edge).\n",
    "4. Osmids that recieve __3 or more edges__ are regular intersections. Nothing is done with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e9705-6503-4b2c-bdb6-3b1fd12157cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_nodes_cleaning = joined_nodes_fix.copy()\n",
    "joined_edges_cleaning = joined_edges_fix.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd329d6d-73e6-49f1-a3da-95e0d6b06b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No duplicates in osmid check\n",
    "print(joined_nodes_cleaning.shape)\n",
    "test = joined_nodes_cleaning.copy()\n",
    "test.drop_duplicates(subset='osmid',inplace=True)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334335f-da7d-469c-bbb1-a19e893834f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No duplicates in u,v,'key' check\n",
    "print(joined_edges_cleaning.shape)\n",
    "test = joined_edges_cleaning.copy()\n",
    "test.drop_duplicates(subset=['u','v','key'],inplace=True)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c62796-c7be-47e3-9999-dd0824e65cbf",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 05 -__ Identify the number of edges that use each node ('streets_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd14e2-6134-4cc6-93a7-ded001546735",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_list = list(joined_edges_cleaning.u)\n",
    "v_list = list(joined_edges_cleaning.v)\n",
    "\n",
    "# For each osmid, find the number of edges that reach that osmid.\n",
    "for osmid in list(joined_nodes_cleaning.osmid.unique()):\n",
    "    \n",
    "    streets_count = 0\n",
    "    for u in u_list:\n",
    "        if osmid == u:\n",
    "            streets_count+=1\n",
    "    for v in v_list:\n",
    "        if osmid == v:\n",
    "            streets_count+=1\n",
    "\n",
    "    idx = joined_nodes_cleaning.osmid == osmid\n",
    "    joined_nodes_cleaning.loc[idx,'streets_count'] = streets_count\n",
    "\n",
    "# Show\n",
    "print(joined_nodes_cleaning.shape)\n",
    "joined_nodes_cleaning.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f0ea0-3674-42a5-b3aa-69e743adc635",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 05 -__ Osmids that recieve __0 edges__ should be __deleted__. They are unconnected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a11f2cd-3236-4f25-a0d4-e41c22ca9b06",
   "metadata": {},
   "source": [
    "__Show__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965bc24-ae3d-475d-8693-3c5c8eda07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_idx = joined_nodes_cleaning.streets_count==0\n",
    "zero_edge_osmids = joined_nodes_cleaning.loc[find_idx]\n",
    "# Show\n",
    "print(len(zero_edge_osmids))\n",
    "zero_edge_osmids.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734c3ce-f8b3-4ab8-9e39-2a1878384368",
   "metadata": {},
   "source": [
    "__Remove__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcc856-f3a0-433a-a111-9b060c83e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_nodes_cleaning_0 = joined_nodes_cleaning.copy()\n",
    "keep_idx = joined_nodes_cleaning_0.streets_count>0\n",
    "joined_nodes_cleaning_0 = joined_nodes_cleaning_0.loc[keep_idx].copy()\n",
    "print(f\"Deleted {len(joined_nodes_cleaning)-len(joined_nodes_cleaning_0)} nodes with 0 edges attatched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f7301-d8f6-4023-ab5a-ff5237c80034",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 05 -__ Osmids that recieve 1 edge will be deleted (Along with that edge) IF their ntw origin is not ntw_01. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0d108-adf7-4a5c-8de9-30b8944c48da",
   "metadata": {},
   "source": [
    "__Show__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f099400-9fdf-4539-b770-a60734fe9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_idx = (joined_nodes_cleaning.streets_count==1)&(joined_nodes_cleaning.ntw_origin!='ntw_01')\n",
    "one_edge_osmids = joined_nodes_cleaning.loc[find_idx]\n",
    "# Show\n",
    "print(len(one_edge_osmids))\n",
    "one_edge_osmids.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b149ee9b-90bd-475d-add6-cececaee6e44",
   "metadata": {},
   "source": [
    "__Remove nodes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c2643-0bd3-426b-b45e-6670a5014eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_nodes_cleaning_1 = joined_nodes_cleaning_0.copy()\n",
    "drop_idx = (joined_nodes_cleaning.streets_count==1)&(joined_nodes_cleaning.ntw_origin!='ntw_01')\n",
    "joined_nodes_cleaning_1 = joined_nodes_cleaning_1.loc[~drop_idx].copy()\n",
    "print(f\"Deleted {len(joined_nodes_cleaning_0)-len(joined_nodes_cleaning_1)} nodes with 1 edge attatched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df2501-3351-41a8-94d0-a635eb389d50",
   "metadata": {},
   "source": [
    "__Remove edges__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471354aa-abfa-49c1-a6e8-350e462ff60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the osmids that were dropped\n",
    "drop_idx = (joined_nodes_cleaning.streets_count==1)&(joined_nodes_cleaning.ntw_origin!='ntw_01')\n",
    "dropped_osmids = list(joined_nodes_cleaning_0.loc[drop_idx].osmid.unique())\n",
    "# Delete the edges that are related to those osmids\n",
    "joined_edges_cleaning_1 = joined_edges_cleaning.copy()\n",
    "drop_edge_idx = (joined_edges_cleaning_1.u.isin(dropped_osmids))|(joined_edges_cleaning_1.v.isin(dropped_osmids))\n",
    "joined_edges_cleaning_1 = joined_edges_cleaning_1.loc[~drop_edge_idx]\n",
    "print(f\"Deleted {len(joined_edges_cleaning)-len(joined_edges_cleaning_1)} edges (not from ntw_01).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42326b3-d276-4952-93f4-a801e8231fd9",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 05 -__ Osmids that recieve 2 edges will be joined (Shouldn't be an intersection, but a continous edge)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ebb7f7-ff3c-446b-8b15-73b6fb2b371b",
   "metadata": {},
   "source": [
    "__Show__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70397030-3d69-4f10-a603-0ba9d69a463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_idx = joined_nodes_cleaning.streets_count==2\n",
    "two_edge_osmids = joined_nodes_cleaning.loc[find_idx].copy()\n",
    "# Show\n",
    "print(len(two_edge_osmids))\n",
    "two_edge_osmids.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759b7f2e-eb01-449c-955e-f2ebea5b19ae",
   "metadata": {},
   "source": [
    "__Remove -__ Dissolve edges from two_edge_osmids into one edge (MultiLineString) and try to convert it to LineString."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b224a-3f8e-489a-ad66-99fd3578d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if two lines connect properly, if one needs to be reversed or if both need to be reversed.\n",
    "def lines_connect(line1, line2):\n",
    "    \"\"\" This function takes as input two lines (From a MultiLineString) and checks if they connect properly,\n",
    "         if one needs to be reversed or if both need to be reversed.\n",
    "\tArgs:\n",
    "\t\tline1 (geometry): Geometry of line 1 from the MultiLineString.\n",
    "        line2 (geometry): Geometry of line 2 from the MultiLineString.\n",
    "\tReturns:\n",
    "        connection (bool):True if both lines connect, False if they don't.\n",
    "    \tjoining_line: The first line, as it is or reversed.\n",
    "        new_line: The second line, as it is or reversed.\n",
    "    \"\"\"\n",
    "    # Case 1: Last coord of first line connects with first coord of second line. No modification needed.\n",
    "    if line1.coords[-1] == line2.coords[0]:\n",
    "        return True, line1, line2\n",
    "    \n",
    "    # Case 2: First coord of first line connects with first coord of second line. Reverse first line.\n",
    "    elif line1.coords[0] == line2.coords[0]:\n",
    "        line1_reversed = LineString(line1.coords[::-1])\n",
    "        return True, line1_reversed, line2\n",
    "\n",
    "    # Case 3: Last coord of first line connects with Last coord of second line. Reverse second line.\n",
    "    elif line1.coords[-1] == line2.coords[-1]:\n",
    "        line2_reversed = LineString(line2.coords[::-1])\n",
    "        return True, line1, line2_reversed\n",
    "\n",
    "    # Case 4: First coord of first line connects with Last coord of second line. Reverse both lines.\n",
    "    elif line1.coords[0] == line2.coords[-1]:\n",
    "        line1_reversed = LineString(line1.coords[::-1])\n",
    "        line2_reversed = LineString(line2.coords[::-1])\n",
    "        return True, line1_reversed, line2_reversed\n",
    "\n",
    "    # Case 5: No coords connect\n",
    "    else:\n",
    "        return False, line1, line2\n",
    "\n",
    "def multilinestring_to_linestring(row):\n",
    "    \"\"\" This function converts a MultiLineStrings to properly connected LineStrings.\n",
    "\tArgs:\n",
    "\t\trow (gdf row): row of a gdf containing either a LineString or a MultiLineString in its geometry.\n",
    "\tReturns:\n",
    "        row (gdf row): row of a gdf with no MultiLineStrings, LineStrings only.\n",
    "    \"\"\"\n",
    "    line = row['geometry']\n",
    "    \n",
    "    # If the geometry is already a LineString, return it as is\n",
    "    if isinstance(line, LineString):\n",
    "        #print(f\"Edge {row['edge_id']} is a LineString.\")\n",
    "        return row\n",
    "    \n",
    "    # If it's a MultiLineString, concatenate all LineStrings' coordinates, ensuring they connect\n",
    "    elif isinstance(line, MultiLineString):\n",
    "        #print(f\"Edge {row['edge_id']} is a MultiLineString.\")\n",
    "        \n",
    "        # Extract and combine all coordinates from each LineString in MultiLineString\n",
    "        all_coords = list(line.geoms[0].coords)  # Start with the first LineString's coordinates\n",
    "\n",
    "        # LineStrings to be concatenated to first LineString\n",
    "        lines_i = []\n",
    "        for i in range(1,len(line.geoms)):\n",
    "            lines_i.append(i)\n",
    "\n",
    "        # Added attempts limit for cases where an node is shared by two edges\n",
    "        # that coincide in various points (very very rare, due to Volvo's Tessellations network)\n",
    "        attempts = 0\n",
    "        attempts_limit = 100\n",
    "        \n",
    "        # Iterate over the remaining LineStrings and ensure they connect\n",
    "        while len(lines_i)>0: # While there are still lines to be connected\n",
    "\n",
    "            if attempts < attempts_limit:\n",
    "                # Iterate over each one of them and try to find a connection to line formed so far\n",
    "                for i in lines_i: \n",
    "\n",
    "                    # Lines to connect\n",
    "                    joining_line = LineString(all_coords) # The line formed so far\n",
    "                    new_line = line.geoms[i] # The new line to be connected\n",
    "                    # Check if lines connect, and reverse lines if needed for connection\n",
    "                    connection, joining_line, new_line = lines_connect(joining_line, new_line)\n",
    "                    # Perform connection\n",
    "                    if connection:\n",
    "                        # Register current coords (cannot use previous, might be reversed)\n",
    "                        all_coords = list(joining_line.coords)\n",
    "                        # Extend the coordinate list with the new line's coordinates\n",
    "                        all_coords.extend(list(new_line.coords))\n",
    "                        # Remove added i from lines_i list\n",
    "                        lines_i.remove(i)\n",
    "                    # Add attempt\n",
    "                    attempts+=1\n",
    "            else:\n",
    "                # Stop\n",
    "                print(f\"Edge {row['edge_id']} exceeded the attempts limit for MultiLineString to LineString conversion.\")\n",
    "                global multilinestring_fail_lst\n",
    "                multilinestring_fail_lst.append(row['edge_id'])\n",
    "                return row\n",
    "        \n",
    "        # Update the row's geometry with the resulting LineString\n",
    "        row['geometry'] = LineString(all_coords)\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323db83-527a-4519-bb94-02b520bfb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_nodes_cleaning_2 = joined_nodes_cleaning_1.copy()\n",
    "joined_edges_cleaning_2 = joined_edges_cleaning_1.copy()\n",
    "\n",
    "multilinestring_fail_lst = []\n",
    "\n",
    "for osmid in list(two_edge_osmids.osmid.unique()):\n",
    "\n",
    "    #print(\"--\"*10)\n",
    "    #print(f\"OSMID OF INTEREST: {osmid}.\")\n",
    "    \n",
    "    # Find edges that use that osmid\n",
    "    found_in_u = joined_edges_cleaning_2.loc[joined_edges_cleaning_2.u == osmid].copy()\n",
    "    found_in_v = joined_edges_cleaning_2.loc[joined_edges_cleaning_2.v == osmid].copy()\n",
    "    found_edges = pd.concat([found_in_u,found_in_v])\n",
    "    #print(found_edges)\n",
    "    \n",
    "    # Find the other osmids those edges connect with\n",
    "    u_v_list = list(found_edges.u.unique()) + list(found_edges.v.unique())\n",
    "    # Remove itself\n",
    "    u_v_list = [i for i in u_v_list if i != osmid]\n",
    "\n",
    "    # Dissolve lines (Creates MultiLineString, will convert to LineString)\n",
    "    flattened_edge = found_edges.dissolve()\n",
    "\n",
    "    # Add data to new edge\n",
    "    flattened_edge['u'] = u_v_list[0]\n",
    "    flattened_edge['v'] = u_v_list[1]\n",
    "    flattened_edge['key'] = 0\n",
    "    flattened_edge['ntw_origin'] = 'ntw_cleaning'\n",
    "    flattened_edge = create_unique_edge_id(flattened_edge)\n",
    "\n",
    "    # Convert MultiLineStrings to LineStrings\n",
    "    flattened_edge = flattened_edge.apply(multilinestring_to_linestring,axis=1)\n",
    "    # If conversion fails, flattened edge_id gets added to global list multilinestring_fail_lst.\n",
    "    flattened_edge_id = flattened_edge.edge_id.unique()[0]\n",
    "    if flattened_edge_id not in multilinestring_fail_lst:\n",
    "        # Delete useless node and previous edges, concat new flattened edge.\n",
    "        joined_nodes_cleaning_2 = joined_nodes_cleaning_2.loc[joined_nodes_cleaning_2.osmid != osmid].copy()\n",
    "        joined_edges_cleaning_2 = joined_edges_cleaning_2.loc[(joined_edges_cleaning_2.u != osmid)&(joined_edges_cleaning_2.v != osmid)].copy()\n",
    "        joined_edges_cleaning_2 = pd.concat([joined_edges_cleaning_2,flattened_edge])\n",
    "    else:\n",
    "        print(f\"Not dissolving edges reaching node {osmid}.\")\n",
    "\n",
    "# Final format\n",
    "joined_edges_cleaning_2.reset_index(inplace=True,drop=True)\n",
    "joined_nodes_cleaning_2.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# Show\n",
    "print(joined_edges_cleaning_2.shape)\n",
    "joined_edges_cleaning_2.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3960e65-ad48-4606-9275-0c83836f28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_conversion_osmids = [437883693932]\n",
    "failed_idx = (joined_edges_cleaning_2.u.isin(failed_conversion_osmids))|(joined_edges_cleaning_2.v.isin(failed_conversion_osmids))\n",
    "joined_edges_cleaning_2.loc[failed_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ce0c1-b758-4904-b73e-fcfcded0e351",
   "metadata": {},
   "source": [
    "### __Part 02 - Step 05 -__ Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc5e6a-d08e-4afc-a2e2-4aa084bdddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detail\n",
    "print(joined_nodes_cleaning_2.crs)\n",
    "print(joined_nodes_cleaning_2.dtypes)\n",
    "joined_nodes_cleaning_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d23f33-7a48-4635-9363-d7b0c5f37b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detail\n",
    "print(joined_edges_cleaning_2.crs)\n",
    "print(joined_edges_cleaning_2.dtypes)\n",
    "joined_edges_cleaning_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ae08c-ceb4-48af-8ee7-d38148bc495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if localsave_02_05:\n",
    "    joined_nodes_cleaning_2.to_file(output_dir + \"part02_step05_ntwsclean/joined_nodes_clean.gpkg\")\n",
    "    joined_edges_cleaning_2.to_file(output_dir + \"part02_step05_ntwsclean/joined_edges_clean.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e06656-5602-4557-9309-7e8bf9cb2a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS-10.0",
   "language": "python",
   "name": "gds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
