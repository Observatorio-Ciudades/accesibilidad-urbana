{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67abf553-9ca7-4d41-a815-308d0e65e3e8",
   "metadata": {},
   "source": [
    "# Script 21 - (Updated up to date 2024-01-30) adjusted to project: Volvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458cecb7-157f-4b0d-8983-e62e874660e2",
   "metadata": {},
   "source": [
    "This notebook is based on Script 21 (Most recent proximity script), created on 2024-01-30.\n",
    "\n",
    "__The notebook differs from regular proxmity analysis in:__\n",
    "* Area of Interest: Guadalajara only.\n",
    "* Points of Interest (Eje-amenidad)\n",
    "    * Escuelas: Preescolar, primaria, secundaria, *__guarderías__*\n",
    "    * Salud: CLUES, *__farmacias__*\n",
    "    * *__Parques: Parques de Guadalajara__*\n",
    "    * *__Equip. Deportivos:__* Canchas, unidades deportivas\n",
    "    * *__Cultural:__* Cines, museos, bibliotecas\n",
    "    * *__Financieros: Busqueda en DENUE de bancos__*\n",
    " \n",
    "* __Processing:__\n",
    "    * Por amenidad:\n",
    "        * Proximidad (tiempo)\n",
    "        * Conteo de amenidades a 15 minutos\n",
    "    * Por eje:\n",
    "        * Tiempo mínimo a amenidades (al más cercano)\n",
    "        * Suma del conteo de las amenidades a 15 minutos   \n",
    "\n",
    "* Output: Generates res9\n",
    "* Output name: _______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c3e5e-e5dc-4ab6-8617-dd28b7dc5eca",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ace2cd4-cfc1-4cb2-97d2-0d39eca03b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/aup/data.py:25: UserWarning: The `utils.config` function is deprecated and will be removed in a future release. Instead, use the `settings` module directly to configure a global setting's value. For example, `ox.settings.log_console=True`.\n",
      "  ox.config(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    import aup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a311f-da69-42ae-9ffc-276b9ae1ab47",
   "metadata": {},
   "source": [
    "## Required script 21 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee368c1-fab8-4f81-a210-5de1b9fc783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Version option (1 or 2) was removed because it will run bibliotecas (Version 2) but look for min time (Version 1), not two-method (Version 2).\n",
    "####################################################################################################################################\n",
    "\n",
    "city = 'Guadalajara'\n",
    "\n",
    "# ---------------------------- BASE DATA REQUIRED ----------------------------\n",
    "# Area of interest (city)\n",
    "metro_schema = 'metropolis'\n",
    "metro_table = 'metro_gdf_2020'\n",
    "# Network data (nodes and edges table for distance analysis,\n",
    "# also used to generate the network G with which the nearest OSMID is assigned to each poi)\n",
    "network_schema = 'osmnx'\n",
    "nodes_table = 'nodes_23_point'\n",
    "edges_table = 'edges_speed' ################################################################################################## PENDIENTE\n",
    "# Points of interest - DENUE\n",
    "denue_schema = 'denue'\n",
    "denue_table = 'denue_23_point'\n",
    "# Points of interest - CLUES\n",
    "clues_schema = 'denue'\n",
    "clues_table = 'clues_23_point'\n",
    "# Points of interest - SIP\n",
    "sip_schema = 'denue'\n",
    "sip_table = 'sip_23_point'\n",
    "# Points of interest - Espacio publico (Parques) ### Exclusive project Volvo\n",
    "parques_schema = 'espacios_publicos' \n",
    "parques_table = 'ep_amg_year_vertices'\n",
    "# Hexgrid\n",
    "hex_schema = 'hexgrid'\n",
    "# Population data\n",
    "pop_schema = 'censo'\n",
    "pop_table = 'hex_bins_pop_2020' ############################################################################################### PENDIENTE para res9\n",
    "\n",
    "# ---------------------------- ANALYSIS AND OUTPUT OPTIONS ----------------------------\n",
    "# Network distance method used in function pois_time. (If length, assumes pedestrian speed of 4km/hr.)\n",
    "prox_measure = 'time_min' # Must pass 'length' or 'time_min'\n",
    "\n",
    "# Count available amenities at given time proximity (minutes)?\n",
    "count_pois = (True,15) # Must pass a tupple containing a boolean (True or False) and time proximity of interest in minutes (Boolean,time)\n",
    "\n",
    "# If pop_output = True, loads pop data from pop_schema and pop_table.\n",
    "# If pop_output = False, loads empty hexgrid.\n",
    "pop_output = False ############################################################## If pop_output == True, allows res 8 only, since output must be 9, pop_output must be false.\n",
    "\n",
    "# Hexagon resolutions of output\n",
    "res_list = [9] \n",
    "\n",
    "# SAVING\n",
    "# Save final output to db?\n",
    "save = False\n",
    "save_schema = 'prox_analysis'\n",
    "save_table = 'proximityanalysis_24_ageb_hex'\n",
    "# Local save? (Runs Aguascalientes for tests)\n",
    "local_save = True\n",
    "local_save_dir = '../../../data/external/temporal_fromjupyter/volvo/proxanalysis_volvo_24_hex9.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9141ff-3d88-4c90-9deb-96d88e3ad4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Adjusted diccs for project Volvo.\n",
    "####################################################################################################################################\n",
    "\n",
    "parameters = {'Escuelas':{'Guarderías':{'denue_guarderias':[624411, 624412]},\n",
    "                          'Preescolar':{'denue_preescolar':[611111, 611112]},\n",
    "                          'Primaria':{'denue_primaria':[611121, 611122]},\n",
    "                          'Secundaria':{'denue_secundaria':[611131, 611132]}\n",
    "                         },\n",
    "              'Salud':{'Primer nivel':{'clues_primer_nivel':[8610]},\n",
    "                       'Farmacias':{'denue_farmacias':[474111,464112]} ########## 464111 Farmacias sin minisúper, 464112 Farmacias con minisúper\n",
    "                       },\n",
    "              'Parques':{'Parques':{'odc_parques':[9321]} ########## AGREGAR DE BD, \n",
    "                                                          ########## Se le asignó el code 9321, correspondiente a 'Activities of amusement parks and theme parks'\n",
    "                                                          ########## Fuente del code elegido: International Standard Industrial Classification of all Economic Activities, Rev.4\n",
    "                                                          ########## https://unstats.un.org/unsd/publication/seriesm/seriesm_4rev4e.pdf\n",
    "                        },\n",
    "              'Equipamiento deportivo':{'Canchas':{'sip_cancha':[93110]},\n",
    "                                        'Unidad deportiva':{'sip_unidad_deportiva':[93111]}\n",
    "                                       },\n",
    "              'Cultural':{'denue_cines':[512130],\n",
    "                          'denue_museos':[712111, 712112],\n",
    "                          'denue_bibliotecas':[519121,519122]\n",
    "                         },\n",
    "              'Financiero':{522110} #################################################### 522110 Banca Múltiple (Bancos y cajeros)\n",
    "             }\n",
    "\n",
    "source_weight = {'Escuelas':{'Guarderías':'min', #There is only one source, no effect.\n",
    "                             'Preescolar':'min', #There is only one source, no effect.\n",
    "                             'Primaria':'min', #There is only one source, no effect.\n",
    "                             'Secundaria':'min' #There is only one source, no effect.\n",
    "                            },\n",
    "                 'Salud':{'Primer nivel':'min',#There is only one source, no effect.\n",
    "                          'Farmacias':'min'#There is only one source, no effect.\n",
    "                         },\n",
    "                 'Parques':{'Parques':'min'#There is only one source, no effect.\n",
    "                           },\n",
    "                 'Equipamiento deportivo':{'Canchas':'min',#There is only one source, no effect.\n",
    "                                           'Unidad deportiva':'min'#There is only one source, no effect.\n",
    "                                          },\n",
    "                 'Cultural':{'Cines':'min',#There is only one source, no effect.\n",
    "                             'Museos':'min',#There is only one source, no effect.\n",
    "                             'Bibliotecas':'min'#There is only one source, no effect.\n",
    "                            },\n",
    "                 'Financiero':{\n",
    "                 }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cc2f16-9e0c-4bce-b6f1-84bc7fb581f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Simplified version, does not filter centro cultural nor dif because it is not used in project Volvo.\n",
    "####################################################################################################################################\n",
    "def get_denue_pois(denue_schema,denue_table,poly_wkt,code):\n",
    "    # This function downloads the codigo_act denue poi requested for the analysis.\n",
    "\n",
    "    # Download denue pois\n",
    "    query = f\"SELECT * FROM {denue_schema}.{denue_table} WHERE (ST_Intersects(geometry, \\'SRID=4326;{poly_wkt}\\')) AND (\\\"codigo_act\\\" = \\'{code}\\')\"\n",
    "    code_pois = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "\n",
    "    # Format denue pois\n",
    "    code_pois = code_pois[['codigo_act', 'geometry']]\n",
    "    code_pois = code_pois.rename(columns={'codigo_act':'code'})\n",
    "    code_pois['code'] = code_pois['code'].astype('int64')\n",
    "\n",
    "    return code_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0301f6-0c16-4c70-b33f-53b53ebfb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# NEW\n",
    "# Project Volvo includes 'parques', which are in OdC's DB as polygons (ep_amg) and were converted to vertices (ep_amg_year_vertices)\n",
    "####################################################################################################################################\n",
    "def get_parques_pois(parques_schema,parques_table,code):\n",
    "    # This function creates parques points of interest out of vertices of parques found in db (schema>table)\n",
    "\n",
    "    # Download parques pois\n",
    "    query = f\"SELECT * FROM {parques_schema}.{parques_table}\"\n",
    "    code_pois = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "\n",
    "    # Format parques pois\n",
    "    code_pois = code_pois.to_crs(\"EPSG:4326\")\n",
    "    code_pois['code'] = code\n",
    "    code_pois = code_pois[['code', 'geometry']]\n",
    "    code_pois['code'] = code_pois['code'].astype('int64')\n",
    "\n",
    "    return code_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c031b263-8358-4bba-8288-c93de29ee193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_method_check(row):\n",
    "    # This function is used to decide which time to choose for cultural amenities.\n",
    "    # Why:\n",
    "        # In version 2 we aded 'Bibliotecas'. The source contains plenty of pois.\n",
    "        # This might dilute other cultural sources. Therefore:\n",
    "\n",
    "    # If 2 or more source amenities are within 15 minutes, \n",
    "    # chooses max time of the sources within 15 minutes.\n",
    "    # (Measures proximity to an amenity which we know is close.)\n",
    "    if row['check_count'] > 1:\n",
    "        # Identify sources within 15 minutes\n",
    "        prox_sources=[]\n",
    "        for s in check_lst:\n",
    "            if row[s] == 1:\n",
    "                prox_sources.append(s.replace('_check',''))\n",
    "        # Find max of those sources\n",
    "        row['max_'+a.lower()] = row[prox_sources].max()\n",
    "\n",
    "    # Else (just 1 or 0 source amenities are within 15 minutes),\n",
    "    # chooses min time of the amenities outside 15 minutes. \n",
    "    # (Ignores if only one is close (most likely bibliotecas), takes next closest)\n",
    "    else:\n",
    "        # Identify sources outside 15 minutes\n",
    "        prox_sources=[]\n",
    "        for s in check_lst:\n",
    "            if row[s] == 0:\n",
    "                prox_sources.append(s.replace('_check',''))\n",
    "        # Find min of those sources\n",
    "        row['max_'+a.lower()] = row[prox_sources].min()\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1028785-32af-4ded-b6b2-9ca673a2a44f",
   "metadata": {},
   "source": [
    "## Script 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e82e307a-035b-4887-bddb-d24d6f2d16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################### PART 1 ###############################################################\n",
    "#################################################### FIND NODES PROXIMITY TO POIS ####################################################\n",
    "###################################################### (PREV. SCRIPT 01 + 02) ########################################################\n",
    "\n",
    "# 1.1 --------------- BASE DATA FOR POIS-NODES ANALYSIS\n",
    "# ------------------- This first step downloads the area of interest and network used to measure distance.\n",
    "\n",
    "# Download area of interest\n",
    "query = f\"SELECT * FROM {metro_schema}.{metro_table} WHERE \\\"city\\\" LIKE \\'{city}\\'\"\n",
    "mun_gdf = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "mun_gdf = mun_gdf.set_crs(\"EPSG:4326\")\n",
    "aoi = mun_gdf.dissolve()\n",
    "\n",
    "# Download Network used to calculate nearest note to each poi\n",
    "#G, nodes, edges = aup.graph_from_hippo(aoi, schema=network_schema, edges_folder=edges_table, nodes_folder=nodes_table)\n",
    "\n",
    "# Show\n",
    "#print(nodes.shape)\n",
    "#print(edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d36b56d-fe82-4ca0-b7be-b7e515e9014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# 1.2 --------------- DOWNLOAD POINTS OF INTEREST (clues and sip pois, not denue)\n",
    "# ------------------- This step downloads SIP and CLUES points of interest (denue pois are downloaded later.)\n",
    "sip_clues_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "# CLUES (Salud)\n",
    "aup.log(f\"--- Downloading CLUES pois for {city}.\")\n",
    "# Download\n",
    "clues_gdf = aup.gdf_from_polygon(aoi, clues_schema, clues_table, geom_col=\"geometry\")\n",
    "# Filter\n",
    "clues_pois = clues_gdf.loc[clues_gdf['nivel_atencion'] == 'PRIMER NIVEL']\n",
    "del clues_gdf\n",
    "# Format\n",
    "clues_pois.loc[:,'code'] = 8610\n",
    "clues_pois = clues_pois[['code','geometry']]\n",
    "# Save to pois_tmp\n",
    "sip_clues_gdf = pd.concat([sip_clues_gdf,clues_pois])\n",
    "del clues_pois\n",
    "\n",
    "# SIP (Marco geoestadistico)\n",
    "aup.log(f\"--- Downloading SIP pois for {city}.\")\n",
    "# Download\n",
    "sip_gdf = aup.gdf_from_polygon(aoi, sip_schema, sip_table, geom_col=\"geometry\")\n",
    "sip_amenities = {'GEOGRAFICO':['Mercado','Plaza'], \n",
    "                 'TIPO':['Cancha','Unidad Deportiva','Áreas Verdes','Jardín','Parque']}\n",
    "# Filter - SIP pois of interest\n",
    "sip_amenities_codes = {'Mercado':4721, #sip_mercado\n",
    "                       'Cancha':93110, #sip_cancha\n",
    "                       'Unidad Deportiva':93111, #sip_unidad_deportiva \n",
    "                       'Áreas Verdes':9321, #sip_espacio_publico \n",
    "                       'Jardín':9321, #sip_espacio_publico\n",
    "                       'Parque':9321, #sip_espacio_publico\n",
    "                       'Plaza':9321 #sip_espacio_publico\n",
    "                        }\n",
    "# Filter - Iterate over sip_amenities and filter sip gdf\n",
    "sip_pois = gpd.GeoDataFrame()\n",
    "for col in sip_amenities:\n",
    "    for amenity in sip_amenities[col]:\n",
    "        sip_tmp = sip_gdf.loc[sip_gdf[col] == amenity]\n",
    "        sip_tmp.loc[:,'code'] = sip_amenities_codes[amenity]\n",
    "        sip_pois = pd.concat([sip_pois,sip_tmp])\n",
    "del sip_gdf\n",
    "# Format\n",
    "sip_pois = sip_pois[['code','geometry']]\n",
    "# Save to pois_tmp\n",
    "sip_clues_gdf = pd.concat([sip_clues_gdf,sip_pois])\n",
    "del sip_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fda9ae6-4642-4e01-8f01-0440356ce93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing source denue_restaurante_insitu.\n",
      "--- Downloading denue source pois code 722511 from db.\n",
      "--- Downloading denue source pois code 722512 from db.\n",
      "--- Downloading denue source pois code 722513 from db.\n",
      "--- Downloading denue source pois code 722514 from db.\n",
      "--- Downloading denue source pois code 722519 from db.\n",
      "--- 4926 denue_restaurante_insitu pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_restaurante_insitu.\n",
      "Starting time analysis for denue_restaurante_insitu.\n",
      "Starting range k = 1 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 2 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 3 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 4 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 5 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 6 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 7 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 8 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 9 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 10 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 11 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 12 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 13 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 14 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 15 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 16 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 17 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 18 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 19 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 20 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 21 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 22 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 23 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 24 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 25 of 25 for denue_restaurante_insitu.\n",
      "Finished time analysis for denue_restaurante_insitu.\n",
      "--- FINISHED source denue_restaurante_insitu. Mean city time = 27.0165546933015\n",
      "Analysing source denue_restaurante_llevar.\n",
      "--- Downloading denue source pois code 722516 from db.\n",
      "--- Downloading denue source pois code 722518 from db.\n",
      "--- Downloading denue source pois code 722517 from db.\n",
      "--- 1055 denue_restaurante_llevar pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_restaurante_llevar.\n",
      "Starting time analysis for denue_restaurante_llevar.\n",
      "Starting range k = 1 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 2 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 3 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 4 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 5 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 6 of 6 for denue_restaurante_llevar.\n",
      "Finished time analysis for denue_restaurante_llevar.\n",
      "--- FINISHED source denue_restaurante_llevar. Mean city time = 33.645540946448484\n",
      "Analysing source denue_bares.\n",
      "--- Downloading denue source pois code 722412 from db.\n",
      "--- 278 denue_bares pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_bares.\n",
      "Starting time analysis for denue_bares.\n",
      "Starting range k = 1 of 2 for denue_bares.\n",
      "Starting range k = 2 of 2 for denue_bares.\n",
      "Finished time analysis for denue_bares.\n",
      "--- FINISHED source denue_bares. Mean city time = 54.69010579237759\n",
      "Analysing source denue_cafe.\n",
      "--- Downloading denue source pois code 722515 from db.\n",
      "--- 957 denue_cafe pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_cafe.\n",
      "Starting time analysis for denue_cafe.\n",
      "Starting range k = 1 of 5 for denue_cafe.\n",
      "Starting range k = 2 of 5 for denue_cafe.\n",
      "Starting range k = 3 of 5 for denue_cafe.\n",
      "Starting range k = 4 of 5 for denue_cafe.\n",
      "Starting range k = 5 of 5 for denue_cafe.\n",
      "Finished time analysis for denue_cafe.\n",
      "--- FINISHED source denue_cafe. Mean city time = 30.951618707461428\n",
      "Analysing source sip_cancha.\n",
      "--- Getting clues/sip source pois code 93110 from previously downloaded.\n",
      "--- 25 sip_cancha pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_cancha.\n",
      "Starting time analysis for sip_cancha.\n",
      "Starting range k = 1 of 1 for sip_cancha.\n",
      "Finished time analysis for sip_cancha.\n",
      "--- FINISHED source sip_cancha. Mean city time = 131.6102281232431\n",
      "Analysing source sip_unidad_deportiva.\n",
      "--- Getting clues/sip source pois code 93111 from previously downloaded.\n",
      "--- 4 sip_unidad_deportiva pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_unidad_deportiva.\n",
      "Starting time analysis for sip_unidad_deportiva.\n",
      "Starting range k = 1 of 1 for sip_unidad_deportiva.\n",
      "Finished time analysis for sip_unidad_deportiva.\n",
      "--- FINISHED source sip_unidad_deportiva. Mean city time = 112.37620133313291\n",
      "Analysing source sip_espacio_publico.\n",
      "--- Getting clues/sip source pois code 9321 from previously downloaded.\n",
      "--- 272 sip_espacio_publico pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_espacio_publico.\n",
      "Starting time analysis for sip_espacio_publico.\n",
      "Starting range k = 1 of 2 for sip_espacio_publico.\n",
      "Starting range k = 2 of 2 for sip_espacio_publico.\n",
      "Finished time analysis for sip_espacio_publico.\n",
      "--- FINISHED source sip_espacio_publico. Mean city time = 29.558058698670447\n",
      "Analysing source denue_parque_natural.\n",
      "--- Downloading denue source pois code 712190 from db.\n",
      "--- 0 denue_parque_natural pois. Analysing source pois proximity to nodes.\n",
      "0 denue_parque_natural found. Time set to np.nan for all nodes.\n",
      "0 denue_parque_natural found. Pois count set to nan for all nodes.\n",
      "--- FINISHED source denue_parque_natural. Mean city time = nan\n",
      "Analysing source denue_cines.\n",
      "--- Downloading denue source pois code 512130 from db.\n",
      "--- 9 denue_cines pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_cines.\n",
      "Starting time analysis for denue_cines.\n",
      "Starting range k = 1 of 1 for denue_cines.\n",
      "Finished time analysis for denue_cines.\n",
      "--- FINISHED source denue_cines. Mean city time = 105.6534675560215\n",
      "Analysing source denue_museos.\n",
      "--- Downloading denue source pois code 712111 from db.\n",
      "--- Downloading denue source pois code 712112 from db.\n",
      "--- 14 denue_museos pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_museos.\n",
      "Starting time analysis for denue_museos.\n",
      "Starting range k = 1 of 1 for denue_museos.\n",
      "Finished time analysis for denue_museos.\n",
      "--- FINISHED source denue_museos. Mean city time = 128.87819266239387\n",
      "Analysing source denue_bibliotecas.\n",
      "--- Downloading denue source pois code 519121 from db.\n",
      "--- Downloading denue source pois code 519122 from db.\n",
      "--- 29 denue_bibliotecas pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_bibliotecas.\n",
      "Starting time analysis for denue_bibliotecas.\n",
      "Starting range k = 1 of 1 for denue_bibliotecas.\n",
      "Finished time analysis for denue_bibliotecas.\n",
      "--- FINISHED source denue_bibliotecas. Mean city time = 61.859031476080055\n",
      "Analysing source denue_centrocultural.\n",
      "--- Downloading denue source pois code 711312 from db.\n",
      "--- 18 denue_centrocultural pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_centrocultural.\n",
      "Starting time analysis for denue_centrocultural.\n",
      "Starting range k = 1 of 1 for denue_centrocultural.\n",
      "Finished time analysis for denue_centrocultural.\n",
      "--- FINISHED source denue_centrocultural. Mean city time = 95.74208895980841\n",
      "FINISHED source pois proximity to nodes analysis for Aguascalientes.\n",
      "(51434, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>denue_restaurante_insitu</th>\n",
       "      <th>denue_restaurante_insitu_15min</th>\n",
       "      <th>denue_restaurante_llevar</th>\n",
       "      <th>denue_restaurante_llevar_15min</th>\n",
       "      <th>denue_bares</th>\n",
       "      <th>denue_bares_15min</th>\n",
       "      <th>denue_cafe</th>\n",
       "      <th>denue_cafe_15min</th>\n",
       "      <th>sip_cancha</th>\n",
       "      <th>...</th>\n",
       "      <th>denue_cines_15min</th>\n",
       "      <th>denue_museos</th>\n",
       "      <th>denue_museos_15min</th>\n",
       "      <th>denue_bibliotecas</th>\n",
       "      <th>denue_bibliotecas_15min</th>\n",
       "      <th>denue_centrocultural</th>\n",
       "      <th>denue_centrocultural_15min</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272921360</td>\n",
       "      <td>0.58794</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.097719</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.25473</td>\n",
       "      <td>21.0</td>\n",
       "      <td>156.885198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.589368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.761478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102.295073</td>\n",
       "      <td>21.872876</td>\n",
       "      <td>POINT (-102.29507 21.87288)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       osmid  denue_restaurante_insitu  denue_restaurante_insitu_15min  \\\n",
       "0  272921360                   0.58794                           132.0   \n",
       "\n",
       "   denue_restaurante_llevar  denue_restaurante_llevar_15min  denue_bares  \\\n",
       "0                       0.0                            13.0     4.097719   \n",
       "\n",
       "   denue_bares_15min  denue_cafe  denue_cafe_15min  sip_cancha  ...  \\\n",
       "0               18.0     5.25473              21.0  156.885198  ...   \n",
       "\n",
       "   denue_cines_15min  denue_museos  denue_museos_15min  denue_bibliotecas  \\\n",
       "0                0.0      7.589368                 1.0          17.761478   \n",
       "\n",
       "   denue_bibliotecas_15min  denue_centrocultural  denue_centrocultural_15min  \\\n",
       "0                      0.0             15.222128                         0.0   \n",
       "\n",
       "            x          y                     geometry  \n",
       "0 -102.295073  21.872876  POINT (-102.29507 21.87288)  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Added option for source being odc (In order to get from BD parques)\n",
    "####################################################################################################################################\n",
    "\n",
    "# 1.3 --------------- ANALYSE POINTS OF INTEREST (If denue, downloads)\n",
    "# ------------------- This step analysis times (and count of pois at given time proximity if requested) using function aup.pois_time.\n",
    "\n",
    "poly_wkt = aoi.dissolve().geometry.to_wkt()[0]\n",
    "\n",
    "i = 0\n",
    "analysis_cols = []\n",
    "\n",
    "for eje in parameters.keys():\n",
    "    for amenity in parameters[eje]:\n",
    "        for source in parameters[eje][amenity]:\n",
    "\n",
    "            print(f\"\"\"Analysing source {source}.\"\"\")\n",
    "            \n",
    "            analysis_cols.append(source)\n",
    "            if count_pois[0]:\n",
    "                count_col = f'{source}_{count_pois[1]}min'\n",
    "                analysis_cols.append(count_col)\n",
    "            \n",
    "            # ANALYSIS - Select source points of interest\n",
    "            source_pois = gpd.GeoDataFrame()\n",
    "            for code in parameters[eje][amenity][source]:\n",
    "                #If source is denue:\n",
    "                if source[0] == 'd':\n",
    "                    print(f'--- Downloading denue source pois code {code} from db.')\n",
    "                    code_pois = get_denue_pois(denue_schema,denue_table,poly_wkt,code,version)\n",
    "                #If source is clues or sip:\n",
    "                elif source[0] == 'c' or source[0] == 's':\n",
    "                    print(f'--- Getting clues/sip source pois code {code} from previously downloaded.')\n",
    "                    code_pois = sip_clues_gdf.loc[sip_clues_gdf['code'] == code]\n",
    "                # If source is odc (Get from bd parques)\n",
    "                elif source[0] == 'o':\n",
    "                    print(f'--- Downloading parks source pois code {code} from db.')\n",
    "                    code_pois = get_parques_pois(parques_schema,parques_table,code)\n",
    "                else:\n",
    "                    print(f'--- Error, check parameters dicctionary.')\n",
    "                    print(f'--- Sources must start with denue_, clues_, odc_ or sip_.')\n",
    "                    intended_crash\n",
    "                    \n",
    "                source_pois = pd.concat([source_pois,code_pois])\n",
    "\n",
    "            print(f\"--- {source_pois.shape[0]} {source} pois. Analysing source pois proximity to nodes.\")\n",
    "            \n",
    "            # ANALYSIS - Calculate times from nodes to source\n",
    "            source_nodes_time = aup.pois_time(G, nodes, edges, source_pois, source, prox_measure,count_pois)\n",
    "            source_nodes_time.rename(columns={'time_'+source:source},inplace=True)\n",
    "            if count_pois[0]:\n",
    "                source_nodes_time = source_nodes_time[['osmid',source,count_col,'x','y','geometry']]\n",
    "            else:\n",
    "                source_nodes_time = source_nodes_time[['osmid',source,'x','y','geometry']]\n",
    "\n",
    "            # ANALYSIS - Merge all times in one df\n",
    "            if i == 0: # For the first analysed source\n",
    "                nodes_analysis = source_nodes_time.copy()\n",
    "            else: # For the rest\n",
    "                if count_pois[0]:\n",
    "                    nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source,count_col]],on='osmid')\n",
    "                else:\n",
    "                    nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source]],on='osmid')\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "            print(f\"--- FINISHED source {source}. Mean city time = {nodes_analysis[source].mean()}\")\n",
    "        \n",
    "# Final format for nodes\n",
    "column_order = ['osmid'] + analysis_cols + ['x','y','geometry']\n",
    "nodes_analysis = nodes_analysis[column_order]\n",
    "\n",
    "print(f\"\"\"FINISHED source pois proximity to nodes analysis for {city}.\"\"\")\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis.shape)\n",
    "nodes_analysis.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5160cc8b-e34a-4567-8cce-d5461777d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################### PART 2 ###############################################################\n",
    "######################################################### AMENITIES ANALYSIS #########################################################\n",
    "######################################################### (PREV. SCRIPT 15) ##########################################################\n",
    "\n",
    "# 2.0 --------------- DEFINITIONS DICTIONARY\n",
    "# ------------------- On script 15 a dictionary (idx_15_min) is used to calculate the times to amenities.\n",
    "# ------------------- This step creates the definitions dicc out of the main parameters dicc.\n",
    "\n",
    "definitions = {}\n",
    "for eje in parameters.keys():\n",
    "    # tmp_dicc is {amenity:[source_list]} for each eje\n",
    "    tmp_dicc = {}\n",
    "    for amenity in parameters[eje]:\n",
    "        items_lst = []\n",
    "        items = list(parameters[eje][amenity].items())\n",
    "        for item in items:\n",
    "            items_lst.append(item[0])\n",
    "        tmp_dicc[amenity] = items_lst\n",
    "    # Each eje gets assigned its own tmp_dicc\n",
    "    definitions[eje] = tmp_dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48344a57-652f-42c8-b5f7-cf2552f9d811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished missing source amenities analysis. 0 not present source amenities were added as np.nan columns.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 --------------- FILL FOR MISSING AMENITIES\n",
    "# ------------------- This step originates on script 15, where each cities nodes time data was loaded from db.\n",
    "# ------------------- Even though its no longer needed, it remains usefull for avoiding crashes.\n",
    "# ------------------- Definitions dicc (Previously, on script 15, called idx_15_min dictionary) is also used in the next steps.\n",
    "\n",
    "all_sources = []\n",
    "# Gather all possible sources\n",
    "for eje in definitions.keys():\n",
    "    for amenity in definitions[eje].values():\n",
    "        for source in amenity:\n",
    "            all_sources.append(source)\n",
    "\n",
    "# If source not in currently analized city, fill column with np.nan\n",
    "column_list = list(nodes_analysis.columns)\n",
    "missing_sourceamenities = []\n",
    "for s in all_sources:\n",
    "        if s not in column_list:\n",
    "            nodes_analysis[s] = np.nan\n",
    "            print(f\"--- {s} source amenity is not present in {city}.\")\n",
    "            missing_sourceamenities.append(s)\n",
    "print(f\"--- Finished missing source amenities analysis. {len(missing_sourceamenities)} not present source amenities were added as np.nan columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcef1ac7-9030-4fd9-b777-7d5a164439d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting proximity to amenities analysis by node.\n",
      "--- Calculated proximity to amenities data by node.\n",
      "(51434, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.222128</td>\n",
       "      <td>5.254730</td>\n",
       "      <td>5.692959</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>272921360</td>\n",
       "      <td>POINT (-102.29507 21.87288)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.979920</td>\n",
       "      <td>6.647844</td>\n",
       "      <td>8.243084</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>272921393</td>\n",
       "      <td>POINT (-102.29510 21.87141)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            15.222128    5.254730              5.692959     15.222128   \n",
       "1            12.979920    6.647844              8.243084     12.979920   \n",
       "\n",
       "    max_time      osmid                     geometry  \n",
       "0  15.222128  272921360  POINT (-102.29507 21.87288)  \n",
       "1  12.979920  272921393  POINT (-102.29510 21.87141)  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2a -------------- AMENITIES ANALYSIS (amenities, ejes and max_time calculation)\n",
    "# ------------------- This step calculates times by amenity (preescolar/primaria/etc) using the previously created \n",
    "# ------------------- definitions dictionary (Previously, on script 15, called idx_15_min dictionary)\n",
    "# ------------------- and using weights dictionary to decide which time to use (min/max/other)\n",
    "\n",
    "print(\"--- Starting proximity to amenities analysis by node.\")\n",
    "\n",
    "column_max_all = [] # list with all max times column names\n",
    "column_max_ejes = [] # list with ejes max times column names\n",
    "\n",
    "#Goes through each eje in dictionary:\n",
    "for e in definitions.keys():\n",
    "\n",
    "    #Appends to lists currently examined eje\n",
    "    column_max_all.append('max_'+ e.lower())\n",
    "    column_max_ejes.append('max_'+ e.lower())\n",
    "    column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "    #Goes through each amenity of current eje:\n",
    "    for a in definitions[e].keys():\n",
    "\n",
    "        #Appends to lists currently examined amenity:\n",
    "        column_max_all.append('max_'+ a.lower())\n",
    "        column_max_amenities.append('max_'+ a.lower())\n",
    "\n",
    "        #Calculates time to currently examined amenity:\n",
    "        #Uses source_weight dictionary to decide which time to use.\n",
    "        weight = source_weight[e][a]\n",
    "        if weight == 'min': # To know distance to closest source amenity.\n",
    "                            # If it doesn't matter which one is closest (e.g. Alimentos).\n",
    "            nodes_analysis['max_'+ a.lower()] = nodes_analysis[definitions[e][a]].min(axis=1)\n",
    "\n",
    "        elif weight == 'max': # To know distance to farthest source amenity.\n",
    "                              # If need to know proximity to all of the options (e.g. Social)\n",
    "            nodes_analysis['max_'+ a.lower()] = nodes_analysis[definitions[e][a]].max(axis=1)\n",
    "\n",
    "        elif weight == 'two-method': #'two-method' (for cultural amenity's sources).\n",
    "                                     # See two_method_check function definition for explanation.\n",
    "            # Check which sources are within 15 minutes\n",
    "            check_lst = []\n",
    "            for s in definitions[e][a]:\n",
    "                nodes_analysis[s+'_check'] = nodes_analysis[s].apply(lambda x: 1 if x <= 15 else 0)\n",
    "                check_lst.append(s+'_check')\n",
    "            # Check how many sources are within 15 minutes\n",
    "            nodes_analysis['check_count'] = nodes_analysis[check_lst].sum(axis=1)\n",
    "            # Apply two method check\n",
    "            nodes_analysis = nodes_analysis.apply(two_method_check,axis='columns')\n",
    "            # Drop columns used for checking\n",
    "            check_lst.append('check_count')\n",
    "            nodes_analysis.drop(columns=check_lst,inplace=True)\n",
    "        else:\n",
    "            # Crash on purpose and raise error\n",
    "            print(\"--- Error in source_weight dicc.\")\n",
    "            print(\"--- Must pass 'min', 'max' or 'two-method'\")\n",
    "            intended_crash\n",
    "\n",
    "    #Calculates time to currently examined eje (max time of its amenities):\n",
    "    nodes_analysis['max_'+ e.lower()] = nodes_analysis[column_max_amenities].max(axis=1) \n",
    "\n",
    "# Set and calculate max time\n",
    "index_column = 'max_time' # column name for maximum time data\n",
    "column_max_all.append(index_column) #Adds to column_max_all list the attribute 'max_time'\n",
    "nodes_analysis[index_column] = nodes_analysis[column_max_ejes].max(axis=1) #Assigns \"max_time\" the max time for all ejes   \n",
    "\n",
    "# Add to column_max_all list the attributes 'osmid' and 'geometry' to filter nodes_analysis.\n",
    "# Looking for data of importance: columns in column_max_all list\n",
    "column_max_all.append('osmid')\n",
    "column_max_all.append('geometry')\n",
    "nodes_timeanalysis_filter = nodes_analysis[column_max_all].copy()\n",
    "    \n",
    "print(\"--- Calculated proximity to amenities data by node.\")\n",
    "\n",
    "# Show\n",
    "print(nodes_timeanalysis_filter.shape)\n",
    "nodes_timeanalysis_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98e55505-041f-4ebd-9e34-acdaaef1a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51434, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.222128</td>\n",
       "      <td>5.254730</td>\n",
       "      <td>5.692959</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>272921360</td>\n",
       "      <td>POINT (-102.29507 21.87288)</td>\n",
       "      <td>188.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.979920</td>\n",
       "      <td>6.647844</td>\n",
       "      <td>8.243084</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>272921393</td>\n",
       "      <td>POINT (-102.29510 21.87141)</td>\n",
       "      <td>209.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            15.222128    5.254730              5.692959     15.222128   \n",
       "1            12.979920    6.647844              8.243084     12.979920   \n",
       "\n",
       "    max_time      osmid                     geometry  entretenimiento_15min  \\\n",
       "0  15.222128  272921360  POINT (-102.29507 21.87288)                  188.0   \n",
       "1  12.979920  272921393  POINT (-102.29510 21.87141)                  209.0   \n",
       "\n",
       "   social_15min  actividad física_15min  cultural_15min  \n",
       "0         184.0                     3.0             1.0  \n",
       "1         204.0                     3.0             2.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2b -------------- AMENITIES COUNT ANALYSIS (amenities at given time count, optional)\n",
    "# ------------------- Similar to previous amenities analysis, this step (optional, added later)\n",
    "# ------------------- calculates how many amenities there are at a given time proximity (count_pois = (Boolean,time))\n",
    "\n",
    "if count_pois[0]:\n",
    "    column_count_all = []\n",
    "    \n",
    "    # Go through each eje\n",
    "    for eje in definitions.keys():\n",
    "        # Name of count eje\n",
    "        eje_count_colname = f'{eje}_{count_pois[1]}min'.lower()\n",
    "        # Append to lists\n",
    "        column_count_all.append(eje_count_colname)\n",
    "    \n",
    "        # Go through eje's amenities\n",
    "        column_count_amenities = []\n",
    "        for amenity in definitions[eje]:\n",
    "            # Name of count amenity\n",
    "            amenity_count_colname = f'{amenity}_{count_pois[1]}min'.lower()\n",
    "            # Append to lists\n",
    "            column_count_all.append(amenity_count_colname)\n",
    "            column_count_amenities.append(amenity_count_colname)\n",
    "    \n",
    "            # Gather amenities sources\n",
    "            column_count_sources = [] # Just used for sum function, not added at final output\n",
    "            for source in definitions[eje][amenity]:\n",
    "                # Add to sources list\n",
    "                source_count_colname = f'{source}_{count_pois[1]}min'\n",
    "                column_count_sources.append(source_count_colname)\n",
    "            # Find sum of all sources found within given time of each node (For current amenity)\n",
    "            nodes_analysis[amenity_count_colname] = nodes_analysis[column_count_sources].sum(axis=1)\n",
    "    \n",
    "        # Find sum of all sources found within given time of each node (For current eje)\n",
    "        nodes_analysis[eje_count_colname] = nodes_analysis[column_count_amenities].sum(axis=1)\n",
    "    \n",
    "    # Filter for columns of interest\n",
    "    column_count_all.append('osmid')\n",
    "    nodes_countanalysis_filter = nodes_analysis[column_count_all]\n",
    "    nodes_analysis_filter = pd.merge(nodes_timeanalysis_filter,nodes_countanalysis_filter,on='osmid')\n",
    "\n",
    "else:\n",
    "    nodes_analysis_filter = nodes_timeanalysis_filter.copy()\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis_filter.shape)\n",
    "nodes_analysis_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67dfbd13-b343-4bec-b625-d08ef35313b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 --------------- POPULATION DATA\n",
    "# ------------------- This step (optional) loads hexagons with population data.\n",
    "######################################################################################################################################\n",
    "# ------------------- This steps final code must be reviewed according to new pop data names in the db.\n",
    "# ------------------- Currently, only hex_bins_pop_2020 is 8\n",
    "if pop_output:\n",
    "    res_list = [8]\n",
    "    print(f\"--- Set res_list to 8 only. pop_output currently only generates res 8 data.\")\n",
    "######################################################################################################################################\n",
    "\n",
    "if pop_output:\n",
    "    hex_socio_gdf = gpd.GeoDataFrame()\n",
    "    # Downloads hex_socio_gdf for city area\n",
    "    for res in res_list:\n",
    "        # Download\n",
    "        hex_pop_res = aup.gdf_from_polygon(aoi, pop_schema, pop_table, geom_col=\"geometry\")\n",
    "        hex_pop_res = hex_pop_res.set_crs(\"EPSG:4326\")\n",
    "        print(f\"--- Downloaded pop gdf res {res}.\")\n",
    "\n",
    "        # Format\n",
    "        hex_pop_res.rename(columns={f'hex_id_{res}':'hex_id'},inplace=True)\n",
    "        hex_pop_res['res'] = res\n",
    "        \n",
    "        # Calculate fields of interest\n",
    "        hex_pop_res_tmp = hex_pop_res.to_crs(\"EPSG:6372\")\n",
    "        hex_pop_res_tmp['dens_pob_ha'] = hex_pop_res_tmp['pobtot'] / (hex_pop_res_tmp.area / 10000)\n",
    "\n",
    "        # Merge calculated fields to hex_pop_res gdf\n",
    "        hex_pop_res_tmp = hex_pop_res_tmp[['hex_id','dens_pob_ha']]\n",
    "        hex_pop_res = pd.merge(hex_pop_res,hex_pop_res_tmp,on='hex_id')\n",
    "\n",
    "        # Save fields of interest for current res\n",
    "        pop_fields = ['pobtot','dens_pob_ha']\n",
    "        hex_socio_gdf = pd.concat([hex_socio_gdf,hex_pop_res[['hex_id','res']+pop_fields+['geometry']]])\n",
    "        print(f\"--- Saved pop gdf res {res}.\")\n",
    "\n",
    "    # Show\n",
    "    print(hex_socio_gdf.shape)\n",
    "    print(hex_socio_gdf.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93799231-f2a1-4844-ad31-11e2d72772cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resolution 7 removed from res_list. This res is not allowed in version 2.\n",
      "--- Resolution 12 removed from res_list. This res is not allowed in version 2.\n",
      "--- Loaded hexgrid of resolution 8.\n",
      "--- Grouped nodes data by hexagons res 8.\n",
      "--- Saved grouped data by hexagons res 8.\n",
      "--- Loaded hexgrid of resolution 9.\n",
      "--- Grouped nodes data by hexagons res 9.\n",
      "--- Saved grouped data by hexagons res 9.\n",
      "--- Loaded hexgrid of resolution 10.\n",
      "--- Grouped nodes data by hexagons res 10.\n",
      "--- Saved grouped data by hexagons res 10.\n",
      "--- Loaded hexgrid of resolution 11.\n",
      "--- Grouped nodes data by hexagons res 11.\n",
      "--- Saved grouped data by hexagons res 11.\n",
      "(58255, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  88498e3289fffff  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "    max_time  entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0  59.692444                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  res  \n",
       "0             0.0    8  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.4 --------------- GROUP DATA BY HEX\n",
    "# ------------------- This groups nodes data by hexagon.\n",
    "# ------------------- If pop output, uses previously created hexes. Else, creates hexgrid.\n",
    "\n",
    "# Prevent crashing from trying not allowed resolutions.\n",
    "checked_res_list = []\n",
    "if version == 1:\n",
    "    allowed_res = [8,9]\n",
    "    for res in res_list:\n",
    "        if res in allowed_res:\n",
    "            checked_res_list.append(res)\n",
    "        else:\n",
    "            print(f\"--- Resolution {res} removed from res_list. This res is not allowed in version {version}.\")\n",
    "elif version == 2:\n",
    "    allowed_res = [8,9,10,11]\n",
    "    for res in res_list:\n",
    "        if res in allowed_res:\n",
    "            checked_res_list.append(res)\n",
    "        else:\n",
    "            print(f\"--- Resolution {res} removed from res_list. This res is not allowed in version {version}.\")\n",
    "res_list = checked_res_list.copy()\n",
    "\n",
    "hex_idx = gpd.GeoDataFrame()\n",
    "for res in res_list:\n",
    "    # Load or create hexgrid\n",
    "    # If pop_output is true, loads previously created hexgrid with pop data\n",
    "    if pop_output:\n",
    "        # Load hexgrid\n",
    "        hex_pop = hex_socio_gdf.loc[hex_socio_gdf['res'] == res]\n",
    "        # Function group_by_hex_mean requires ID to include resolution\n",
    "        hex_pop.rename(columns={'hex_id':f'hex_id_{res}'},inplace=True)\n",
    "        # Create hex_tmp (id and geometry)\n",
    "        hex_pop = hex_pop.to_crs(\"EPSG:4326\")\n",
    "        hex_tmp = hex_pop[[f'hex_id_{res}','geometry']].copy()\n",
    "        print(f\"--- Loaded pop hexgrid of resolution {res}.\")\n",
    "        \n",
    "    # If pop_output is false, creates hexgrid\n",
    "    else:\n",
    "        if version == 1:\n",
    "            hex_table = f'hexgrid_{res}_city'\n",
    "            query = f\"SELECT * FROM {hex_schema}.{hex_table} WHERE \\\"metropolis\\\" LIKE \\'{city}\\'\"\n",
    "        elif version == 2:\n",
    "            hex_table = f'hexgrid_{res}_city_2020'\n",
    "            query = f\"SELECT * FROM {hex_schema}.{hex_table} WHERE \\\"city\\\" LIKE \\'{city}\\'\"\n",
    "        else:\n",
    "            print(\"--- Error in specified proximity analysis version.\")\n",
    "            print(\"--- Must pass integers 1 or 2.\")\n",
    "            intended_crash\n",
    "\n",
    "        # Load hexgrid (which already has ID_res)\n",
    "        hexgrid = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "        # Create hex_tmp\n",
    "        hex_tmp = hexgrid.set_crs(\"EPSG:4326\")\n",
    "        hex_tmp = hex_tmp[[f'hex_id_{res}','geometry']].copy()\n",
    "        print(f\"--- Loaded hexgrid of resolution {res}.\")\n",
    "    \n",
    "    # Group time data by hex\n",
    "    hex_res_idx = aup.group_by_hex_mean(nodes_analysis_filter, hex_tmp, res, index_column)\n",
    "    hex_res_idx = hex_res_idx.loc[hex_res_idx[index_column]>0].copy()\n",
    "    print(f\"--- Grouped nodes data by hexagons res {res}.\")\n",
    "    \n",
    "    # If pop_output is true, add pop data\n",
    "    if pop_output:\n",
    "        pop_list = pop_fields.copy()\n",
    "        pop_list.append(f'hex_id_{res}')\n",
    "        hex_res_pop = pd.merge(hex_res_idx, hex_pop[pop_list], on=f'hex_id_{res}')\n",
    "    else:\n",
    "        hex_res_pop = hex_res_idx.copy()\n",
    "    \n",
    "    # After funtion group_by_hex_mean we can remove res from ID and set as a column\n",
    "    hex_res_pop.rename(columns={f'hex_id_{res}':'hex_id'},inplace=True)\n",
    "    hex_res_pop['res'] = res\n",
    "\n",
    "    # Finally, add to hex_idx each resolution processing\n",
    "    hex_idx = pd.concat([hex_idx,hex_res_pop])\n",
    "    print(f\"--- Saved grouped data by hexagons res {res}.\")\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5a7e222-9f4d-471e-a2c6-9c2ee9e20b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished recalculating ejes times in hexagons.\n",
      "(58255, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  88498e3289fffff  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "    max_time  entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0  59.692444                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  res  \n",
       "0             0.0    8  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################### PART 3 ###############################################################\n",
    "#################################################### RECALCULATION AND FINAL DATA ####################################################\n",
    "#################################################### (PREV. SCRIPT 15 + NEW DATA) ####################################################\n",
    "\n",
    "# 3.1 --------------- RE-CALCULATE MAX TIMES BY HEXAGON\n",
    "# ------------------- This step recalculates max time to each eje  \n",
    "# ------------------- from max times to calculated amenities \n",
    "\n",
    "#Goes (again) through each eje in dictionary:\n",
    "for e in definitions.keys():\n",
    "    column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "    #Goes (again) through each amenity of current eje:    \n",
    "    for a in definitions[e].keys():\n",
    "        column_max_amenities.append('max_'+ a.lower())\n",
    "    #Re-calculates time to currently examined eje (max time of its amenities):        \n",
    "    hex_idx['max_'+ e.lower()] = hex_idx[column_max_amenities].max(axis=1)\n",
    "\n",
    "print('--- Finished recalculating ejes times in hexagons.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea87895f-03d2-4fe0-a73a-fadbcbdbcc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished calculating index, mean, median and max time.\n",
      "(58255, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>res</th>\n",
       "      <th>idx_social</th>\n",
       "      <th>idx_actividad física</th>\n",
       "      <th>idx_cultural</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>idx_sum</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01275</td>\n",
       "      <td>0.248565</td>\n",
       "      <td>0.199486</td>\n",
       "      <td>45.576902</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>0.460801</td>\n",
       "      <td>Aguascalientes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  88498e3289fffff  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "    max_time  entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0  59.692444                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  res  idx_social  idx_actividad física  idx_cultural  \\\n",
       "0             0.0    8     0.01275              0.248565      0.199486   \n",
       "\n",
       "   mean_time  median_time   idx_sum            city  \n",
       "0  45.576902    39.485914  0.460801  Aguascalientes  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 --------------- CALCULATE AND ADD ADDITIONAL AND FINAL DATA\n",
    "# ------------------- This step adds mean, median, city and idx data to each hex\n",
    "\n",
    "#Define idx function\n",
    "def apply_sigmoidal(x):\n",
    "    if x == -1:\n",
    "        return -1\n",
    "    elif x > 1000:\n",
    "        return 0\n",
    "    else:\n",
    "        val = aup.sigmoidal_function(0.1464814753435666, x, 30)\n",
    "        return val\n",
    "\n",
    "# Create all amenities list (previosly we had amenities list by eje) from column_max_ejes\n",
    "max_amenities_cols = [i for i in column_max_all if i not in column_max_ejes]\n",
    "max_amenities_cols.remove('max_time')\n",
    "max_amenities_cols.remove('osmid')\n",
    "max_amenities_cols.remove('geometry')\n",
    "# Create list with idx column names\n",
    "idx_amenities_cols = []\n",
    "for ac in max_amenities_cols:\n",
    "    idx_col = ac.replace('max','idx')\n",
    "    hex_idx[idx_col] = hex_idx[ac].apply(apply_sigmoidal)\n",
    "    idx_amenities_cols.append(idx_col)\n",
    "# Add final data\n",
    "hex_idx[index_column] = hex_idx[column_max_ejes].max(axis=1)\n",
    "hex_idx['mean_time'] = hex_idx[max_amenities_cols].mean(axis=1)\n",
    "hex_idx['median_time'] = hex_idx[max_amenities_cols].median(axis=1)\n",
    "hex_idx['idx_sum'] = hex_idx[idx_amenities_cols].sum(axis=1)\n",
    "hex_idx['city'] = city\n",
    "\n",
    "print('--- Finished calculating index, mean, median and max time.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6dfc035-4a3b-42e2-9b56-ef9c397df84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished final format for gdf.\n",
      "(58255, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>res</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>idx_social</th>\n",
       "      <th>idx_actividad física</th>\n",
       "      <th>idx_cultural</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>idx_sum</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>8</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01275</td>\n",
       "      <td>0.248565</td>\n",
       "      <td>0.199486</td>\n",
       "      <td>45.576902</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.460801</td>\n",
       "      <td>Aguascalientes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id  res                                           geometry  \\\n",
       "0  88498e3289fffff    8  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "   entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  idx_social  idx_actividad física  idx_cultural  mean_time  \\\n",
       "0             0.0     0.01275              0.248565      0.199486  45.576902   \n",
       "\n",
       "   median_time   max_time   idx_sum            city  \n",
       "0    39.485914  59.692444  0.460801  Aguascalientes  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3 --------------- FINAL FORMAT\n",
    "# ------------------- This step gives final format to the gdf\n",
    "\n",
    "# First elements of ordered column list - ID and geometry\n",
    "final_column_ordered_list = ['hex_id','res','geometry']\n",
    "\n",
    "# Second elements of ordered column list - max_ejes and max_amenities \n",
    "# removing max_time, osmid and geometry.\n",
    "column_max_ejes_amenities = column_max_all.copy()\n",
    "column_max_ejes_amenities.remove('max_time')\n",
    "column_max_ejes_amenities.remove('osmid')\n",
    "column_max_ejes_amenities.remove('geometry')\n",
    "final_column_ordered_list = final_column_ordered_list + column_max_ejes_amenities\n",
    "\n",
    "# Third elements of ordered column list - count pois columns (if requested)\n",
    "# removing osmid and geometry.\n",
    "if count_pois[0]:\n",
    "    third_elements = column_count_all.copy()\n",
    "    third_elements.remove(\"osmid\")\n",
    "    final_column_ordered_list = final_column_ordered_list + third_elements\n",
    "\n",
    "# Fourth elements of ordered list are listed in idx_amenities_cols\n",
    "final_column_ordered_list = final_column_ordered_list + idx_amenities_cols\n",
    "\n",
    "# Fifth elements of ordered list - Final mean, median, max and idx\n",
    "fifth_elements = ['mean_time', 'median_time', 'max_time', 'idx_sum']\n",
    "final_column_ordered_list = final_column_ordered_list + fifth_elements\n",
    "\n",
    "# Sixth elements - If pop is calculated - Pop data\n",
    "if pop_output:\n",
    "    final_column_ordered_list = final_column_ordered_list + pop_fields\n",
    "\n",
    "# Last element - City data\n",
    "final_column_ordered_list.append('city')\n",
    "\n",
    "# Filter/reorder final output    \n",
    "hex_idx_city = hex_idx[final_column_ordered_list]\n",
    "    \n",
    "print('--- Finished final format for gdf.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx_city.shape)\n",
    "hex_idx_city.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fab92b30-759e-4ea9-8ca7-43c502eaee34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_entretenimiento', 'max_social', 'max_actividad física', 'max_cultural']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_max_ejes_amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f8320-9466-427d-bcf9-24231ee71b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS-10.0",
   "language": "python",
   "name": "gds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
