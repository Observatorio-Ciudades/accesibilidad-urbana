{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67abf553-9ca7-4d41-a815-308d0e65e3e8",
   "metadata": {},
   "source": [
    "# Script 21 - (Updated up to date 2024-01-30) adjusted to project: Volvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458cecb7-157f-4b0d-8983-e62e874660e2",
   "metadata": {},
   "source": [
    "This notebook is based on Script 21 (Most recent proximity script), created on 2024-01-30.\n",
    "\n",
    "__The notebook differs from regular proxmity analysis in:__\n",
    "* Area of Interest: Guadalajara only.\n",
    "* Points of Interest (Eje-amenidad)\n",
    "    * Escuelas: Preescolar, primaria, secundaria, *__guarderías__*\n",
    "    * Salud: CLUES, *__farmacias__*\n",
    "    * *__Parques: Parques de Guadalajara__*\n",
    "    * *__Equip. Deportivos:__* Canchas, unidades deportivas\n",
    "    * *__Cultural:__* Cines, museos, bibliotecas\n",
    "    * *__Financieros: Bancos__*\n",
    " \n",
    "* __Processing:__\n",
    "    * Por amenidad:\n",
    "        * Proximidad (tiempo)\n",
    "        * Conteo de amenidades a 15 minutos\n",
    "    * Por eje:\n",
    "        * Tiempo mínimo a amenidades (al más cercano)\n",
    "        * Suma del conteo de las amenidades a 15 minutos   \n",
    "\n",
    "* Output: Generates res9\n",
    "* Output name: _______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c3e5e-e5dc-4ab6-8617-dd28b7dc5eca",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ace2cd4-cfc1-4cb2-97d2-0d39eca03b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/aup/data.py:25: UserWarning: The `utils.config` function is deprecated and will be removed in a future release. Instead, use the `settings` module directly to configure a global setting's value. For example, `ox.settings.log_console=True`.\n",
      "  ox.config(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    import aup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a311f-da69-42ae-9ffc-276b9ae1ab47",
   "metadata": {},
   "source": [
    "## Required script 21 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee368c1-fab8-4f81-a210-5de1b9fc783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Version option (1 or 2) was removed because it will run bibliotecas (Version 2) but look for min time (Version 1), not two-method (Version 2).\n",
    "####################################################################################################################################\n",
    "\n",
    "city = 'Guadalajara'\n",
    "\n",
    "# ---------------------------- BASE DATA REQUIRED ----------------------------\n",
    "# Area of interest (city)\n",
    "metro_schema = 'metropolis'\n",
    "metro_table = 'metro_gdf_2020' #'metro_gdf_2015' or 'metro_gdf_2020'\n",
    "# Network data (nodes and edges table for distance analysis,\n",
    "# also used to generate the network G with which the nearest OSMID is assigned to each poi)\n",
    "network_schema = 'osmnx'\n",
    "nodes_table = 'nodes' #'nodes' or 'nodes_23_point'\n",
    "edges_table = 'edges_speed' ################################################################################################## PENDIENTE\n",
    "# Points of interest - DENUE\n",
    "denue_schema = 'denue'\n",
    "denue_table = 'denue_23_point' #'denue_2020' or 'denue_23_point'\n",
    "# Points of interest - CLUES\n",
    "clues_schema = 'denue'\n",
    "clues_table = 'clues_23_point' #'clues' or 'clues_23_point'\n",
    "# Points of interest - SIP\n",
    "sip_schema = 'denue'\n",
    "sip_table = 'sip_23_point' #'sip_2020' or 'sip_23_point'\n",
    "# Points of interest - Espacio publico (Parques) ### Exclusive project Volvo\n",
    "parques_schema = 'espacios_publicos' \n",
    "parques_table = 'ep_amg'\n",
    "# Hexgrid\n",
    "hex_schema = 'hexgrid'\n",
    "# Population data\n",
    "pop_schema = 'censo'\n",
    "pop_table = 'hex_censo_mza_2020_res9'\n",
    "\n",
    "# ---------------------------- ANALYSIS AND OUTPUT OPTIONS ----------------------------\n",
    "# Network distance method used in function pois_time. (If length, assumes pedestrian speed of 4km/hr.)\n",
    "prox_measure = 'time_min' # Must pass 'length' or 'time_min'\n",
    "\n",
    "# Count available amenities at given time proximity (minutes)?\n",
    "count_pois = (True,15) # Must pass a tupple containing a boolean (True or False) and time proximity of interest in minutes (Boolean,time)\n",
    "\n",
    "# If pop_output = True, loads pop data from pop_schema and pop_table.\n",
    "# If pop_output = False, loads empty hexgrid.\n",
    "pop_output = True ############################################################## For Volvo, we agreed pop_output=True using hex_censo_mza_2020_res9\n",
    "\n",
    "# Hexagon resolutions of output\n",
    "res_list = [9] \n",
    "\n",
    "# SAVING\n",
    "# Save final output to db?\n",
    "save = False\n",
    "save_schema = 'prox_analysis'\n",
    "save_table = 'proximityanalysis_24_ageb_hex'\n",
    "# Local save? (Runs Aguascalientes for tests)\n",
    "local_save = True\n",
    "local_save_dir = '../../../data/external/temporal_fromjupyter/volvo/proxanalysis_volvo_2024_hex9.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af9141ff-3d88-4c90-9deb-96d88e3ad4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Adjusted diccs for project Volvo.\n",
    "####################################################################################################################################\n",
    "\n",
    "parameters = {'Escuelas':{'Guarderías':{'denue_guarderias':[624411, 624412]},\n",
    "                          'Preescolar':{'denue_preescolar':[611111, 611112]},\n",
    "                          'Primaria':{'denue_primaria':[611121, 611122]},\n",
    "                          'Secundaria':{'denue_secundaria':[611131, 611132]}\n",
    "                         },\n",
    "              'Salud':{'Primer nivel':{'clues_primer_nivel':[8610]},\n",
    "                       'Farmacias':{'denue_farmacias':[474111,464112]} ########## Volvo: 464111 Farmacias sin minisúper, 464112 Farmacias con minisúper\n",
    "                       },\n",
    "              'Parques':{'Area verde':{'odc_parques':[9321]} ########## Volvo: AGREGAR DE BD, \n",
    "                                                          ########## Se le asignó el code 9321, correspondiente a 'Activities of amusement parks and theme parks'\n",
    "                                                          ########## Fuente del code elegido: International Standard Industrial Classification of all Economic Activities, Rev.4\n",
    "                                                          ########## https://unstats.un.org/unsd/publication/seriesm/seriesm_4rev4e.pdf\n",
    "                        },\n",
    "              'Equipamiento deportivo':{'Canchas':{'sip_cancha':[93110]},\n",
    "                                        'Unidad deportiva':{'sip_unidad_deportiva':[93111]}\n",
    "                                       },\n",
    "              'Cultural':{'Cines':{'denue_cines':[512130]},\n",
    "                          'Museos':{'denue_museos':[712111, 712112]},\n",
    "                          'Bibliotecas':{'denue_bibliotecas':[519121,519122]}\n",
    "                         },\n",
    "              'Financiero':{'Bancos':{'denue_bancos':[522110]} #################################################### Volvo: 522110 Banca Múltiple (Bancos y cajeros)\n",
    "                           }\n",
    "             }\n",
    "\n",
    "source_weight = {'Escuelas':{'Guarderías':'min', #There is only one source, no effect.\n",
    "                             'Preescolar':'min', #There is only one source, no effect.\n",
    "                             'Primaria':'min', #There is only one source, no effect.\n",
    "                             'Secundaria':'min' #There is only one source, no effect.\n",
    "                            },\n",
    "                 'Salud':{'Primer nivel':'min',#There is only one source, no effect.\n",
    "                          'Farmacias':'min'#There is only one source, no effect.\n",
    "                         },\n",
    "                 'Parques':{'Area verde':'min'#There is only one source, no effect.\n",
    "                           },\n",
    "                 'Equipamiento deportivo':{'Canchas':'min',#There is only one source, no effect.\n",
    "                                           'Unidad deportiva':'min'#There is only one source, no effect.\n",
    "                                          },\n",
    "                 'Cultural':{'Cines':'min',#There is only one source, no effect.\n",
    "                             'Museos':'min',#There is only one source, no effect.\n",
    "                             'Bibliotecas':'min'#There is only one source, no effect.\n",
    "                            },\n",
    "                 'Financiero':{'Bancos':'min'\n",
    "                              }\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75cc2f16-9e0c-4bce-b6f1-84bc7fb581f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Simplified version, does not filter centro cultural nor dif because it is not used in project Volvo.\n",
    "####################################################################################################################################\n",
    "def get_denue_pois(denue_schema,denue_table,poly_wkt,code):\n",
    "    # This function downloads the codigo_act denue poi requested for the analysis.\n",
    "\n",
    "    # Download denue pois\n",
    "    query = f\"SELECT * FROM {denue_schema}.{denue_table} WHERE (ST_Intersects(geometry, \\'SRID=4326;{poly_wkt}\\')) AND (\\\"codigo_act\\\" = \\'{code}\\')\"\n",
    "    code_pois = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "\n",
    "    # Format denue pois\n",
    "    code_pois = code_pois[['codigo_act', 'geometry']]\n",
    "    code_pois = code_pois.rename(columns={'codigo_act':'code'})\n",
    "    code_pois['code'] = code_pois['code'].astype('int64')\n",
    "\n",
    "    return code_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0301f6-0c16-4c70-b33f-53b53ebfb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# NEW\n",
    "# Project Volvo includes 'parques', which are in OdC's DB\n",
    "####################################################################################################################################\n",
    "def get_parques_pois(parques_schema,parques_table,code):\n",
    "    # This function creates parques points of interest out of vertices of parques found in db (schema>table)\n",
    "\n",
    "    # Download parques pois\n",
    "    query = f\"SELECT * FROM {parques_schema}.{parques_table}\"\n",
    "    gdf = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Get vertices coordinates\n",
    "    gdf_coords = gdf.geometry.get_coordinates()\n",
    "\n",
    "    # Merge back with gdf containing data\n",
    "    gdf_coords_data = pd.merge(gdf_coords,gdf,left_index=True,right_index=True)\n",
    "\n",
    "    # Drop poly geometry \n",
    "    df_coords_data = gdf_coords_data.drop(columns=['geometry'])\n",
    "    # Set points geometry\n",
    "    gdf_2 = gpd.GeoDataFrame(df_coords_data, \n",
    "                             geometry=gpd.points_from_xy(df_coords_data.x, df_coords_data.y),\n",
    "                             crs='EPSG:4326')\n",
    "    # Format\n",
    "    gdf_2.drop(columns=['x','y'],inplace=True)\n",
    "    gdf_2.reset_index(inplace=True)\n",
    "    gdf_2.rename(columns={'index':'polygon_id'},inplace=True)\n",
    "\n",
    "    # Project Volvo filter\n",
    "    # Tipos\n",
    "    tipos = ['Parque','Espacio verde vecinal', 'Plaza', 'Área natural', 'Área natural protegida']\n",
    "    gdf_f1 = gdf_2.loc[gdf_2.Tipo.isin(tipos)]\n",
    "    # Usos\n",
    "    gdf_f2 = gdf_f1.loc[gdf_f1.Uso == 'Uso recreativo']\n",
    "\n",
    "    # Proxanalysis filter\n",
    "    #code_pois = gdf_f2.set_crs(\"EPSG:4326\")\n",
    "    gdf_f2['code'] = code\n",
    "    code_pois = gdf_f2[['polygon_id','code','geometry']]\n",
    "    code_pois['code'] = code_pois['code'].astype('int64')\n",
    "\n",
    "    code_pois = code_pois.drop_duplicates()\n",
    "\n",
    "    return code_pois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1028785-32af-4ded-b6b2-9ca673a2a44f",
   "metadata": {},
   "source": [
    "## Script 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eadcfe9-7e76-44fb-93ec-826c39205457",
   "metadata": {},
   "source": [
    "### Part 1.1 and 1.2 - AOI, G, nodes, edges, pois (clues and sip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82e307a-035b-4887-bddb-d24d6f2d16eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184338, 4)\n",
      "(441463, 19)\n"
     ]
    }
   ],
   "source": [
    "############################################################### PART 1 ###############################################################\n",
    "#################################################### FIND NODES PROXIMITY TO POIS ####################################################\n",
    "###################################################### (PREV. SCRIPT 01 + 02) ########################################################\n",
    "\n",
    "# 1.1 --------------- BASE DATA FOR POIS-NODES ANALYSIS\n",
    "# ------------------- This first step downloads the area of interest and network used to measure distance.\n",
    "\n",
    "# Download area of interest\n",
    "query = f\"SELECT * FROM {metro_schema}.{metro_table} WHERE \\\"city\\\" LIKE \\'{city}\\'\"\n",
    "mun_gdf = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "mun_gdf = mun_gdf.set_crs(\"EPSG:4326\")\n",
    "aoi = mun_gdf.dissolve()\n",
    "\n",
    "# Download Network used to calculate nearest note to each poi\n",
    "G, nodes, edges = aup.graph_from_hippo(aoi, schema=network_schema, edges_folder=edges_table, nodes_folder=nodes_table)\n",
    "\n",
    "# Show\n",
    "print(nodes.shape)\n",
    "print(edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d36b56d-fe82-4ca0-b7be-b7e515e9014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# 1.2 --------------- DOWNLOAD POINTS OF INTEREST (clues and sip pois, not denue)\n",
    "# ------------------- This step downloads SIP and CLUES points of interest (denue pois are downloaded later.)\n",
    "sip_clues_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "# CLUES (Salud)\n",
    "aup.log(f\"--- Downloading CLUES pois for {city}.\")\n",
    "# Download\n",
    "clues_gdf = aup.gdf_from_polygon(aoi, clues_schema, clues_table, geom_col=\"geometry\")\n",
    "# Filter\n",
    "clues_pois = clues_gdf.loc[clues_gdf['nivel_atencion'] == 'PRIMER NIVEL']\n",
    "del clues_gdf\n",
    "# Format\n",
    "clues_pois.loc[:,'code'] = 8610\n",
    "clues_pois = clues_pois[['code','geometry']]\n",
    "# Save to pois_tmp\n",
    "sip_clues_gdf = pd.concat([sip_clues_gdf,clues_pois])\n",
    "del clues_pois\n",
    "\n",
    "# SIP (Marco geoestadistico)\n",
    "aup.log(f\"--- Downloading SIP pois for {city}.\")\n",
    "# Download\n",
    "sip_gdf = aup.gdf_from_polygon(aoi, sip_schema, sip_table, geom_col=\"geometry\")\n",
    "sip_amenities = {'GEOGRAFICO':['Mercado','Plaza'], \n",
    "                 'TIPO':['Cancha','Unidad Deportiva','Áreas Verdes','Jardín','Parque']}\n",
    "# Filter - SIP pois of interest\n",
    "sip_amenities_codes = {'Mercado':4721, #sip_mercado\n",
    "                       'Cancha':93110, #sip_cancha\n",
    "                       'Unidad Deportiva':93111, #sip_unidad_deportiva \n",
    "                       'Áreas Verdes':9321, #sip_espacio_publico \n",
    "                       'Jardín':9321, #sip_espacio_publico\n",
    "                       'Parque':9321, #sip_espacio_publico\n",
    "                       'Plaza':9321 #sip_espacio_publico\n",
    "                        }\n",
    "# Filter - Iterate over sip_amenities and filter sip gdf\n",
    "sip_pois = gpd.GeoDataFrame()\n",
    "for col in sip_amenities:\n",
    "    for amenity in sip_amenities[col]:\n",
    "        sip_tmp = sip_gdf.loc[sip_gdf[col] == amenity]\n",
    "        sip_tmp.loc[:,'code'] = sip_amenities_codes[amenity]\n",
    "        sip_pois = pd.concat([sip_pois,sip_tmp])\n",
    "del sip_gdf\n",
    "# Format\n",
    "sip_pois = sip_pois[['code','geometry']]\n",
    "# Save to pois_tmp\n",
    "sip_clues_gdf = pd.concat([sip_clues_gdf,sip_pois])\n",
    "del sip_pois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f095c-0b53-4dc9-9b34-fbfce8665984",
   "metadata": {},
   "source": [
    "### Part 1.3a - nodes analysis for all amenities except green spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fda9ae6-4642-4e01-8f01-0440356ce93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Analysing source denue_guarderias.\n",
      "--- Downloading denue source pois code 624411 from db.\n",
      "--- Downloading denue source pois code 624412 from db.\n",
      "--- 427 denue_guarderias pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_guarderias.\n",
      "Starting time analysis for denue_guarderias.\n",
      "Starting range k = 1 of 3 for denue_guarderias.\n",
      "Starting range k = 2 of 3 for denue_guarderias.\n",
      "Starting range k = 3 of 3 for denue_guarderias.\n",
      "Finished time analysis for denue_guarderias.\n",
      "--- FINISHED source denue_guarderias. Mean city time = 29.733439637890502\n",
      "---Analysing source denue_preescolar.\n",
      "--- Downloading denue source pois code 611111 from db.\n",
      "--- Downloading denue source pois code 611112 from db.\n",
      "--- 1676 denue_preescolar pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_preescolar.\n",
      "Starting time analysis for denue_preescolar.\n",
      "Starting range k = 1 of 9 for denue_preescolar.\n",
      "Starting range k = 2 of 9 for denue_preescolar.\n",
      "Starting range k = 3 of 9 for denue_preescolar.\n",
      "Starting range k = 4 of 9 for denue_preescolar.\n",
      "Starting range k = 5 of 9 for denue_preescolar.\n",
      "Starting range k = 6 of 9 for denue_preescolar.\n",
      "Starting range k = 7 of 9 for denue_preescolar.\n",
      "Starting range k = 8 of 9 for denue_preescolar.\n",
      "Starting range k = 9 of 9 for denue_preescolar.\n",
      "Finished time analysis for denue_preescolar.\n",
      "--- FINISHED source denue_preescolar. Mean city time = 18.708641000165724\n",
      "---Analysing source denue_primaria.\n",
      "--- Downloading denue source pois code 611121 from db.\n",
      "--- Downloading denue source pois code 611122 from db.\n",
      "--- 1491 denue_primaria pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_primaria.\n",
      "Starting time analysis for denue_primaria.\n",
      "Starting range k = 1 of 8 for denue_primaria.\n",
      "Starting range k = 2 of 8 for denue_primaria.\n",
      "Starting range k = 3 of 8 for denue_primaria.\n",
      "Starting range k = 4 of 8 for denue_primaria.\n",
      "Starting range k = 5 of 8 for denue_primaria.\n",
      "Starting range k = 6 of 8 for denue_primaria.\n",
      "Starting range k = 7 of 8 for denue_primaria.\n",
      "Starting range k = 8 of 8 for denue_primaria.\n",
      "Finished time analysis for denue_primaria.\n",
      "--- FINISHED source denue_primaria. Mean city time = 19.678422163903285\n",
      "---Analysing source denue_secundaria.\n",
      "--- Downloading denue source pois code 611131 from db.\n",
      "--- Downloading denue source pois code 611132 from db.\n",
      "--- 246 denue_secundaria pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_secundaria.\n",
      "Starting time analysis for denue_secundaria.\n",
      "Starting range k = 1 of 2 for denue_secundaria.\n",
      "Starting range k = 2 of 2 for denue_secundaria.\n",
      "Finished time analysis for denue_secundaria.\n",
      "--- FINISHED source denue_secundaria. Mean city time = 32.07955916506414\n",
      "---Analysing source clues_primer_nivel.\n",
      "--- Getting clues/sip source pois code 8610 from previously downloaded.\n",
      "--- 708 clues_primer_nivel pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each clues_primer_nivel.\n",
      "Starting time analysis for clues_primer_nivel.\n",
      "Starting range k = 1 of 4 for clues_primer_nivel.\n",
      "Starting range k = 2 of 4 for clues_primer_nivel.\n",
      "Starting range k = 3 of 4 for clues_primer_nivel.\n",
      "Starting range k = 4 of 4 for clues_primer_nivel.\n",
      "Finished time analysis for clues_primer_nivel.\n",
      "--- FINISHED source clues_primer_nivel. Mean city time = 22.017309668037658\n",
      "---Analysing source denue_farmacias.\n",
      "--- Downloading denue source pois code 474111 from db.\n",
      "--- Downloading denue source pois code 464112 from db.\n",
      "--- 613 denue_farmacias pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_farmacias.\n",
      "Starting time analysis for denue_farmacias.\n",
      "Starting range k = 1 of 4 for denue_farmacias.\n",
      "Starting range k = 2 of 4 for denue_farmacias.\n",
      "Starting range k = 3 of 4 for denue_farmacias.\n",
      "Starting range k = 4 of 4 for denue_farmacias.\n",
      "Finished time analysis for denue_farmacias.\n",
      "--- FINISHED source denue_farmacias. Mean city time = 22.726686618206664\n",
      "---SKIPPING odc_parques.\n",
      "---Analysing source sip_cancha.\n",
      "--- Getting clues/sip source pois code 93110 from previously downloaded.\n",
      "--- 246 sip_cancha pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_cancha.\n",
      "Starting time analysis for sip_cancha.\n",
      "Starting range k = 1 of 2 for sip_cancha.\n",
      "Starting range k = 2 of 2 for sip_cancha.\n",
      "Finished time analysis for sip_cancha.\n",
      "--- FINISHED source sip_cancha. Mean city time = 32.11971614987063\n",
      "---Analysing source sip_unidad_deportiva.\n",
      "--- Getting clues/sip source pois code 93111 from previously downloaded.\n",
      "--- 67 sip_unidad_deportiva pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_unidad_deportiva.\n",
      "Starting time analysis for sip_unidad_deportiva.\n",
      "Starting range k = 1 of 1 for sip_unidad_deportiva.\n",
      "Finished time analysis for sip_unidad_deportiva.\n",
      "--- FINISHED source sip_unidad_deportiva. Mean city time = 114.3896705731577\n",
      "---Analysing source denue_cines.\n",
      "--- Downloading denue source pois code 512130 from db.\n",
      "--- 53 denue_cines pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_cines.\n",
      "Starting time analysis for denue_cines.\n",
      "Starting range k = 1 of 1 for denue_cines.\n",
      "Finished time analysis for denue_cines.\n",
      "--- FINISHED source denue_cines. Mean city time = 73.2130687976499\n",
      "---Analysing source denue_museos.\n",
      "--- Downloading denue source pois code 712111 from db.\n",
      "--- Downloading denue source pois code 712112 from db.\n",
      "--- 47 denue_museos pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_museos.\n",
      "Starting time analysis for denue_museos.\n",
      "Starting range k = 1 of 1 for denue_museos.\n",
      "Finished time analysis for denue_museos.\n",
      "--- FINISHED source denue_museos. Mean city time = 143.41311694804807\n",
      "---Analysing source denue_bibliotecas.\n",
      "--- Downloading denue source pois code 519121 from db.\n",
      "--- Downloading denue source pois code 519122 from db.\n",
      "--- 77 denue_bibliotecas pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_bibliotecas.\n",
      "Starting time analysis for denue_bibliotecas.\n",
      "Starting range k = 1 of 1 for denue_bibliotecas.\n",
      "Finished time analysis for denue_bibliotecas.\n",
      "--- FINISHED source denue_bibliotecas. Mean city time = 45.244689457553946\n",
      "---Analysing source denue_bancos.\n",
      "--- Downloading denue source pois code 522110 from db.\n",
      "--- 3045 denue_bancos pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_bancos.\n",
      "Starting time analysis for denue_bancos.\n",
      "Starting range k = 1 of 16 for denue_bancos.\n",
      "Starting range k = 2 of 16 for denue_bancos.\n",
      "Starting range k = 3 of 16 for denue_bancos.\n",
      "Starting range k = 4 of 16 for denue_bancos.\n",
      "Starting range k = 5 of 16 for denue_bancos.\n",
      "Starting range k = 6 of 16 for denue_bancos.\n",
      "Starting range k = 7 of 16 for denue_bancos.\n",
      "Starting range k = 8 of 16 for denue_bancos.\n",
      "Starting range k = 9 of 16 for denue_bancos.\n",
      "Starting range k = 10 of 16 for denue_bancos.\n",
      "Starting range k = 11 of 16 for denue_bancos.\n",
      "Starting range k = 12 of 16 for denue_bancos.\n",
      "Starting range k = 13 of 16 for denue_bancos.\n",
      "Starting range k = 14 of 16 for denue_bancos.\n",
      "Starting range k = 15 of 16 for denue_bancos.\n",
      "Starting range k = 16 of 16 for denue_bancos.\n",
      "Finished time analysis for denue_bancos.\n",
      "--- FINISHED source denue_bancos. Mean city time = 20.022807880273685\n",
      "FINISHED source pois proximity to nodes analysis for Guadalajara.\n",
      "(184338, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>denue_guarderias</th>\n",
       "      <th>denue_guarderias_15min</th>\n",
       "      <th>denue_preescolar</th>\n",
       "      <th>denue_preescolar_15min</th>\n",
       "      <th>denue_primaria</th>\n",
       "      <th>denue_primaria_15min</th>\n",
       "      <th>denue_secundaria</th>\n",
       "      <th>denue_secundaria_15min</th>\n",
       "      <th>clues_primer_nivel</th>\n",
       "      <th>...</th>\n",
       "      <th>denue_cines_15min</th>\n",
       "      <th>denue_museos</th>\n",
       "      <th>denue_museos_15min</th>\n",
       "      <th>denue_bibliotecas</th>\n",
       "      <th>denue_bibliotecas_15min</th>\n",
       "      <th>denue_bancos</th>\n",
       "      <th>denue_bancos_15min</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28751344</td>\n",
       "      <td>13.128475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80726</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.88002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.86144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.68526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.983204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-103.306309</td>\n",
       "      <td>20.711533</td>\n",
       "      <td>POINT (-103.30631 20.71153)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      osmid  denue_guarderias  denue_guarderias_15min  denue_preescolar  \\\n",
       "0  28751344         13.128475                     1.0           1.80726   \n",
       "\n",
       "   denue_preescolar_15min  denue_primaria  denue_primaria_15min  \\\n",
       "0                     5.0        7.275387                   8.0   \n",
       "\n",
       "   denue_secundaria  denue_secundaria_15min  clues_primer_nivel  ...  \\\n",
       "0           3.88002                     2.0            7.275387  ...   \n",
       "\n",
       "   denue_cines_15min  denue_museos  denue_museos_15min  denue_bibliotecas  \\\n",
       "0                0.0      84.86144                 0.0           15.68526   \n",
       "\n",
       "   denue_bibliotecas_15min  denue_bancos  denue_bancos_15min           x  \\\n",
       "0                      0.0     12.983204                 2.0 -103.306309   \n",
       "\n",
       "           y                     geometry  \n",
       "0  20.711533  POINT (-103.30631 20.71153)  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Added option for source being odc (In order skip it since for parks it will be slightly different).\n",
    "# Removed 'version' from get_denue_pois\n",
    "# Output renamed (nodes_analysis_1), will be concatenated with nodes_analysis_2 (Greenspace analysis)\n",
    "####################################################################################################################################\n",
    "\n",
    "# 1.3a --------------- ANALYSE POINTS OF INTEREST (If denue, downloads)\n",
    "# ------------------- This step analysis times (and count of pois at given time proximity if requested) using function aup.pois_time.\n",
    "\n",
    "poly_wkt = aoi.dissolve().geometry.to_wkt()[0]\n",
    "\n",
    "i = 0\n",
    "analysis_cols = []\n",
    "\n",
    "for eje in parameters.keys():\n",
    "    for amenity in parameters[eje]:\n",
    "        for source in parameters[eje][amenity]:\n",
    "            if source[0] == 'o':\n",
    "                print(f\"---SKIPPING {source}.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\"\"---Analysing source {source}.\"\"\")\n",
    "            \n",
    "            analysis_cols.append(source)\n",
    "            if count_pois[0]:\n",
    "                count_col = f'{source}_{count_pois[1]}min'\n",
    "                analysis_cols.append(count_col)\n",
    "            \n",
    "            # ANALYSIS - Select source points of interest\n",
    "            source_pois = gpd.GeoDataFrame()\n",
    "            for code in parameters[eje][amenity][source]:\n",
    "                #If source is denue:\n",
    "                if source[0] == 'd':\n",
    "                    print(f'--- Downloading denue source pois code {code} from db.')\n",
    "                    code_pois = get_denue_pois(denue_schema,denue_table,poly_wkt,code)\n",
    "                #If source is clues or sip:\n",
    "                elif source[0] == 'c' or source[0] == 's':\n",
    "                    print(f'--- Getting clues/sip source pois code {code} from previously downloaded.')\n",
    "                    code_pois = sip_clues_gdf.loc[sip_clues_gdf['code'] == code]\n",
    "                else:\n",
    "                    print(f'--- Error, check parameters dicctionary.')\n",
    "                    print(f'--- Sources must start with denue_, clues_, odc_ or sip_.')\n",
    "                    intended_crash\n",
    "                    \n",
    "                source_pois = pd.concat([source_pois,code_pois])\n",
    "\n",
    "            print(f\"--- {source_pois.shape[0]} {source} pois. Analysing source pois proximity to nodes.\")\n",
    "            \n",
    "            # ANALYSIS - Calculate times from nodes to source\n",
    "            source_nodes_time = aup.pois_time(G, nodes, edges, source_pois, source, prox_measure,count_pois)\n",
    "            source_nodes_time.rename(columns={'time_'+source:source},inplace=True)\n",
    "            if count_pois[0]:\n",
    "                source_nodes_time = source_nodes_time[['osmid',source,count_col,'x','y','geometry']]\n",
    "            else:\n",
    "                source_nodes_time = source_nodes_time[['osmid',source,'x','y','geometry']]\n",
    "\n",
    "            # ANALYSIS - Merge all times in one df\n",
    "            if i == 0: # For the first analysed source\n",
    "                nodes_analysis = source_nodes_time.copy()\n",
    "            else: # For the rest\n",
    "                if count_pois[0]:\n",
    "                    nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source,count_col]],on='osmid')\n",
    "                else:\n",
    "                    nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source]],on='osmid')\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "            print(f\"--- FINISHED source {source}. Mean city time = {nodes_analysis[source].mean()}\")\n",
    "        \n",
    "# Final format for nodes\n",
    "column_order = ['osmid'] + analysis_cols + ['x','y','geometry']\n",
    "nodes_analysis_1 = nodes_analysis[column_order]\n",
    "\n",
    "print(f\"\"\"FINISHED source pois proximity to nodes analysis for {city}.\"\"\")\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis_1.shape)\n",
    "nodes_analysis_1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf92e0f-39ff-4deb-87c2-2aefcd832a30",
   "metadata": {},
   "source": [
    "### Part 1.3b - nodes analysis for green spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46aa60f-d527-492d-b59c-7024776508a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading source pois code 9321 from db.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loaded and filtered source pois code 9321 from db.\n",
      "--- 57635 odc_parques pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each odc_parques.\n",
      "Starting time analysis for odc_parques.\n",
      "Starting range k = 1 of 56 for odc_parques.\n",
      "Starting range k = 2 of 56 for odc_parques.\n",
      "Starting range k = 3 of 56 for odc_parques.\n",
      "Starting range k = 4 of 56 for odc_parques.\n",
      "Starting range k = 5 of 56 for odc_parques.\n",
      "Starting range k = 6 of 56 for odc_parques.\n",
      "Starting range k = 7 of 56 for odc_parques.\n",
      "Starting range k = 8 of 56 for odc_parques.\n",
      "Starting range k = 9 of 56 for odc_parques.\n",
      "Starting range k = 10 of 56 for odc_parques.\n",
      "Starting range k = 11 of 56 for odc_parques.\n",
      "Starting range k = 12 of 56 for odc_parques.\n",
      "Starting range k = 13 of 56 for odc_parques.\n",
      "Starting range k = 14 of 56 for odc_parques.\n",
      "Starting range k = 15 of 56 for odc_parques.\n",
      "Starting range k = 16 of 56 for odc_parques.\n",
      "Starting range k = 17 of 56 for odc_parques.\n",
      "Starting range k = 18 of 56 for odc_parques.\n",
      "Starting range k = 19 of 56 for odc_parques.\n",
      "Starting range k = 20 of 56 for odc_parques.\n",
      "Starting range k = 21 of 56 for odc_parques.\n",
      "Starting range k = 22 of 56 for odc_parques.\n",
      "Starting range k = 23 of 56 for odc_parques.\n",
      "Starting range k = 24 of 56 for odc_parques.\n",
      "Starting range k = 25 of 56 for odc_parques.\n",
      "Starting range k = 26 of 56 for odc_parques.\n",
      "Starting range k = 27 of 56 for odc_parques.\n",
      "Starting range k = 28 of 56 for odc_parques.\n",
      "Starting range k = 29 of 56 for odc_parques.\n",
      "Starting range k = 30 of 56 for odc_parques.\n",
      "Starting range k = 31 of 56 for odc_parques.\n",
      "Starting range k = 32 of 56 for odc_parques.\n",
      "Starting range k = 33 of 56 for odc_parques.\n",
      "Starting range k = 34 of 56 for odc_parques.\n",
      "Starting range k = 35 of 56 for odc_parques.\n",
      "Starting range k = 36 of 56 for odc_parques.\n",
      "Starting range k = 37 of 56 for odc_parques.\n",
      "Starting range k = 38 of 56 for odc_parques.\n",
      "Starting range k = 39 of 56 for odc_parques.\n",
      "Starting range k = 40 of 56 for odc_parques.\n",
      "Starting range k = 41 of 56 for odc_parques.\n",
      "Starting range k = 42 of 56 for odc_parques.\n",
      "Starting range k = 43 of 56 for odc_parques.\n",
      "Starting range k = 44 of 56 for odc_parques.\n",
      "Starting range k = 45 of 56 for odc_parques.\n",
      "Starting range k = 46 of 56 for odc_parques.\n",
      "Starting range k = 47 of 56 for odc_parques.\n",
      "Starting range k = 48 of 56 for odc_parques.\n",
      "Starting range k = 49 of 56 for odc_parques.\n",
      "Starting range k = 50 of 56 for odc_parques.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting range k = 51 of 56 for odc_parques.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting range k = 52 of 56 for odc_parques.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting range k = 53 of 56 for odc_parques.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting range k = 54 of 56 for odc_parques.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting range k = 55 of 56 for odc_parques.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting range k = 56 of 56 for odc_parques.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  super().__setitem__(key, value)\n",
      "/tmp/ipykernel_22586/2034211160.py:179: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  nodes_time.reset_index(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished time analysis for odc_parques.\n",
      "--- FINISHED source odc_parques. Mean city time = 21.967618044636573\n",
      "FINISHED source pois proximity to nodes analysis for Guadalajara.\n",
      "(184338, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>odc_parques</th>\n",
       "      <th>odc_parques_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28751344</td>\n",
       "      <td>5.714179</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      osmid  odc_parques  odc_parques_15min\n",
       "0  28751344     5.714179               29.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# 1.3b ADAPTATION\n",
    "# Parks pois are vertices from polygons gotten from db.\n",
    "# Since one polygon of interest will have several points of interest (vertices), any osmnx node could get assigned several pois even if they all belong to the same park.\n",
    "# Therefore, we cannot use function aup.pois_time.\n",
    "# This step unfolds function aup.pois_time so that if the previous case happens, the node gets assigned to the closest poi of the polygon only. (Once)\n",
    "####################################################################################################################################\n",
    "\n",
    "# 1.3 --------------- ANALYSE POINTS OF INTEREST (If denue, downloads)\n",
    "# ------------------- This step analysis times (and count of pois at given time proximity if requested) using function aup.pois_time.\n",
    "\n",
    "# PREP. FOR ANALYSIS\n",
    "i = 0\n",
    "# PREP. FOR ANALYSIS - List of columns used to deliver final format\n",
    "analysis_cols = []\n",
    "\n",
    "eje = 'Parques'\n",
    "for amenity in parameters[eje]:\n",
    "    for source in parameters[eje][amenity]:\n",
    "\n",
    "        analysis_cols.append(source)\n",
    "        # PREP. FOR ANALYSIS - If counting pois, append corresponding column (count_col formated example: 'denue_preescolar_15min')\n",
    "        if count_pois[0]:\n",
    "            count_col = f'{source}_{count_pois[1]}min'\n",
    "            analysis_cols.append(count_col)\n",
    "        \n",
    "        # ANALYSIS - Select source points of interest (concats all data of current source's codes in source_pois)\n",
    "        source_pois = gpd.GeoDataFrame()\n",
    "        for code in parameters[eje][amenity][source]:\n",
    "            if source[0] == 'o':\n",
    "                print(f'--- Loading source pois code {code} from db.')\n",
    "                code_pois = get_parques_pois(parques_schema,parques_table,code)\n",
    "                source_pois = pd.concat([source_pois,code_pois])\n",
    "                print(f'--- Loaded and filtered source pois code {code} from db.')\n",
    "\n",
    "        print(f\"--- {source_pois.shape[0]} {source} pois. Analysing source pois proximity to nodes.\")\n",
    "\n",
    "        # ANALYSIS - Calculate time data from nodes to source\n",
    "        ####################################################################################################################################################################################\n",
    "        # FUNCTION aup.pois_time\n",
    "        # Calculates times from nodes to source (source_nodes_time = aup.pois_time(G, nodes, edges, source_pois, source, prox_measure,count_pois))\n",
    "        # analysis function being used: def pois_time(G, nodes, edges, pois, poi_name, prox_measure,count_pois=(False,0)):\n",
    "        pois = source_pois.copy()\n",
    "        poi_name = source\n",
    "        ##########################################################################################\n",
    "        # STEP 1: NEAREST. \n",
    "        # Finds and assigns nearest node OSMID to each point of interest.\n",
    "           \n",
    "        # Defines projection for downloaded data\n",
    "        pois = pois.set_crs(\"EPSG:4326\")\n",
    "        nodes = nodes.set_crs(\"EPSG:4326\")\n",
    "        edges = edges.set_crs(\"EPSG:4326\")\n",
    "        \n",
    "        # In case there are no amenities of the type in the city, prevents it from crashing if len = 0\n",
    "        if len(pois) == 0:\n",
    "            nodes_time = nodes.copy()\n",
    "    \n",
    "            # Format\n",
    "            nodes_time.reset_index(inplace=True)\n",
    "            nodes_time = nodes_time.set_crs(\"EPSG:4326\")\n",
    "    \n",
    "            # As no amenities were found, output columns are set to nan.\n",
    "            nodes_time['time_'+poi_name] = np.nan # Time is set to np.nan.\n",
    "            print(f\"0 {poi_name} found. Time set to np.nan for all nodes.\")\n",
    "            if count_pois[0]: \n",
    "                nodes_time[f'{poi_name}_{count_pois[1]}min'] = np.nan # If requested pois_count, value is set to np.nan.\n",
    "                print(f\"0 {poi_name} found. Pois count set to nan for all nodes.\")\n",
    "                nodes_time = nodes_time[['osmid','time_'+poi_name,f'{poi_name}_{count_pois[1]}min','x','y','geometry']]\n",
    "                #return nodes_time\n",
    "            else:\n",
    "                nodes_time = nodes_time[['osmid','time_'+poi_name,'x','y','geometry']]\n",
    "                #return nodes_time\n",
    "        \n",
    "        else:\n",
    "            ### Find nearest osmnx node for each DENUE point.\n",
    "            nearest = aup.find_nearest(G, nodes, pois, return_distance= True)\n",
    "            nearest = nearest.set_crs(\"EPSG:4326\")\n",
    "            print(f\"Found and assigned nearest node osmid to each {poi_name}.\")\n",
    "                \n",
    "            ##########################################################################################\n",
    "            # ADDITIONAL STEP\n",
    "            # Filters for the minimum distance (distance_node) from osmid to each polygon vertex\n",
    "    \n",
    "            # Group by node (osmid) and polygon (green space) considering only the closest vertex (min)\n",
    "            groupby = nearest.groupby(['osmid','polygon_id']).agg({'distance_node':np.min})\n",
    "    \n",
    "            # Merges back with nodes geometry\n",
    "            groupby.reset_index(inplace=True)\n",
    "            geom_gdf = nodes.reset_index()[['osmid','geometry']]\n",
    "            nearest = pd.merge(groupby,geom_gdf,on='osmid',how='left')\n",
    "    \n",
    "            # Deletes polygon_id\n",
    "            nearest.drop(columns=['polygon_id'],inplace=True)\n",
    "            \n",
    "            ##########################################################################################\n",
    "            # STEP 2: DISTANCE NEAREST POI. \n",
    "            # Calculates distance from each node to its nearest point of interest using previously assigned nearest node.\n",
    "            \n",
    "            # --------------- 2.1 FORMAT NETWORK DATA\n",
    "            # Fill NANs with mean times (prevents crash)\n",
    "            edges[prox_measure].fillna(edges[prox_measure].mean(),inplace=True)\n",
    "            # If prox_measure = 'length', calculates time_min assuming walking speed = 4km/hr\n",
    "            if prox_measure == 'length':\n",
    "                edges['time_min'] = (edges['length']*60)/4000\n",
    "            \n",
    "            # --------------- 2.2 ELEMENTS NEEDED OUTSIDE THE ANALYSIS LOOP\n",
    "            # The pois are divided by batches of 200 or 250 pois and analysed using the function calculate_distance_nearest_poi.\n",
    "            # nodes_analysis is a nodes gdf (index reseted) used in the function aup.calculate_distance_nearest_poi.\n",
    "            nodes_analysis = nodes.reset_index().copy()\n",
    "            # nodes_time: int_gdf stores, processes time data within the loop and returns final gdf. (df_int, df_temp, df_min and nodes_distance in previous code versions)\n",
    "            nodes_time = nodes.copy()\n",
    "            \n",
    "            # --------------- 2.3 PROCESSING DISTANCE\n",
    "            print (f\"Starting time analysis for {poi_name}.\")\n",
    "            # List of columns with output data by batch\n",
    "            time_cols = []\n",
    "            poiscount_cols = []\n",
    "            \n",
    "            # If possible, analyses by batches of 200 pois.\n",
    "            if len(nearest) % 250:\n",
    "                batch_size = len(nearest)/200\n",
    "                for k in range(int(batch_size)+1):\n",
    "                    print(f\"Starting range k = {k+1} of {int(batch_size)+1} for {poi_name}.\")\n",
    "                    # Calculate\n",
    "                    source_process = nearest.iloc[int(200*k):int(200*(1+k))].copy()\n",
    "                    nodes_distance_prep = aup.calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght='time_min',count_pois=count_pois)\n",
    "                    \n",
    "                    # Extract from nodes_distance_prep the calculated time data\n",
    "                    batch_time_col = 'time_'+str(k)+poi_name\n",
    "                    time_cols.append(batch_time_col)\n",
    "                    nodes_time[batch_time_col] = nodes_distance_prep['dist_'+poi_name]\n",
    "                    \n",
    "                    # If requested, extract from nodes_distance_prep the calculated pois count\n",
    "                    if count_pois[0]:\n",
    "                        batch_poiscount_col = f'{poi_name}_{str(k)}_{count_pois[1]}min'\n",
    "                        poiscount_cols.append(batch_poiscount_col)\n",
    "                        nodes_time[batch_poiscount_col] = nodes_distance_prep[f'{poi_name}_{count_pois[1]}min']\n",
    "                \n",
    "                # After batch processing is over, find final output values for all batches.\n",
    "                # For time data, apply the min function to time columns.\n",
    "                nodes_time['time_'+poi_name] = nodes_time[time_cols].min(axis=1)\n",
    "                # If requested, apply the sum function to pois_count columns. \n",
    "                if count_pois[0]:\n",
    "                    # Sum pois count\n",
    "                    nodes_time[f'{poi_name}_{count_pois[1]}min'] = nodes_time[poiscount_cols].sum(axis=1)\n",
    "    \t\t\n",
    "    \t\t# Else, analyses by batches of 250 pois.\n",
    "            else:\n",
    "                batch_size = len(nearest)/250\n",
    "                for k in range(int(batch_size)+1):\n",
    "                    print(f\"Starting range k = {k+1} of {int(batch_size)+1} for source {poi_name}.\")\n",
    "                    # Calculate\n",
    "                    source_process = nearest.iloc[int(250*k):int(250*(1+k))].copy()\n",
    "                    nodes_distance_prep = aup.calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght='time_min',count_pois=count_pois)\n",
    "                    \n",
    "                    # Extract from nodes_distance_prep the calculated time data\n",
    "                    batch_time_col = 'time_'+str(k)+poi_name\n",
    "                    time_cols.append(batch_time_col)\n",
    "                    nodes_time[batch_time_col] = nodes_distance_prep['dist_'+poi_name]\n",
    "                    \n",
    "                    # If requested, extract from nodes_distance_prep the calculated pois count\n",
    "                    if count_pois[0]:\n",
    "                        batch_poiscount_col = f'{poi_name}_{str(k)}_{count_pois[1]}min'\n",
    "                        poiscount_cols.append(batch_poiscount_col)\n",
    "                        nodes_time[batch_poiscount_col] = nodes_distance_prep[f'{poi_name}_{count_pois[1]}min']\n",
    "                        \n",
    "                # After batch processing is over, find final output values for all batches.\n",
    "                # For time data, apply the min function to time columns.\n",
    "                nodes_time['time_'+poi_name] = nodes_time[time_cols].min(axis=1)\n",
    "                # If requested, apply the sum function to pois_count columns. \n",
    "                if count_pois[0]:\n",
    "                    # Sum pois count\n",
    "                    nodes_time[f'{poi_name}_{count_pois[1]}min'] = nodes_time[poiscount_cols].sum(axis=1)\n",
    "            \n",
    "            print(f\"Finished time analysis for {poi_name}.\")\n",
    "\n",
    "            ##########################################################################################\n",
    "            # Step 3: FINAL FORMAT. Organices and filters output data.\n",
    "            nodes_time.reset_index(inplace=True)\n",
    "            nodes_time = nodes_time.set_crs(\"EPSG:4326\")\n",
    "            if count_pois[0]:\n",
    "                nodes_time = nodes_time[['osmid','time_'+poi_name,f'{poi_name}_{count_pois[1]}min','x','y','geometry']]\n",
    "                #return nodes_time\n",
    "            else:\n",
    "                nodes_time = nodes_time[['osmid','time_'+poi_name,'x','y','geometry']]\t\t\n",
    "                #return nodes_time\n",
    "        \n",
    "        ####################################################################################################################################################################################\n",
    "        # FINISHES FUNCTION aup.pois_time\n",
    "        source_nodes_time = nodes_time.copy()\n",
    "        ####################################################################################################################################################################################\n",
    "\n",
    "        source_nodes_time.rename(columns={'time_'+source:source},inplace=True)\n",
    "        if count_pois[0]:\n",
    "            source_nodes_time = source_nodes_time[['osmid',source,count_col,'x','y','geometry']]\n",
    "        else:\n",
    "            source_nodes_time = source_nodes_time[['osmid',source,'x','y','geometry']]\n",
    "\n",
    "        # ANALYSIS - Merge all times in one df\n",
    "        if i == 0: # For the first analysed source\n",
    "            nodes_analysis = source_nodes_time.copy()\n",
    "        else: # For the rest\n",
    "            if count_pois[0]:\n",
    "                nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source,count_col]],on='osmid')\n",
    "            else:\n",
    "                nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source]],on='osmid')\n",
    "\n",
    "        i = i+1\n",
    "\n",
    "        print(f\"--- FINISHED source {source}. Mean city time = {nodes_analysis[source].mean()}\")\n",
    "        \n",
    "# Final format for nodes\n",
    "column_order = ['osmid'] + analysis_cols # Removed x,y and geometry from output to merge later with nodes_analysis_1\n",
    "nodes_analysis_2 = nodes_analysis[column_order]\n",
    "\n",
    "print(f\"\"\"FINISHED source pois proximity to nodes analysis for {city}.\"\"\")\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis_2.shape)\n",
    "nodes_analysis_2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d70695-4c70-4c52-a534-c96a39b0160b",
   "metadata": {},
   "source": [
    "### Part 1.3c - Merge both nodes analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "361d5c6c-0fa2-4b51-afcb-1baaf5cbd41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184338, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>denue_guarderias</th>\n",
       "      <th>denue_guarderias_15min</th>\n",
       "      <th>denue_preescolar</th>\n",
       "      <th>denue_preescolar_15min</th>\n",
       "      <th>denue_primaria</th>\n",
       "      <th>denue_primaria_15min</th>\n",
       "      <th>denue_secundaria</th>\n",
       "      <th>denue_secundaria_15min</th>\n",
       "      <th>clues_primer_nivel</th>\n",
       "      <th>...</th>\n",
       "      <th>denue_museos_15min</th>\n",
       "      <th>denue_bibliotecas</th>\n",
       "      <th>denue_bibliotecas_15min</th>\n",
       "      <th>denue_bancos</th>\n",
       "      <th>denue_bancos_15min</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>odc_parques</th>\n",
       "      <th>odc_parques_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28751344</td>\n",
       "      <td>13.128475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.807260</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.880020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.685260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.983204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-103.306309</td>\n",
       "      <td>20.711533</td>\n",
       "      <td>POINT (-103.30631 20.71153)</td>\n",
       "      <td>5.714179</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28753224</td>\n",
       "      <td>5.504485</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.731417</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.703541</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.288914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.194589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.200104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.690190</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-103.316645</td>\n",
       "      <td>20.700650</td>\n",
       "      <td>POINT (-103.31665 20.70065)</td>\n",
       "      <td>9.018499</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      osmid  denue_guarderias  denue_guarderias_15min  denue_preescolar  \\\n",
       "0  28751344         13.128475                     1.0          1.807260   \n",
       "1  28753224          5.504485                     2.0          5.731417   \n",
       "\n",
       "   denue_preescolar_15min  denue_primaria  denue_primaria_15min  \\\n",
       "0                     5.0        7.275387                   8.0   \n",
       "1                    12.0        7.703541                  10.0   \n",
       "\n",
       "   denue_secundaria  denue_secundaria_15min  clues_primer_nivel  ...  \\\n",
       "0          3.880020                     2.0            7.275387  ...   \n",
       "1         16.288914                     0.0           11.194589  ...   \n",
       "\n",
       "   denue_museos_15min  denue_bibliotecas  denue_bibliotecas_15min  \\\n",
       "0                 0.0          15.685260                      0.0   \n",
       "1                 0.0          12.200104                      1.0   \n",
       "\n",
       "   denue_bancos  denue_bancos_15min           x          y  \\\n",
       "0     12.983204                 2.0 -103.306309  20.711533   \n",
       "1      5.690190                 5.0 -103.316645  20.700650   \n",
       "\n",
       "                      geometry  odc_parques  odc_parques_15min  \n",
       "0  POINT (-103.30631 20.71153)     5.714179               29.0  \n",
       "1  POINT (-103.31665 20.70065)     9.018499               11.0  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_analysis = pd.merge(nodes_analysis_1,nodes_analysis_2,on='osmid')\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis.shape)\n",
    "nodes_analysis.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b4c62-9762-4470-b1cc-462afe4b7c89",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5160cc8b-e34a-4567-8cce-d5461777d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################### PART 2 ###############################################################\n",
    "######################################################### AMENITIES ANALYSIS #########################################################\n",
    "######################################################### (PREV. SCRIPT 15) ##########################################################\n",
    "\n",
    "# 2.0 --------------- DEFINITIONS DICTIONARY\n",
    "# ------------------- On script 15 a dictionary (idx_15_min) is used to calculate the times to amenities.\n",
    "# ------------------- This step creates the definitions dicc out of the main parameters dicc.\n",
    "\n",
    "definitions = {}\n",
    "for eje in parameters.keys():\n",
    "    # tmp_dicc is {amenity:[source_list]} for each eje\n",
    "    tmp_dicc = {}\n",
    "    for amenity in parameters[eje]:\n",
    "        items_lst = []\n",
    "        items = list(parameters[eje][amenity].items())\n",
    "        for item in items:\n",
    "            items_lst.append(item[0])\n",
    "        tmp_dicc[amenity] = items_lst\n",
    "    # Each eje gets assigned its own tmp_dicc\n",
    "    definitions[eje] = tmp_dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48344a57-652f-42c8-b5f7-cf2552f9d811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished missing source amenities analysis. 0 not present source amenities were added as np.nan columns.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 --------------- FILL FOR MISSING AMENITIES\n",
    "# ------------------- This step originates on script 15, where each cities nodes time data was loaded from db.\n",
    "# ------------------- Even though its no longer needed, it remains usefull for avoiding crashes.\n",
    "# ------------------- Definitions dicc (Previously, on script 15, called idx_15_min dictionary) is also used in the next steps.\n",
    "\n",
    "all_sources = []\n",
    "# Gather all possible sources\n",
    "for eje in definitions.keys():\n",
    "    for amenity in definitions[eje].values():\n",
    "        for source in amenity:\n",
    "            all_sources.append(source)\n",
    "\n",
    "# If source not in currently analized city, fill column with np.nan\n",
    "column_list = list(nodes_analysis.columns)\n",
    "missing_sourceamenities = []\n",
    "for s in all_sources:\n",
    "        if s not in column_list:\n",
    "            nodes_analysis[s] = np.nan\n",
    "            print(f\"--- {s} source amenity is not present in {city}.\")\n",
    "            missing_sourceamenities.append(s)\n",
    "print(f\"--- Finished missing source amenities analysis. {len(missing_sourceamenities)} not present source amenities were added as np.nan columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcef1ac7-9030-4fd9-b777-7d5a164439d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting proximity to amenities analysis by node.\n",
      "For amenity Guarderías found minimum time between ['denue_guarderias'].\n",
      "For amenity Preescolar found minimum time between ['denue_preescolar'].\n",
      "For amenity Primaria found minimum time between ['denue_primaria'].\n",
      "For amenity Secundaria found minimum time between ['denue_secundaria'].\n",
      "For amenity Primer nivel found minimum time between ['clues_primer_nivel'].\n",
      "For amenity Farmacias found minimum time between ['denue_farmacias'].\n",
      "For amenity Area verde found minimum time between ['odc_parques'].\n",
      "For amenity Canchas found minimum time between ['sip_cancha'].\n",
      "For amenity Unidad deportiva found minimum time between ['sip_unidad_deportiva'].\n",
      "For amenity Cines found minimum time between ['denue_cines'].\n",
      "For amenity Museos found minimum time between ['denue_museos'].\n",
      "For amenity Bibliotecas found minimum time between ['denue_bibliotecas'].\n",
      "For amenity Bancos found minimum time between ['denue_bancos'].\n",
      "--- Calculated proximity to amenities data by node.\n",
      "(184338, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_escuelas</th>\n",
       "      <th>min_escuelas</th>\n",
       "      <th>time_guarderías</th>\n",
       "      <th>time_preescolar</th>\n",
       "      <th>time_primaria</th>\n",
       "      <th>time_secundaria</th>\n",
       "      <th>max_salud</th>\n",
       "      <th>min_salud</th>\n",
       "      <th>time_primer nivel</th>\n",
       "      <th>time_farmacias</th>\n",
       "      <th>...</th>\n",
       "      <th>min_cultural</th>\n",
       "      <th>time_cines</th>\n",
       "      <th>time_museos</th>\n",
       "      <th>time_bibliotecas</th>\n",
       "      <th>max_financiero</th>\n",
       "      <th>min_financiero</th>\n",
       "      <th>time_bancos</th>\n",
       "      <th>max_time</th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.128475</td>\n",
       "      <td>1.807260</td>\n",
       "      <td>13.128475</td>\n",
       "      <td>1.807260</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>3.880020</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>4.255024</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>4.255024</td>\n",
       "      <td>...</td>\n",
       "      <td>15.685260</td>\n",
       "      <td>31.402184</td>\n",
       "      <td>84.861440</td>\n",
       "      <td>15.685260</td>\n",
       "      <td>12.983204</td>\n",
       "      <td>12.983204</td>\n",
       "      <td>12.983204</td>\n",
       "      <td>84.861440</td>\n",
       "      <td>28751344</td>\n",
       "      <td>POINT (-103.30631 20.71153)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.288914</td>\n",
       "      <td>5.504485</td>\n",
       "      <td>5.504485</td>\n",
       "      <td>5.731417</td>\n",
       "      <td>7.703541</td>\n",
       "      <td>16.288914</td>\n",
       "      <td>11.194589</td>\n",
       "      <td>2.455262</td>\n",
       "      <td>11.194589</td>\n",
       "      <td>2.455262</td>\n",
       "      <td>...</td>\n",
       "      <td>12.200104</td>\n",
       "      <td>40.056989</td>\n",
       "      <td>60.503516</td>\n",
       "      <td>12.200104</td>\n",
       "      <td>5.690190</td>\n",
       "      <td>5.690190</td>\n",
       "      <td>5.690190</td>\n",
       "      <td>60.503516</td>\n",
       "      <td>28753224</td>\n",
       "      <td>POINT (-103.31665 20.70065)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_escuelas  min_escuelas  time_guarderías  time_preescolar  \\\n",
       "0     13.128475      1.807260        13.128475         1.807260   \n",
       "1     16.288914      5.504485         5.504485         5.731417   \n",
       "\n",
       "   time_primaria  time_secundaria  max_salud  min_salud  time_primer nivel  \\\n",
       "0       7.275387         3.880020   7.275387   4.255024           7.275387   \n",
       "1       7.703541        16.288914  11.194589   2.455262          11.194589   \n",
       "\n",
       "   time_farmacias  ...  min_cultural  time_cines  time_museos  \\\n",
       "0        4.255024  ...     15.685260   31.402184    84.861440   \n",
       "1        2.455262  ...     12.200104   40.056989    60.503516   \n",
       "\n",
       "   time_bibliotecas  max_financiero  min_financiero  time_bancos   max_time  \\\n",
       "0         15.685260       12.983204       12.983204    12.983204  84.861440   \n",
       "1         12.200104        5.690190        5.690190     5.690190  60.503516   \n",
       "\n",
       "      osmid                     geometry  \n",
       "0  28751344  POINT (-103.30631 20.71153)  \n",
       "1  28753224  POINT (-103.31665 20.70065)  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Changed prefix 'max_' for 'time_' in amenities\n",
    "# Added 'min_' to ejes\n",
    "# Removed 'two-method'\n",
    "####################################################################################################################################\n",
    "\n",
    "# 2.2a -------------- AMENITIES ANALYSIS (amenities, ejes and max_time calculation)\n",
    "# ------------------- This step calculates times by amenity (preescolar/primaria/etc) using the previously created \n",
    "# ------------------- definitions dictionary (Previously, on script 15, called idx_15_min dictionary)\n",
    "# ------------------- and using weights dictionary to decide which time to use (min/max/other)\n",
    "\n",
    "print(\"--- Starting proximity to amenities analysis by node.\")\n",
    "\n",
    "column_max_all = [] # list with all max times column names\n",
    "column_max_ejes = [] # list with ejes max times column names\n",
    "\n",
    "#Goes through each eje in dictionary:\n",
    "for e in definitions.keys():\n",
    "\n",
    "    #Appends to lists currently examined eje\n",
    "    column_max_all.append('max_'+ e.lower())\n",
    "    column_max_all.append('min_'+ e.lower())\n",
    "    column_max_ejes.append('max_'+ e.lower())\n",
    "    column_max_ejes.append('min_'+ e.lower())\n",
    "    column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "    #Goes through each amenity of current eje:\n",
    "    for a in definitions[e].keys():\n",
    "\n",
    "        #Appends to lists currently examined amenity:\n",
    "        column_max_all.append('time_'+ a.lower())\n",
    "        column_max_amenities.append('time_'+ a.lower())\n",
    "\n",
    "        #Calculates time to currently examined amenity:\n",
    "        #Uses source_weight dictionary to decide which time to use.\n",
    "        weight = source_weight[e][a]\n",
    "        if weight == 'min': # To know distance to closest source amenity.\n",
    "                            # If it doesn't matter which one is closest (e.g. Alimentos).\n",
    "            nodes_analysis['time_'+ a.lower()] = nodes_analysis[definitions[e][a]].min(axis=1)\n",
    "            \n",
    "            print(f'For amenity {a} found minimum time between {definitions[e][a]}.')\n",
    "\n",
    "        elif weight == 'max': # To know distance to farthest source amenity.\n",
    "                              # If need to know proximity to all of the options (e.g. Social)\n",
    "            nodes_analysis['time_'+ a.lower()] = nodes_analysis[definitions[e][a]].max(axis=1)\n",
    "            \n",
    "            print(f'For amenity {a} found maximum time between {definitions[e][a]}.')\n",
    "        else:\n",
    "            # Crash on purpose and raise error\n",
    "            print(\"--- Error in source_weight dicc.\")\n",
    "            print(\"--- Must pass 'min', 'max' or 'two-method'\")\n",
    "            intended_crash\n",
    "\n",
    "    #Calculates time to currently examined eje (max time of its amenities):\n",
    "    nodes_analysis['max_'+ e.lower()] = nodes_analysis[column_max_amenities].max(axis=1)\n",
    "    nodes_analysis['min_'+ e.lower()] = nodes_analysis[column_max_amenities].min(axis=1)\n",
    "\n",
    "# Set and calculate max time\n",
    "index_column = 'max_time' # column name for maximum time data\n",
    "column_max_all.append(index_column) #Adds to column_max_all list the attribute 'max_time'\n",
    "nodes_analysis[index_column] = nodes_analysis[column_max_ejes].max(axis=1) #Assigns \"max_time\" the max time for all ejes   \n",
    "\n",
    "# Add to column_max_all list the attributes 'osmid' and 'geometry' to filter nodes_analysis.\n",
    "# Looking for data of importance: columns in column_max_all list\n",
    "column_max_all.append('osmid')\n",
    "column_max_all.append('geometry')\n",
    "nodes_timeanalysis_filter = nodes_analysis[column_max_all].copy()\n",
    "    \n",
    "print(\"--- Calculated proximity to amenities data by node.\")\n",
    "\n",
    "# Show\n",
    "print(nodes_timeanalysis_filter.shape)\n",
    "nodes_timeanalysis_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e55505-041f-4ebd-9e34-acdaaef1a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184338, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_escuelas</th>\n",
       "      <th>min_escuelas</th>\n",
       "      <th>time_guarderías</th>\n",
       "      <th>time_preescolar</th>\n",
       "      <th>time_primaria</th>\n",
       "      <th>time_secundaria</th>\n",
       "      <th>max_salud</th>\n",
       "      <th>min_salud</th>\n",
       "      <th>time_primer nivel</th>\n",
       "      <th>time_farmacias</th>\n",
       "      <th>...</th>\n",
       "      <th>area verde_15min</th>\n",
       "      <th>equipamiento deportivo_15min</th>\n",
       "      <th>canchas_15min</th>\n",
       "      <th>unidad deportiva_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>cines_15min</th>\n",
       "      <th>museos_15min</th>\n",
       "      <th>bibliotecas_15min</th>\n",
       "      <th>financiero_15min</th>\n",
       "      <th>bancos_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.128475</td>\n",
       "      <td>1.807260</td>\n",
       "      <td>13.128475</td>\n",
       "      <td>1.807260</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>3.880020</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>4.255024</td>\n",
       "      <td>7.275387</td>\n",
       "      <td>4.255024</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.288914</td>\n",
       "      <td>5.504485</td>\n",
       "      <td>5.504485</td>\n",
       "      <td>5.731417</td>\n",
       "      <td>7.703541</td>\n",
       "      <td>16.288914</td>\n",
       "      <td>11.194589</td>\n",
       "      <td>2.455262</td>\n",
       "      <td>11.194589</td>\n",
       "      <td>2.455262</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_escuelas  min_escuelas  time_guarderías  time_preescolar  \\\n",
       "0     13.128475      1.807260        13.128475         1.807260   \n",
       "1     16.288914      5.504485         5.504485         5.731417   \n",
       "\n",
       "   time_primaria  time_secundaria  max_salud  min_salud  time_primer nivel  \\\n",
       "0       7.275387         3.880020   7.275387   4.255024           7.275387   \n",
       "1       7.703541        16.288914  11.194589   2.455262          11.194589   \n",
       "\n",
       "   time_farmacias  ...  area verde_15min  equipamiento deportivo_15min  \\\n",
       "0        4.255024  ...              29.0                           4.0   \n",
       "1        2.455262  ...              11.0                           2.0   \n",
       "\n",
       "   canchas_15min  unidad deportiva_15min  cultural_15min  cines_15min  \\\n",
       "0            4.0                     0.0             0.0          0.0   \n",
       "1            1.0                     1.0             1.0          0.0   \n",
       "\n",
       "   museos_15min  bibliotecas_15min  financiero_15min  bancos_15min  \n",
       "0           0.0                0.0               2.0           2.0  \n",
       "1           0.0                1.0               5.0           5.0  \n",
       "\n",
       "[2 rows x 47 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2b -------------- AMENITIES COUNT ANALYSIS (amenities at given time count, optional)\n",
    "# ------------------- Similar to previous amenities analysis, this step (optional, added later)\n",
    "# ------------------- calculates how many amenities there are at a given time proximity (count_pois = (Boolean,time))\n",
    "\n",
    "if count_pois[0]:\n",
    "    column_count_all = []\n",
    "    \n",
    "    # Go through each eje\n",
    "    for eje in definitions.keys():\n",
    "        # Name of count eje\n",
    "        eje_count_colname = f'{eje}_{count_pois[1]}min'.lower()\n",
    "        # Append to lists\n",
    "        column_count_all.append(eje_count_colname)\n",
    "    \n",
    "        # Go through eje's amenities\n",
    "        column_count_amenities = []\n",
    "        for amenity in definitions[eje]:\n",
    "            # Name of count amenity\n",
    "            amenity_count_colname = f'{amenity}_{count_pois[1]}min'.lower()\n",
    "            # Append to lists\n",
    "            column_count_all.append(amenity_count_colname)\n",
    "            column_count_amenities.append(amenity_count_colname)\n",
    "    \n",
    "            # Gather amenities sources\n",
    "            column_count_sources = [] # Just used for sum function, not added at final output\n",
    "            for source in definitions[eje][amenity]:\n",
    "                # Add to sources list\n",
    "                source_count_colname = f'{source}_{count_pois[1]}min'\n",
    "                column_count_sources.append(source_count_colname)\n",
    "            # Find sum of all sources found within given time of each node (For current amenity)\n",
    "            nodes_analysis[amenity_count_colname] = nodes_analysis[column_count_sources].sum(axis=1)\n",
    "    \n",
    "        # Find sum of all sources found within given time of each node (For current eje)\n",
    "        nodes_analysis[eje_count_colname] = nodes_analysis[column_count_amenities].sum(axis=1)\n",
    "    \n",
    "    # Filter for columns of interest\n",
    "    column_count_all.append('osmid')\n",
    "    nodes_countanalysis_filter = nodes_analysis[column_count_all]\n",
    "    nodes_analysis_filter = pd.merge(nodes_timeanalysis_filter,nodes_countanalysis_filter,on='osmid')\n",
    "\n",
    "else:\n",
    "    nodes_analysis_filter = nodes_timeanalysis_filter.copy()\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis_filter.shape)\n",
    "nodes_analysis_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67dfbd13-b343-4bec-b625-d08ef35313b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Downloaded pop gdf res 9.\n",
      "--- Saved pop gdf res 9.\n",
      "(5667, 5)\n",
      "            hex_id  res  pobtot  dens_pob_ha  \\\n",
      "0  8949aa252bbffff    9   895.0    72.377587   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-103.40480 20.46253, -103.40358 20.4...  \n"
     ]
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Using hex_censo_mza_res9, does not need to calculate dens_pob_ha, it's already there.\n",
    "####################################################################################################################################\n",
    "\n",
    "# 2.3 --------------- POPULATION DATA\n",
    "# ------------------- This step (optional) loads hexagons with population data.\n",
    "\n",
    "if pop_output:\n",
    "    hex_socio_gdf = gpd.GeoDataFrame()\n",
    "    # Downloads hex_socio_gdf for city area\n",
    "    for res in res_list:\n",
    "        # Download\n",
    "        hex_pop_res = aup.gdf_from_polygon(aoi, pop_schema, pop_table, geom_col=\"geometry\")\n",
    "        hex_pop_res = hex_pop_res.set_crs(\"EPSG:4326\")\n",
    "        print(f\"--- Downloaded pop gdf res {res}.\")\n",
    "\n",
    "        # Format\n",
    "        hex_pop_res.rename(columns={f'hex_id_{res}':'hex_id'},inplace=True)\n",
    "        hex_pop_res['res'] = res\n",
    "        \n",
    "        # Calculate fields of interest\n",
    "        #hex_pop_res_tmp = hex_pop_res.to_crs(\"EPSG:6372\")\n",
    "        #hex_pop_res_tmp['dens_pob_ha'] = hex_pop_res_tmp['pobtot'] / (hex_pop_res_tmp.area / 10000)\n",
    "\n",
    "        # Merge calculated fields to hex_pop_res gdf\n",
    "        #hex_pop_res_tmp = hex_pop_res_tmp[['hex_id','dens_pob_ha']]\n",
    "        #hex_pop_res = pd.merge(hex_pop_res,hex_pop_res_tmp,on='hex_id')\n",
    "\n",
    "        # Save fields of interest for current res\n",
    "        pop_fields = ['pobtot','dens_pob_ha']\n",
    "        hex_socio_gdf = pd.concat([hex_socio_gdf,hex_pop_res[['hex_id','res']+pop_fields+['geometry']]])\n",
    "        print(f\"--- Saved pop gdf res {res}.\")\n",
    "\n",
    "    # Show\n",
    "    print(hex_socio_gdf.shape)\n",
    "    print(hex_socio_gdf.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93799231-f2a1-4844-ad31-11e2d72772cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loaded pop hexgrid of resolution 9.\n",
      "--- Grouped nodes data by hexagons res 9.\n",
      "--- Saved grouped data by hexagons res 9.\n",
      "(5639, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_escuelas</th>\n",
       "      <th>min_escuelas</th>\n",
       "      <th>time_guarderías</th>\n",
       "      <th>time_preescolar</th>\n",
       "      <th>time_primaria</th>\n",
       "      <th>time_secundaria</th>\n",
       "      <th>max_salud</th>\n",
       "      <th>min_salud</th>\n",
       "      <th>...</th>\n",
       "      <th>unidad deportiva_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>cines_15min</th>\n",
       "      <th>museos_15min</th>\n",
       "      <th>bibliotecas_15min</th>\n",
       "      <th>financiero_15min</th>\n",
       "      <th>bancos_15min</th>\n",
       "      <th>pobtot</th>\n",
       "      <th>dens_pob_ha</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949aa252bbffff</td>\n",
       "      <td>POLYGON ((-103.40480 20.46253, -103.40358 20.4...</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>4.316403</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>18.338011</td>\n",
       "      <td>15.153014</td>\n",
       "      <td>5.424581</td>\n",
       "      <td>65.126155</td>\n",
       "      <td>13.229981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>895.0</td>\n",
       "      <td>72.377587</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  8949aa252bbffff  POLYGON ((-103.40480 20.46253, -103.40358 20.4...   \n",
       "\n",
       "   max_escuelas  min_escuelas  time_guarderías  time_preescolar  \\\n",
       "0     65.700136      4.316403        65.700136        18.338011   \n",
       "\n",
       "   time_primaria  time_secundaria  max_salud  min_salud  ...  \\\n",
       "0      15.153014         5.424581  65.126155  13.229981  ...   \n",
       "\n",
       "   unidad deportiva_15min  cultural_15min  cines_15min  museos_15min  \\\n",
       "0                     0.0             0.0          0.0           0.0   \n",
       "\n",
       "   bibliotecas_15min  financiero_15min  bancos_15min  pobtot  dens_pob_ha  res  \n",
       "0                0.0          0.333333      0.333333   895.0    72.377587    9  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Removed code refering to version\n",
    "####################################################################################################################################\n",
    "\n",
    "# 2.4 --------------- GROUP DATA BY HEX\n",
    "# ------------------- This groups nodes data by hexagon.\n",
    "# ------------------- If pop output, uses previously created hexes. Else, creates hexgrid.\n",
    "\n",
    "hex_idx = gpd.GeoDataFrame()\n",
    "for res in res_list:\n",
    "    # Load or create hexgrid\n",
    "    # If pop_output is true, loads previously created hexgrid with pop data\n",
    "    if pop_output:\n",
    "        # Load hexgrid\n",
    "        hex_pop = hex_socio_gdf.loc[hex_socio_gdf['res'] == res]\n",
    "        # Function group_by_hex_mean requires ID to include resolution\n",
    "        hex_pop.rename(columns={'hex_id':f'hex_id_{res}'},inplace=True)\n",
    "        # Create hex_tmp (id and geometry)\n",
    "        hex_pop = hex_pop.to_crs(\"EPSG:4326\")\n",
    "        hex_tmp = hex_pop[[f'hex_id_{res}','geometry']].copy()\n",
    "        print(f\"--- Loaded pop hexgrid of resolution {res}.\")\n",
    "        \n",
    "    # If pop_output is false, creates hexgrid\n",
    "    else:\n",
    "        # Load hexgrid (which already has ID_res)\n",
    "        hex_table = f'hexgrid_{res}_city_2020'\n",
    "        query = f\"SELECT * FROM {hex_schema}.{hex_table} WHERE \\\"city\\\" LIKE \\'{city}\\'\"\n",
    "        hexgrid = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "        # Create hex_tmp\n",
    "        hex_tmp = hexgrid.set_crs(\"EPSG:4326\")\n",
    "        hex_tmp = hex_tmp[[f'hex_id_{res}','geometry']].copy()\n",
    "        print(f\"--- Loaded hexgrid of resolution {res}.\")\n",
    "    \n",
    "    # Group time data by hex\n",
    "    hex_res_idx = aup.group_by_hex_mean(nodes_analysis_filter, hex_tmp, res, index_column)\n",
    "    hex_res_idx = hex_res_idx.loc[hex_res_idx[index_column]>0].copy()\n",
    "    print(f\"--- Grouped nodes data by hexagons res {res}.\")\n",
    "    \n",
    "    # If pop_output is true, add pop data\n",
    "    if pop_output:\n",
    "        pop_list = pop_fields.copy()\n",
    "        pop_list.append(f'hex_id_{res}')\n",
    "        hex_res_pop = pd.merge(hex_res_idx, hex_pop[pop_list], on=f'hex_id_{res}')\n",
    "    else:\n",
    "        hex_res_pop = hex_res_idx.copy()\n",
    "    \n",
    "    # After funtion group_by_hex_mean we can remove res from ID and set as a column\n",
    "    hex_res_pop.rename(columns={f'hex_id_{res}':'hex_id'},inplace=True)\n",
    "    hex_res_pop['res'] = res\n",
    "\n",
    "    # Finally, add to hex_idx each resolution processing\n",
    "    hex_idx = pd.concat([hex_idx,hex_res_pop])\n",
    "    print(f\"--- Saved grouped data by hexagons res {res}.\")\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a7e222-9f4d-471e-a2c6-9c2ee9e20b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished recalculating ejes times in hexagons.\n",
      "(5639, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_escuelas</th>\n",
       "      <th>min_escuelas</th>\n",
       "      <th>time_guarderías</th>\n",
       "      <th>time_preescolar</th>\n",
       "      <th>time_primaria</th>\n",
       "      <th>time_secundaria</th>\n",
       "      <th>max_salud</th>\n",
       "      <th>min_salud</th>\n",
       "      <th>...</th>\n",
       "      <th>unidad deportiva_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>cines_15min</th>\n",
       "      <th>museos_15min</th>\n",
       "      <th>bibliotecas_15min</th>\n",
       "      <th>financiero_15min</th>\n",
       "      <th>bancos_15min</th>\n",
       "      <th>pobtot</th>\n",
       "      <th>dens_pob_ha</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949aa252bbffff</td>\n",
       "      <td>POLYGON ((-103.40480 20.46253, -103.40358 20.4...</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>5.424581</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>18.338011</td>\n",
       "      <td>15.153014</td>\n",
       "      <td>5.424581</td>\n",
       "      <td>65.126155</td>\n",
       "      <td>13.229981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>895.0</td>\n",
       "      <td>72.377587</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  8949aa252bbffff  POLYGON ((-103.40480 20.46253, -103.40358 20.4...   \n",
       "\n",
       "   max_escuelas  min_escuelas  time_guarderías  time_preescolar  \\\n",
       "0     65.700136      5.424581        65.700136        18.338011   \n",
       "\n",
       "   time_primaria  time_secundaria  max_salud  min_salud  ...  \\\n",
       "0      15.153014         5.424581  65.126155  13.229981  ...   \n",
       "\n",
       "   unidad deportiva_15min  cultural_15min  cines_15min  museos_15min  \\\n",
       "0                     0.0             0.0          0.0           0.0   \n",
       "\n",
       "   bibliotecas_15min  financiero_15min  bancos_15min  pobtot  dens_pob_ha  res  \n",
       "0                0.0          0.333333      0.333333   895.0    72.377587    9  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################### PART 3 ###############################################################\n",
    "#################################################### RECALCULATION AND FINAL DATA ####################################################\n",
    "#################################################### (PREV. SCRIPT 15 + NEW DATA) ####################################################\n",
    "\n",
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Changed 'max_' prefix to 'time_' prefix for amenities\n",
    "# Added min_ to ejes re-calculation\n",
    "####################################################################################################################################\n",
    "\n",
    "# 3.1 --------------- RE-CALCULATE MAX TIMES BY HEXAGON\n",
    "# ------------------- This step recalculates max time to each eje  \n",
    "# ------------------- from max times to calculated amenities \n",
    "\n",
    "#Goes (again) through each eje in dictionary:\n",
    "for e in definitions.keys():\n",
    "    column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "    #Goes (again) through each amenity of current eje:    \n",
    "    for a in definitions[e].keys():\n",
    "        column_max_amenities.append('time_'+ a.lower())\n",
    "    #Re-calculates time to currently examined eje (min and max time of its amenities):        \n",
    "    hex_idx['max_'+ e.lower()] = hex_idx[column_max_amenities].max(axis=1)\n",
    "    hex_idx['min_'+ e.lower()] = hex_idx[column_max_amenities].min(axis=1)\n",
    "\n",
    "print('--- Finished recalculating ejes times in hexagons.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea87895f-03d2-4fe0-a73a-fadbcbdbcc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5639, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_escuelas</th>\n",
       "      <th>min_escuelas</th>\n",
       "      <th>time_guarderías</th>\n",
       "      <th>time_preescolar</th>\n",
       "      <th>time_primaria</th>\n",
       "      <th>time_secundaria</th>\n",
       "      <th>max_salud</th>\n",
       "      <th>min_salud</th>\n",
       "      <th>...</th>\n",
       "      <th>unidad deportiva_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>cines_15min</th>\n",
       "      <th>museos_15min</th>\n",
       "      <th>bibliotecas_15min</th>\n",
       "      <th>financiero_15min</th>\n",
       "      <th>bancos_15min</th>\n",
       "      <th>pobtot</th>\n",
       "      <th>dens_pob_ha</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949aa252bbffff</td>\n",
       "      <td>POLYGON ((-103.40480 20.46253, -103.40358 20.4...</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>5.424581</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>18.338011</td>\n",
       "      <td>15.153014</td>\n",
       "      <td>5.424581</td>\n",
       "      <td>65.126155</td>\n",
       "      <td>13.229981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>895.0</td>\n",
       "      <td>72.377587</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  8949aa252bbffff  POLYGON ((-103.40480 20.46253, -103.40358 20.4...   \n",
       "\n",
       "   max_escuelas  min_escuelas  time_guarderías  time_preescolar  \\\n",
       "0     65.700136      5.424581        65.700136        18.338011   \n",
       "\n",
       "   time_primaria  time_secundaria  max_salud  min_salud  ...  \\\n",
       "0      15.153014         5.424581  65.126155  13.229981  ...   \n",
       "\n",
       "   unidad deportiva_15min  cultural_15min  cines_15min  museos_15min  \\\n",
       "0                     0.0             0.0          0.0           0.0   \n",
       "\n",
       "   bibliotecas_15min  financiero_15min  bancos_15min  pobtot  dens_pob_ha  res  \n",
       "0                0.0          0.333333      0.333333   895.0    72.377587    9  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Removed additional data (idx, mean_time, median_time, city)\n",
    "####################################################################################################################################\n",
    "\n",
    "# 3.2 --------------- CALCULATE AND ADD ADDITIONAL AND FINAL DATA\n",
    "# ------------------- This step adds mean, median, city and idx data to each hex\n",
    "\n",
    "#Define idx function\n",
    "#def apply_sigmoidal(x):\n",
    "#    if x == -1:\n",
    "#        return -1\n",
    "#    elif x > 1000:\n",
    "#        return 0\n",
    "#    else:\n",
    "#        val = aup.sigmoidal_function(0.1464814753435666, x, 30)\n",
    "#        return val\n",
    "\n",
    "# Create all amenities list (previosly we had amenities list by eje) from column_max_ejes\n",
    "max_amenities_cols = [i for i in column_max_all if i not in column_max_ejes]\n",
    "max_amenities_cols.remove('max_time')\n",
    "max_amenities_cols.remove('osmid')\n",
    "max_amenities_cols.remove('geometry')\n",
    "# Create list with idx column names\n",
    "#idx_amenities_cols = []\n",
    "#for ac in max_amenities_cols:\n",
    "#    idx_col = ac.replace('max','idx')\n",
    "#    hex_idx[idx_col] = hex_idx[ac].apply(apply_sigmoidal)\n",
    "#    idx_amenities_cols.append(idx_col)\n",
    "# Add final data\n",
    "#hex_idx[index_column] = hex_idx[column_max_ejes].max(axis=1)\n",
    "#hex_idx['mean_time'] = hex_idx[max_amenities_cols].mean(axis=1)\n",
    "#hex_idx['median_time'] = hex_idx[max_amenities_cols].median(axis=1)\n",
    "#hex_idx['idx_sum'] = hex_idx[idx_amenities_cols].sum(axis=1)\n",
    "#hex_idx['city'] = city\n",
    "\n",
    "#print('--- Finished calculating index, mean, median and max time.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6dfc035-4a3b-42e2-9b56-ef9c397df84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished final format for gdf.\n",
      "(5639, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>res</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_escuelas</th>\n",
       "      <th>min_escuelas</th>\n",
       "      <th>time_guarderías</th>\n",
       "      <th>time_preescolar</th>\n",
       "      <th>time_primaria</th>\n",
       "      <th>time_secundaria</th>\n",
       "      <th>max_salud</th>\n",
       "      <th>...</th>\n",
       "      <th>canchas_15min</th>\n",
       "      <th>unidad deportiva_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>cines_15min</th>\n",
       "      <th>museos_15min</th>\n",
       "      <th>bibliotecas_15min</th>\n",
       "      <th>financiero_15min</th>\n",
       "      <th>bancos_15min</th>\n",
       "      <th>pobtot</th>\n",
       "      <th>dens_pob_ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949aa252bbffff</td>\n",
       "      <td>9</td>\n",
       "      <td>POLYGON ((-103.40480 20.46253, -103.40358 20.4...</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>5.424581</td>\n",
       "      <td>65.700136</td>\n",
       "      <td>18.338011</td>\n",
       "      <td>15.153014</td>\n",
       "      <td>5.424581</td>\n",
       "      <td>65.126155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>895.0</td>\n",
       "      <td>72.377587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id  res                                           geometry  \\\n",
       "0  8949aa252bbffff    9  POLYGON ((-103.40480 20.46253, -103.40358 20.4...   \n",
       "\n",
       "   max_escuelas  min_escuelas  time_guarderías  time_preescolar  \\\n",
       "0     65.700136      5.424581        65.700136        18.338011   \n",
       "\n",
       "   time_primaria  time_secundaria  max_salud  ...  canchas_15min  \\\n",
       "0      15.153014         5.424581  65.126155  ...            0.0   \n",
       "\n",
       "   unidad deportiva_15min  cultural_15min  cines_15min  museos_15min  \\\n",
       "0                     0.0             0.0          0.0           0.0   \n",
       "\n",
       "   bibliotecas_15min  financiero_15min  bancos_15min  pobtot  dens_pob_ha  \n",
       "0                0.0          0.333333      0.333333   895.0    72.377587  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################################################################\n",
    "# ADAPTATION\n",
    "# Removed additional data (idx, mean_time, median_time, city)\n",
    "####################################################################################################################################\n",
    "\n",
    "# 3.3 --------------- FINAL FORMAT\n",
    "# ------------------- This step gives final format to the gdf\n",
    "\n",
    "# First elements of ordered column list - ID and geometry\n",
    "final_column_ordered_list = ['hex_id','res','geometry']\n",
    "\n",
    "# Second elements of ordered column list - max_ejes and max_amenities \n",
    "# removing max_time, osmid and geometry.\n",
    "column_max_ejes_amenities = column_max_all.copy()\n",
    "column_max_ejes_amenities.remove('max_time')\n",
    "column_max_ejes_amenities.remove('osmid')\n",
    "column_max_ejes_amenities.remove('geometry')\n",
    "final_column_ordered_list = final_column_ordered_list + column_max_ejes_amenities\n",
    "\n",
    "# Third elements of ordered column list - count pois columns (if requested)\n",
    "# removing osmid and geometry.\n",
    "if count_pois[0]:\n",
    "    third_elements = column_count_all.copy()\n",
    "    third_elements.remove(\"osmid\")\n",
    "    final_column_ordered_list = final_column_ordered_list + third_elements\n",
    "\n",
    "# Fourth elements of ordered list are listed in idx_amenities_cols\n",
    "#final_column_ordered_list = final_column_ordered_list + idx_amenities_cols\n",
    "\n",
    "# Fifth elements of ordered list - Final mean, median, max and idx\n",
    "#fifth_elements = ['mean_time', 'median_time', 'max_time', 'idx_sum']\n",
    "#final_column_ordered_list = final_column_ordered_list + fifth_elements\n",
    "\n",
    "# Sixth elements - If pop is calculated - Pop data\n",
    "if pop_output:\n",
    "    final_column_ordered_list = final_column_ordered_list + pop_fields\n",
    "\n",
    "# Last element - City data\n",
    "#final_column_ordered_list.append('city')\n",
    "\n",
    "# Filter/reorder final output    \n",
    "hex_idx_city = hex_idx[final_column_ordered_list]\n",
    "    \n",
    "print('--- Finished final format for gdf.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx_city.shape)\n",
    "hex_idx_city.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fab92b30-759e-4ea9-8ca7-43c502eaee34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hex_id', 'res', 'geometry', 'max_escuelas', 'min_escuelas',\n",
       "       'time_guarderías', 'time_preescolar', 'time_primaria',\n",
       "       'time_secundaria', 'max_salud', 'min_salud', 'time_primer nivel',\n",
       "       'time_farmacias', 'max_parques', 'min_parques', 'time_area verde',\n",
       "       'max_equipamiento deportivo', 'min_equipamiento deportivo',\n",
       "       'time_canchas', 'time_unidad deportiva', 'max_cultural', 'min_cultural',\n",
       "       'time_cines', 'time_museos', 'time_bibliotecas', 'max_financiero',\n",
       "       'min_financiero', 'time_bancos', 'escuelas_15min', 'guarderías_15min',\n",
       "       'preescolar_15min', 'primaria_15min', 'secundaria_15min', 'salud_15min',\n",
       "       'primer nivel_15min', 'farmacias_15min', 'parques_15min',\n",
       "       'area verde_15min', 'equipamiento deportivo_15min', 'canchas_15min',\n",
       "       'unidad deportiva_15min', 'cultural_15min', 'cines_15min',\n",
       "       'museos_15min', 'bibliotecas_15min', 'financiero_15min', 'bancos_15min',\n",
       "       'pobtot', 'dens_pob_ha'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_idx_city.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8751746e-9c55-4cc1-802c-14a26d264246",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_save:\n",
    "    hex_idx_city.to_file(local_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4745d56-945b-4586-be09-85c19d9a9aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c080576-9779-4c59-9ffd-2f69c58ba106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS-10.0",
   "language": "python",
   "name": "gds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
