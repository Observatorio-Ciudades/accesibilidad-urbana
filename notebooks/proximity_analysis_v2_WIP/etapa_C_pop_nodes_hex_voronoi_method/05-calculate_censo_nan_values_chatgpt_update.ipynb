{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53845e6c-a642-4c8d-bebc-9f83977c3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/aup/data.py:25: UserWarning: The `utils.config` function is deprecated and will be removed in a future release. Instead, use the `settings` module directly to configure a global setting's value. For example, `ox.settings.log_console=True`.\n",
      "  ox.config(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "import shapely\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    import aup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3f352d-287d-4f20-b1ca-edba237d21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTSIDE FUNCTION:\n",
    "city = 'Aguascalientes'\n",
    "\n",
    "# --------------- CREATE AREA OF INTEREST (aoi)\n",
    "# Downloads mun_gdf for city and create aoi\n",
    "query = f\"SELECT * FROM metropolis.metro_gdf_2020 WHERE \\\"city\\\" LIKE \\'{city}\\'\"\n",
    "mun_gdf = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "mun_gdf = mun_gdf.set_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ec5ec4-9bd5-4d84-ac7d-d318c0698eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AGEBs for area of interest.\n",
      "Loading blocks for area of interest.\n"
     ]
    }
   ],
   "source": [
    "# --------------- DOWNLOAD POP DATA\n",
    "aoi = mun_gdf.dissolve()\n",
    "print(\"Loading AGEBs for area of interest.\")\n",
    "pop_ageb_gdf = aup.gdf_from_polygon(aoi,'censoageb','censoageb_2020')\n",
    "print(\"Loading blocks for area of interest.\")\n",
    "pop_mza_gdf = aup.gdf_from_polygon(aoi,'censo_mza','censo_mza_2020')\n",
    "pop_mza_gdf = pop_mza_gdf.loc[pop_mza_gdf.AMBITO == 'Urbana'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "392251ab-a48f-4ef9-91c7-6e8fe480d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ageb = '0515'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffaa6319-6b4c-418e-abfe-f8715fd292cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mza_gdf_chosen = pop_mza_gdf.loc[pop_mza_gdf.CVE_AGEB == chosen_ageb].copy()\n",
    "pop_ageb_gdf_chosen = pop_ageb_gdf.loc[pop_ageb_gdf.cve_ageb == chosen_ageb].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c21197d-2d03-4d8e-b0be-1929f1c599a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVEGEO</th>\n",
       "      <th>CVE_ENT</th>\n",
       "      <th>CVE_MUN</th>\n",
       "      <th>CVE_LOC</th>\n",
       "      <th>CVE_AGEB</th>\n",
       "      <th>CVE_MZA</th>\n",
       "      <th>AMBITO</th>\n",
       "      <th>TIPOMZA</th>\n",
       "      <th>geometry</th>\n",
       "      <th>ENTIDAD</th>\n",
       "      <th>...</th>\n",
       "      <th>VPH_TELEF</th>\n",
       "      <th>VPH_CEL</th>\n",
       "      <th>VPH_INTER</th>\n",
       "      <th>VPH_STVP</th>\n",
       "      <th>VPH_SPMVPI</th>\n",
       "      <th>VPH_CVJ</th>\n",
       "      <th>VPH_SINRTV</th>\n",
       "      <th>VPH_SINLTC</th>\n",
       "      <th>VPH_SINCINT</th>\n",
       "      <th>VPH_SINTIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0100100010515001</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001</td>\n",
       "      <td>0515</td>\n",
       "      <td>001</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Típica</td>\n",
       "      <td>POLYGON ((-102.29552 21.88697, -102.29516 21.8...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CVEGEO CVE_ENT CVE_MUN CVE_LOC CVE_AGEB CVE_MZA  AMBITO  \\\n",
       "444  0100100010515001      01     001    0001     0515     001  Urbana   \n",
       "\n",
       "    TIPOMZA                                           geometry  ENTIDAD  ...  \\\n",
       "444  Típica  POLYGON ((-102.29552 21.88697, -102.29516 21.8...        1  ...   \n",
       "\n",
       "    VPH_TELEF  VPH_CEL VPH_INTER  VPH_STVP VPH_SPMVPI VPH_CVJ  VPH_SINRTV  \\\n",
       "444        35       49        41        27         18       3        None   \n",
       "\n",
       "     VPH_SINLTC VPH_SINCINT VPH_SINTIC  \n",
       "444        None          14          0  \n",
       "\n",
       "[1 rows x 239 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_mza_gdf_chosen.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf21b433-38c4-40ae-be92-ef96dc75ef0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cve_geo</th>\n",
       "      <th>cve_ent</th>\n",
       "      <th>cve_mun</th>\n",
       "      <th>cve_loc</th>\n",
       "      <th>cve_ageb</th>\n",
       "      <th>geometry</th>\n",
       "      <th>entidad</th>\n",
       "      <th>nom_ent</th>\n",
       "      <th>mun</th>\n",
       "      <th>nom_mun</th>\n",
       "      <th>...</th>\n",
       "      <th>vph_cel</th>\n",
       "      <th>vph_inter</th>\n",
       "      <th>vph_stvp</th>\n",
       "      <th>vph_spmvpi</th>\n",
       "      <th>vph_cvj</th>\n",
       "      <th>vph_sinrtv</th>\n",
       "      <th>vph_sintlc</th>\n",
       "      <th>vph_sincint</th>\n",
       "      <th>vph_sintic</th>\n",
       "      <th>cve_geo_ageb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0100100010515</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>0001</td>\n",
       "      <td>0515</td>\n",
       "      <td>POLYGON ((-102.29278 21.89010, -102.29275 21.8...</td>\n",
       "      <td>1</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>1</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>...</td>\n",
       "      <td>759.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0100100010515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cve_geo cve_ent cve_mun cve_loc cve_ageb  \\\n",
       "191  0100100010515      01     001    0001     0515   \n",
       "\n",
       "                                              geometry  entidad  \\\n",
       "191  POLYGON ((-102.29278 21.89010, -102.29275 21.8...        1   \n",
       "\n",
       "            nom_ent  mun         nom_mun  ...  vph_cel vph_inter vph_stvp  \\\n",
       "191  Aguascalientes    1  Aguascalientes  ...    759.0     621.0    454.0   \n",
       "\n",
       "     vph_spmvpi  vph_cvj  vph_sinrtv  vph_sintlc  vph_sincint  vph_sintic  \\\n",
       "191       325.0    124.0        19.0        24.0        204.0         NaN   \n",
       "\n",
       "      cve_geo_ageb  \n",
       "191  0100100010515  \n",
       "\n",
       "[1 rows x 237 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_ageb_gdf_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052ec73a-3efd-4247-bc03-2e4a013d9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_mza_gdf_chosen.to_csv('../../../data/external/temporal_fromjupyter/calculate_censo_nan_values/pop_mza_gdf_chosen.csv', index=False)\n",
    "#pop_ageb_gdf_chosen.to_csv('../../../data/external/temporal_fromjupyter/calculate_censo_nan_values/pop_ageb_gdf_chosen.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb51226-b6f0-47a2-9b63-dd329262dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_censo_nan_values_v1(pop_ageb_gdf, pop_mza_gdf,extended_logs=False):\n",
    "    ##########################################################################################\n",
    "\t# STEP 1: CHECK FOR DIFFERENCES IN AVAILABLE AGEBs (PREVENTS CRASH)\n",
    "\n",
    "\t# --------------- 1.1 SET COLUMNS TO .UPPER() EXCEPT FOR GEOMETRY\n",
    "\t# (When the equations were written, we used UPPER names, easier to change it this way and then return output with .lower columns)\n",
    "    pop_ageb_gdf.columns = pop_ageb_gdf.columns.str.upper()\n",
    "    pop_ageb_gdf.rename(columns={'GEOMETRY':'geometry'},inplace=True)\n",
    "    \n",
    "    pop_mza_gdf.columns = pop_mza_gdf.columns.str.upper()\n",
    "    pop_mza_gdf.rename(columns={'GEOMETRY':'geometry'},inplace=True)\n",
    "\n",
    "\t# --------------- 1.2 CHECK FOR DIFFERENCES IN AGEBs\n",
    "\t# Look for AGEBs in both gdfs\n",
    "    agebs_in_ageb_gdf = list(pop_ageb_gdf['CVE_AGEB'].unique())\n",
    "    agebs_in_mza_gdf = list(pop_mza_gdf['CVE_AGEB'].unique())\n",
    "    \n",
    "    if (len(agebs_in_ageb_gdf) == 0) and (len(agebs_in_mza_gdf) == 0):\n",
    "        print(\"Error: Area of interest has no pop data.\")\n",
    "        intended_crash\n",
    "\n",
    "\t# Test for AGEBs present in mza_gdf but not in AGEB_gdf\n",
    "    missing_agebs = list(set(agebs_in_mza_gdf) - set(agebs_in_ageb_gdf))\n",
    "    if len(missing_agebs) > 0:\n",
    "        print(f'WARNING: AGEBs {missing_agebs} present in mza_gdf but missing from ageb_gdf.')\n",
    "        print(f'WARNING: Removing AGEBs {missing_agebs} from AGEB analysis.')\n",
    "    else:\n",
    "        print(\"No problem\")\n",
    "    \n",
    "\t##########################################################################################\n",
    "\t# STEP 2: CALCULATE NAN VALUES\n",
    "    print(\"STARTING NANs calculation.\")\n",
    "\n",
    "\t# STATISTICS - LOG DATA\n",
    "\t# Will create progress logs when progress reaches these percentages:\n",
    "    progress_logs = [10,20,30,40,50,60,70,80,90,100]\n",
    "\t# This df stores accumulative (All AGEBs) statistics for logs.\n",
    "    acc_statistics = pd.DataFrame()\n",
    "\n",
    "\t# --------------- NaNs CALCULATION 2.0) Start\n",
    "    i = 1\n",
    "    for ageb in agebs_in_mza_gdf: # Most of the code of this function iterates over each AGEB\n",
    "        if extended_logs:\n",
    "            print('--'*20)\n",
    "            print(f'Calculating NaNs for AGEB {ageb} ({i}/{len(agebs_in_mza_gdf)}.)')\n",
    "\t\t\n",
    "\t\t# STATISTICS - PROGRESS LOG DATA\n",
    "\t\t# Measures current progress, prints if passed a checkpoint of progress_logs list.\n",
    "        current_progress = (i / len(agebs_in_mza_gdf))*100\n",
    "        for checkpoint in progress_logs:\n",
    "            if current_progress >= checkpoint:\n",
    "                print(f'Calculating NaNs. {checkpoint}% done.')\n",
    "                progress_logs.remove(checkpoint)\n",
    "                break\n",
    "        \n",
    "\t\t# --------------- NaNs CALCULATION 2.1) FIND CURRENT AGEB BLOCK DATA\n",
    "        mza_ageb_gdf = pop_mza_gdf.loc[pop_mza_gdf['CVE_AGEB'] == ageb].copy()\n",
    "        \n",
    "\t\t# --------------- NaNs CALCULATION 2.2) KEEP OUT OF THE PROCESS ROWS WHICH HAVE 0 VALUES (ALL values are NaNs)\n",
    "\t\t# 2.2a) Set columns to be analysed\n",
    "        columns_of_interest = ['POBFEM','POBMAS',\n",
    "\t\t\t\t\t\t\t'P_0A2','P_0A2_F','P_0A2_M',\n",
    "\t\t\t\t\t\t\t'P_3A5','P_3A5_F','P_3A5_M',\n",
    "\t\t\t\t\t\t\t'P_6A11','P_6A11_F','P_6A11_M',\n",
    "\t\t\t\t\t\t\t'P_12A14','P_12A14_F','P_12A14_M',\n",
    "\t\t\t\t\t\t\t'P_15A17','P_15A17_F','P_15A17_M',\n",
    "\t\t\t\t\t\t\t'P_18A24','P_18A24_F','P_18A24_M',\n",
    "\t\t\t\t\t\t\t'P_60YMAS','P_60YMAS_F','P_60YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_3YMAS','P_3YMAS_F','P_3YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_12YMAS','P_12YMAS_F','P_12YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_15YMAS','P_15YMAS_F','P_15YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_18YMAS','P_18YMAS_F','P_18YMAS_M',\n",
    "\t\t\t\t\t\t\t'REL_H_M','POB0_14','POB15_64','POB65_MAS']\n",
    "        blocks = mza_ageb_gdf[['CVEGEO','POBTOT'] + columns_of_interest].copy()\n",
    "\t\t\n",
    "\t\t# 2.2b) Set found values to 0\n",
    "        blocks['found_values'] = 0\n",
    "\t\t\n",
    "\t\t# 2.2c) Find rows with nan values and sum of nan values\n",
    "        for col in columns_of_interest:\n",
    "\t\t\t# Turn to numeric\n",
    "            blocks[col] = pd.to_numeric(blocks[col])\n",
    "\t\t\t# Set checker column to 'exist' (1)\n",
    "            blocks[f'check_{col}'] = 1\n",
    "\t\t\t# If it doesn't exist, set that row's check to (0)\n",
    "            idx = blocks[col].isna()\n",
    "            blocks.loc[idx, f'check_{col}'] = 0\n",
    "\t\t\t# Sum total row nan values\n",
    "            blocks['found_values'] = blocks['found_values'] + blocks[f'check_{col}']\n",
    "\t\t\t# Drop checker column\n",
    "            blocks.drop(columns=[f'check_{col}'],inplace=True)\n",
    "\t\t\n",
    "\t\t# 2.2d) Loc rows with values in columns_of_interest (Can calculate NaNs)\n",
    "        blocks_values = blocks.loc[blocks['found_values'] > 0].copy()\n",
    "        blocks_values.drop(columns=['found_values'],inplace=True)\n",
    "\t\t\n",
    "\t\t# 2.2e) Save rows with 0 values for later. (Can't calculate NaNs, must distribute values).\n",
    "        blocks_nans = blocks.loc[blocks['found_values'] == 0].copy()\n",
    "        blocks_nans.drop(columns=['found_values'],inplace=True)\n",
    "        \n",
    "        del blocks\n",
    "\t\t\n",
    "\t\t# --------------- NaNs CALCULATION 3) CALCULATE NaN values in blocks\n",
    "        if extended_logs:\n",
    "            print(f'Calculating NaNs using block data for AGEB {ageb}.')\n",
    "        # 2.3a) Count current (original) nan values\n",
    "        original_nan_values = int(blocks_values.isna().sum().sum())\n",
    "        # 2.3b) Set a start and finish nan value for while loop and run\n",
    "        start_nan_values = original_nan_values\n",
    "        finish_nan_values = start_nan_values - 1\n",
    "        loop_count = 1\n",
    "        while start_nan_values > finish_nan_values:\n",
    "\t\t\t# ROUND STARTING DATA\n",
    "            start_nan_values = blocks_values.isna().sum().sum()\n",
    "\n",
    "\t\t\t# 2.3c) Set of equation with structure [PARENT] = [SUB] + [SUB]\n",
    "\t\t\t# POBTOT = POBFEM + POBMAS\n",
    "            blocks_values.POBTOT.fillna(blocks_values.POBFEM + blocks_values.POBMAS, inplace=True)\n",
    "            blocks_values.POBFEM.fillna(blocks_values.POBTOT - blocks_values.POBMAS, inplace=True)\n",
    "            blocks_values.POBMAS.fillna(blocks_values.POBTOT - blocks_values.POBFEM, inplace=True)\n",
    "\t\t\t# P_0A2 = P_0A2_F + P_0A2_M\n",
    "            blocks_values.P_0A2.fillna(blocks_values.P_0A2_F + blocks_values.P_0A2_M, inplace=True)\n",
    "            blocks_values.P_0A2_F.fillna(blocks_values.P_0A2 - blocks_values.P_0A2_M, inplace=True)\n",
    "            blocks_values.P_0A2_M.fillna(blocks_values.P_0A2 - blocks_values.P_0A2_F, inplace=True)\n",
    "\t\t\t# P_3A5 = P_3A5_F + P_3A5_M\n",
    "            blocks_values.P_3A5.fillna(blocks_values.P_3A5_F + blocks_values.P_3A5_M, inplace=True)\n",
    "            blocks_values.P_3A5_F.fillna(blocks_values.P_3A5 - blocks_values.P_3A5_M, inplace=True)\n",
    "            blocks_values.P_3A5_M.fillna(blocks_values.P_3A5 - blocks_values.P_3A5_F, inplace=True)\n",
    "\t\t\t# P_6A11 = P_6A11_F + P_6A11_M\n",
    "            blocks_values.P_6A11.fillna(blocks_values.P_6A11_F + blocks_values.P_6A11_M, inplace=True)\n",
    "            blocks_values.P_6A11_F.fillna(blocks_values.P_6A11 - blocks_values.P_6A11_M, inplace=True)\n",
    "            blocks_values.P_6A11_M.fillna(blocks_values.P_6A11 - blocks_values.P_6A11_F, inplace=True)\n",
    "\t\t\t# P_12A14 = P_12A14_F + P_12A14_M\n",
    "            blocks_values.P_12A14.fillna(blocks_values.P_12A14_F + blocks_values.P_12A14_M, inplace=True)\n",
    "            blocks_values.P_12A14_F.fillna(blocks_values.P_12A14 - blocks_values.P_12A14_M, inplace=True)\n",
    "            blocks_values.P_12A14_M.fillna(blocks_values.P_12A14 - blocks_values.P_12A14_F, inplace=True)\n",
    "\t\t\t# P_15A17 = P_15A17_F + P_15A17_M\n",
    "            blocks_values.P_15A17.fillna(blocks_values.P_15A17_F + blocks_values.P_15A17_M, inplace=True)\n",
    "            blocks_values.P_15A17_F.fillna(blocks_values.P_15A17 - blocks_values.P_15A17_M, inplace=True)\n",
    "            blocks_values.P_15A17_M.fillna(blocks_values.P_15A17 - blocks_values.P_15A17_F, inplace=True)\n",
    "\t\t\t# P_18A24 = P_18A24_F + P_18A24_M\n",
    "            blocks_values.P_18A24.fillna(blocks_values.P_18A24_F + blocks_values.P_18A24_M, inplace=True)\n",
    "            blocks_values.P_18A24_F.fillna(blocks_values.P_18A24 - blocks_values.P_18A24_M, inplace=True)\n",
    "            blocks_values.P_18A24_M.fillna(blocks_values.P_18A24 - blocks_values.P_18A24_F, inplace=True)\n",
    "\t\t\t# P_60YMAS = P_60YMAS_F + P_60YMAS_M\n",
    "            blocks_values.P_60YMAS.fillna(blocks_values.P_60YMAS_F + blocks_values.P_60YMAS_M, inplace=True)\n",
    "            blocks_values.P_60YMAS_F.fillna(blocks_values.P_60YMAS - blocks_values.P_60YMAS_M, inplace=True)\n",
    "            blocks_values.P_60YMAS_M.fillna(blocks_values.P_60YMAS - blocks_values.P_60YMAS_F, inplace=True)\n",
    "\t\t\t\n",
    "\t\t\t# 2.3d) Set of equation with structure [POBTOT] - [{n}_YMAS] = [group] + [group] + ... + [group]\n",
    "\t\t\t# POBTOT - P_3YMAS = P_0A2\n",
    "\t\t\t# --> P_0A2 = POBTOT - P_3YMAS\n",
    "            blocks_values.P_0A2.fillna(blocks_values.POBTOT - blocks_values.P_3YMAS, inplace=True)\n",
    "            blocks_values.P_0A2_F.fillna(blocks_values.POBFEM - blocks_values.P_3YMAS_F, inplace=True)\n",
    "            blocks_values.P_0A2_M.fillna(blocks_values.POBMAS - blocks_values.P_3YMAS_M, inplace=True)\n",
    "\t\t\t# --> P_3YMAS = POBTOT - P_0A2\n",
    "            blocks_values.P_3YMAS.fillna(blocks_values.POBTOT - blocks_values.P_0A2, inplace=True)\n",
    "            blocks_values.P_3YMAS_F.fillna(blocks_values.POBFEM - blocks_values.P_0A2_F, inplace=True)\n",
    "            blocks_values.P_3YMAS_M.fillna(blocks_values.POBMAS - blocks_values.P_0A2_M, inplace=True)\n",
    "\t\t\t# POBTOT - P_12YMAS = (P_0A2 + P_3A5 + P_6A11)\n",
    "\t\t\t# --> P_0A2 = POBTOT - P_12YMAS - P_3A5 - P_6A11\n",
    "            blocks_values.P_0A2.fillna(blocks_values.POBTOT - blocks_values.P_12YMAS - blocks_values.P_3A5 - blocks_values.P_6A11, inplace=True)\n",
    "            blocks_values.P_0A2_F.fillna(blocks_values.POBFEM - blocks_values.P_12YMAS_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F, inplace=True)\n",
    "            blocks_values.P_0A2_M.fillna(blocks_values.POBMAS - blocks_values.P_12YMAS_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M, inplace=True)\n",
    "    \t\t# --> P_3A5 = POBTOT - P_12YMAS - P_0A2 - P_6A11\n",
    "            blocks_values.P_3A5.fillna(blocks_values.POBTOT - blocks_values.P_12YMAS - blocks_values.P_0A2 - blocks_values.P_6A11, inplace=True)\n",
    "            blocks_values.P_3A5_F.fillna(blocks_values.POBFEM - blocks_values.P_12YMAS_F - blocks_values.P_0A2_F - blocks_values.P_6A11_F, inplace=True)\n",
    "            blocks_values.P_3A5_M.fillna(blocks_values.POBMAS - blocks_values.P_12YMAS_M - blocks_values.P_0A2_M - blocks_values.P_6A11_M, inplace=True)\n",
    "\t\t\t# --> P_6A11 = POBTOT - P_12YMAS - P_0A2 - P_3A5\n",
    "            blocks_values.P_6A11.fillna(blocks_values.POBTOT - blocks_values.P_12YMAS - blocks_values.P_0A2 - blocks_values.P_3A5, inplace=True)\n",
    "            blocks_values.P_6A11_F.fillna(blocks_values.POBFEM - blocks_values.P_12YMAS_F - blocks_values.P_0A2_F - blocks_values.P_3A5_F, inplace=True)\n",
    "            blocks_values.P_6A11_M.fillna(blocks_values.POBMAS - blocks_values.P_12YMAS_M - blocks_values.P_0A2_M - blocks_values.P_3A5_M, inplace=True)\n",
    "\t\t\t# --> P_12YMAS = POBTOT - P_0A2 - P_3A5 -P_6A11\n",
    "            blocks_values.P_12YMAS.fillna(blocks_values.POBTOT - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_6A11, inplace=True)\n",
    "            blocks_values.P_12YMAS_F.fillna(blocks_values.POBFEM - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F, inplace=True)\n",
    "            blocks_values.P_12YMAS_M.fillna(blocks_values.POBMAS - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M, inplace=True)\n",
    "\t\t\t# POBTOT - P_15YMAS = (P_0A2 + P_3A5 + P_6A11 + P_12A14)\n",
    "\t\t\t# --> P_0A2 = POBTOT - P_15YMAS - P_3A5 - P_6A11 - P_12A14\n",
    "            blocks_values.P_0A2.fillna(blocks_values.POBTOT - blocks_values.P_15YMAS - blocks_values.P_3A5 - blocks_values.P_6A11 - blocks_values.P_12A14, inplace=True)\n",
    "            blocks_values.P_0A2_F.fillna(blocks_values.POBFEM - blocks_values.P_15YMAS_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F - blocks_values.P_12A14_F, inplace=True)\n",
    "            blocks_values.P_0A2_M.fillna(blocks_values.POBMAS - blocks_values.P_15YMAS_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M - blocks_values.P_12A14_M, inplace=True)\n",
    "\t\t\t# --> P_3A5 = POBTOT - P_15YMAS - P_0A2 - P_6A11 - P_12A14\n",
    "            blocks_values.P_3A5.fillna(blocks_values.POBTOT - blocks_values.P_15YMAS - blocks_values.P_0A2 - blocks_values.P_6A11 - blocks_values.P_12A14, inplace=True)\n",
    "            blocks_values.P_3A5_F.fillna(blocks_values.POBFEM - blocks_values.P_15YMAS_F - blocks_values.P_0A2_F - blocks_values.P_6A11_F - blocks_values.P_12A14_F, inplace=True)\n",
    "            blocks_values.P_3A5_M.fillna(blocks_values.POBMAS - blocks_values.P_15YMAS_M - blocks_values.P_0A2_M - blocks_values.P_6A11_M - blocks_values.P_12A14_M, inplace=True)\n",
    "\t\t\t# --> P_6A11 = POBTOT - P_15YMAS - P_0A2 - P_3A5 - P_12A14\n",
    "            blocks_values.P_6A11.fillna(blocks_values.POBTOT - blocks_values.P_15YMAS - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_12A14, inplace=True)\n",
    "            blocks_values.P_6A11_F.fillna(blocks_values.POBFEM - blocks_values.P_15YMAS_F - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_12A14_F, inplace=True)\n",
    "            blocks_values.P_6A11_M.fillna(blocks_values.POBMAS - blocks_values.P_15YMAS_M - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_12A14_M, inplace=True)\n",
    "\t\t\t# --> P_12A14 = POBTOT - P_15YMAS - P_0A2 - P_3A5 - P_6A11\n",
    "            blocks_values.P_12A14.fillna(blocks_values.POBTOT - blocks_values.P_15YMAS - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_6A11, inplace=True)\n",
    "            blocks_values.P_12A14_F.fillna(blocks_values.POBFEM - blocks_values.P_15YMAS_F - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F, inplace=True)\n",
    "            blocks_values.P_12A14_M.fillna(blocks_values.POBMAS - blocks_values.P_15YMAS_M - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M, inplace=True)\n",
    "            # --> P_15YMAS = POBTOT - P_0A2 - P_3A5 - P_6A11 - P_12A14\n",
    "            blocks_values.P_15YMAS.fillna(blocks_values.POBTOT - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_6A11 - blocks_values.P_12A14, inplace=True)\n",
    "            blocks_values.P_15YMAS_F.fillna(blocks_values.POBFEM - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F - blocks_values.P_12A14_F, inplace=True)\n",
    "            blocks_values.P_15YMAS_M.fillna(blocks_values.POBMAS - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M - blocks_values.P_12A14_M, inplace=True)\n",
    "            # POBTOT - P_18YMAS = (P_0A2 + P_3A5 + P_6A11 + P_12A14 + P_15A17)\n",
    "\t\t\t# --> P_0A2 = POBTOT - P_18YMAS - P_3A5 - P_6A11 - P_12A14 - P_15A17\n",
    "            blocks_values.P_0A2.fillna(blocks_values.POBTOT - blocks_values.P_18YMAS - blocks_values.P_3A5 - blocks_values.P_6A11 - blocks_values.P_12A14 - blocks_values.P_15A17, inplace=True)\n",
    "            blocks_values.P_0A2_F.fillna(blocks_values.POBFEM - blocks_values.P_18YMAS_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F - blocks_values.P_12A14_F - blocks_values.P_15A17_F, inplace=True)\n",
    "            blocks_values.P_0A2_M.fillna(blocks_values.POBMAS - blocks_values.P_18YMAS_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M - blocks_values.P_12A14_M - blocks_values.P_15A17_M, inplace=True)\n",
    "\t\t\t# --> P_3A5 = POBTOT - P_18YMAS - P_0A2 - P_6A11 - P_12A14 - P_15A17\n",
    "            blocks_values.P_3A5.fillna(blocks_values.POBTOT - blocks_values.P_18YMAS - blocks_values.P_0A2 - blocks_values.P_6A11 - blocks_values.P_12A14 - blocks_values.P_15A17, inplace=True)\n",
    "            blocks_values.P_3A5_F.fillna(blocks_values.POBFEM - blocks_values.P_18YMAS_F - blocks_values.P_0A2_F - blocks_values.P_6A11_F - blocks_values.P_12A14_F - blocks_values.P_15A17_F, inplace=True)\n",
    "            blocks_values.P_3A5_M.fillna(blocks_values.POBMAS - blocks_values.P_18YMAS_M - blocks_values.P_0A2_M - blocks_values.P_6A11_M - blocks_values.P_12A14_M - blocks_values.P_15A17_M, inplace=True)\n",
    "\t\t\t# --> P_6A11 = POBTOT - P_18YMAS - P_0A2 - P_3A5 - P_12A14 - P_15A17\n",
    "            blocks_values.P_6A11.fillna(blocks_values.POBTOT - blocks_values.P_18YMAS - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_12A14 - blocks_values.P_15A17, inplace=True)\n",
    "            blocks_values.P_6A11_F.fillna(blocks_values.POBFEM - blocks_values.P_18YMAS_F - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_12A14_F - blocks_values.P_15A17_F, inplace=True)\n",
    "            blocks_values.P_6A11_M.fillna(blocks_values.POBMAS - blocks_values.P_18YMAS_M - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_12A14_M - blocks_values.P_15A17_M, inplace=True)\n",
    "\t\t\t# --> P_12A14 = POBTOT - P_18YMAS - P_0A2 - P_3A5 - P_6A11 - P_15A17\n",
    "            blocks_values.P_12A14.fillna(blocks_values.POBTOT - blocks_values.P_18YMAS - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_6A11 - blocks_values.P_15A17, inplace=True)\n",
    "            blocks_values.P_12A14_F.fillna(blocks_values.POBFEM - blocks_values.P_18YMAS_F - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F - blocks_values.P_15A17_F, inplace=True)\n",
    "            blocks_values.P_12A14_M.fillna(blocks_values.POBMAS - blocks_values.P_18YMAS_M - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M - blocks_values.P_15A17_M, inplace=True)\n",
    "\t\t\t# --> P_15A17 = POBTOT - P_18YMAS - P_0A2 - P_3A5 - P_6A11 - P_12A14\n",
    "            blocks_values.P_15A17.fillna(blocks_values.POBTOT - blocks_values.P_18YMAS - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_6A11 - blocks_values.P_12A14, inplace=True)\n",
    "            blocks_values.P_15A17_F.fillna(blocks_values.POBFEM - blocks_values.P_18YMAS_F - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F - blocks_values.P_12A14_F, inplace=True)\n",
    "            blocks_values.P_15A17_M.fillna(blocks_values.POBMAS - blocks_values.P_18YMAS_M - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M - blocks_values.P_12A14_M, inplace=True)\n",
    "\t\t\t# --> P_18YMAS = POBTOT - P_0A2 - P_3A5 - P_6A11 - P_12A14 - P_15A17\n",
    "            blocks_values.P_18YMAS.fillna(blocks_values.POBTOT - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_6A11 - blocks_values.P_12A14 - blocks_values.P_15A17, inplace=True)\n",
    "            blocks_values.P_18YMAS_F.fillna(blocks_values.POBFEM - blocks_values.P_0A2_F - blocks_values.P_3A5_F - blocks_values.P_6A11_F - blocks_values.P_12A14_F - blocks_values.P_15A17_F, inplace=True)\n",
    "            blocks_values.P_18YMAS_M.fillna(blocks_values.POBMAS - blocks_values.P_0A2_M - blocks_values.P_3A5_M - blocks_values.P_6A11_M - blocks_values.P_12A14_M - blocks_values.P_15A17_M, inplace=True)\n",
    "\n",
    "\t\t\t# 2.3e) Set of complementary equations\n",
    "\t\t\t# REL_H_M = (POBMAS/POBFEM)*100\n",
    "\t\t\t# --> POBMAS = (REL_H_M/100) * POBFEM\n",
    "            blocks_values.POBMAS.fillna(round((blocks_values.REL_H_M / 100) * blocks_values.POBFEM,0), inplace=True)\n",
    "\t\t\t# --> POBFEM = (POBMAS * 100) / REL_H_M\n",
    "            blocks_values.POBFEM.fillna(round((blocks_values.POBMAS * 100) / blocks_values.REL_H_M,0), inplace=True)\n",
    "\t\t\t# POBTOT = POB0_14 + POB15_64 + POB65_MAS\n",
    "\t\t\t# --> POB0_14 = POBTOT - POB15_64 - POB65_MAS\n",
    "            blocks_values.POB0_14.fillna(blocks_values.POBTOT - blocks_values.POB15_64 - blocks_values.POB65_MAS, inplace=True)\n",
    "    \t\t# --> POB15_64 = POBTOT - POB0_14 - POB65_MAS\n",
    "            blocks_values.POB15_64.fillna(blocks_values.POBTOT - blocks_values.POB0_14 - blocks_values.POB65_MAS, inplace=True)\n",
    "\t\t\t# --> POB65_MAS = POBTOT - POB0_14 - POB15_64\n",
    "            blocks_values.POB65_MAS.fillna(blocks_values.POBTOT - blocks_values.POB0_14 - blocks_values.POB15_64, inplace=True)\n",
    "\t\t\t# POB0_14 = P_0A2 + P_3A5 + P_6A11 + P_12A14\n",
    "\t\t\t# --> POB0_14 = P_0A2 + P_3A5 + P_6A11 + P_12A14\n",
    "            blocks_values.POB0_14.fillna(blocks_values.P_0A2 + blocks_values.P_3A5 + blocks_values.P_6A11 + blocks_values.P_12A14, inplace=True)\n",
    "    \t\t# --> P_0A2 = POB0_14 - P_3A5 - P_6A11 - P_12A14\n",
    "            blocks_values.P_0A2.fillna(blocks_values.POB0_14 - blocks_values.P_3A5 - blocks_values.P_6A11 - blocks_values.P_12A14, inplace=True)\n",
    "\t\t\t# --> P_3A5 = POB0_14 - P_0A2 - P_6A11 - P_12A14\n",
    "            blocks_values.P_3A5.fillna(blocks_values.POB0_14 - blocks_values.P_0A2 - blocks_values.P_6A11 - blocks_values.P_12A14, inplace=True)\n",
    "\t\t\t# --> P_6A11 = POB0_14 - P_0A2 - P_3A5 - P_12A14\n",
    "            blocks_values.P_6A11.fillna(blocks_values.POB0_14 - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_12A14, inplace=True)\t\t\t\t\n",
    "\t\t\t# --> P_12A14 = POB0_14 - P_0A2 - P_3A5 - P_6A11\n",
    "            blocks_values.P_12A14.fillna(blocks_values.POB0_14 - blocks_values.P_0A2 - blocks_values.P_3A5 - blocks_values.P_6A11, inplace=True) \n",
    "\t\t\t# P_15YMAS = POBTOT - POB0_14\n",
    "\t\t\t# --> P_15YMAS = POBTOT - POB0_14\n",
    "            blocks_values.P_15YMAS.fillna(blocks_values.POBTOT - blocks_values.POB0_14, inplace=True)\n",
    "\t\t\t# --> POB0_14 = POBTOT - P_15YMAS\n",
    "            blocks_values.POB0_14.fillna(blocks_values.POBTOT - blocks_values.P_15YMAS, inplace=True)\n",
    "\t\t\t\n",
    "\t\t\t# ROUND FINISHING DATA\n",
    "            finish_nan_values = blocks_values.isna().sum().sum()\n",
    "            if extended_logs:\n",
    "                print(f'Round {loop_count} Starting with {start_nan_values} nan values. Finishing with {finish_nan_values} nan values.')\n",
    "            loop_count += 1\n",
    "        nan_reduction = round(((1-(finish_nan_values/original_nan_values))*100),2)\n",
    "        if extended_logs:\n",
    "            print(f'Originally had {original_nan_values} nan values, now there are {finish_nan_values}. A {nan_reduction}% reduction.')\n",
    "\t\t\n",
    "\t\t# 2.3f) Join back blocks with all nan values\n",
    "        blocks_calc = pd.concat([blocks_values,blocks_nans])\n",
    "        \n",
    "        return blocks_calc, blocks_values\n",
    "\n",
    "        a = \"\"\"\n",
    "        \n",
    "\t\t# --------------- NaNs CALCULATION 4) FOR THE NAN VALUES THAT COULDN'T BE SOLVED, DISTRIBUTE AGEB VALUES.\n",
    "\t\t\n",
    "\t\t# 2.4a) Prepare for second loop\n",
    "\t\t# Remove masc/fem relation from analysis. \n",
    "\t\t# It complicates this and further processes, when needed calculate using (REL_H_M = (POBMAS/POBFEM)*100)\n",
    "\t\tageb_filling_cols = columns_of_interest.copy()\n",
    "\t\tageb_filling_cols.remove('REL_H_M')\n",
    "\t\tblocks_calc.drop(columns=['REL_H_M'],inplace=True)\n",
    "\n",
    "\t\tif ageb not in missing_agebs:\n",
    "\n",
    "\t\t\tif extended_logs:\n",
    "\t\t\t\tprint(f'Calculating NaNs using AGEB data for AGEB {ageb}.')\n",
    "\n",
    "\t\t\t# Locate AGEB data in pop_ageb_gdf\n",
    "\t\t\tageb_gdf = pop_ageb_gdf.loc[pop_ageb_gdf['CVE_AGEB'] == ageb]\n",
    "\n",
    "\t\t\t# Solving method used to solve column\n",
    "\t\t\tsolved_using_blocks = 0 # for log statistics\n",
    "\t\t\tsolved_using_ageb = 0 # for log statistics\n",
    "\t\t\t\n",
    "\t\t\t# 2.4b) Fill with AGEB values.\n",
    "\t\t\tfor col in ageb_filling_cols:\n",
    "\t\t\t\t# Find number of nan values in current col\n",
    "\t\t\t\tcol_nan_values = blocks_calc.isna().sum()[col]\n",
    "\n",
    "\t\t\t\t# If there are no nan values left in col, pass.\n",
    "\t\t\t\tif col_nan_values == 0:\n",
    "\t\t\t\t\tsolved_using_blocks += 1 # for log statistics\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Elif there is only one value left, assign missing value directly to cell.\n",
    "\t\t\t\telif col_nan_values == 1: \n",
    "\t\t\t\t\t# Calculate missing value\n",
    "\t\t\t\t\tageb_col_value = ageb_gdf[col].unique()[0]\n",
    "\t\t\t\t\tcurrent_block_sum = blocks_calc[col].sum()\n",
    "\t\t\t\t\tmissing_value = ageb_col_value - current_block_sum\n",
    "\t\t\t\t\t# Add missing value to na spot in column\n",
    "\t\t\t\t\tblocks_calc[col].fillna(missing_value,inplace=True)\n",
    "\t\t\t\t\tsolved_using_ageb += 1 # for log statistics\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Elif there are more than one nan in col, distribute using POBTOT of those blocks as distr. method.\n",
    "\t\t\t\telif col_nan_values > 1:        \n",
    "\t\t\t\t\t# Locate rows with NaNs in current col\n",
    "\t\t\t\t\tidx = blocks_calc[col].isna()\n",
    "\t\t\t\t\t# Set distributing factor to 0\n",
    "\t\t\t\t\tblocks_calc['dist_factor'] = 0\n",
    "\t\t\t\t\t# Assign to those rows a distributing factor ==> (POBTOT of each row / sum of POBTOT of those rows)\n",
    "\t\t\t\t\tblocks_calc.loc[idx,'dist_factor'] = (blocks_calc['POBTOT']) / blocks_calc.loc[idx]['POBTOT'].sum()\n",
    "\t\t\t\t\t# Calculate missing value\n",
    "\t\t\t\t\tageb_col_value = ageb_gdf[col].unique()[0]\n",
    "\t\t\t\t\tcurrent_block_sum = blocks_calc[col].sum()\n",
    "\t\t\t\t\tmissing_value = ageb_col_value - current_block_sum\n",
    "\t\t\t\t\t# Distribute missing value in those rows using POBTOT factor\n",
    "\t\t\t\t\tblocks_calc[col].fillna(missing_value * blocks_calc['dist_factor'], inplace=True)\n",
    "\t\t\t\t\tblocks_calc.drop(columns=['dist_factor'],inplace=True)\n",
    "\t\t\t\t\tsolved_using_ageb += 1 # for log statistics\n",
    "\n",
    "\t\t\t# Logs Statistics - How was this AGEB solved?\n",
    "\t\t\tif extended_logs:\n",
    "\t\t\t\tpct_col_byblocks = (solved_using_blocks / len(ageb_filling_cols))*100\n",
    "\t\t\t\tpct_col_byagebs = (solved_using_ageb / len(ageb_filling_cols))*100\n",
    "\t\t\t\tprint(f'{pct_col_byblocks}% of columns solved using block data only.')\n",
    "\t\t\t\tprint(f'{pct_col_byagebs}% of columns required AGEB filling.')\n",
    "\t\t\n",
    "\t\t\t# Logs Statistics - Add currently examined AGEB statistics to log df\n",
    "\t\t\tacc_statistics.loc[i,'ageb'] = ageb\n",
    "\t\t\t# Percentage of NaNs found using blocks gdf\n",
    "\t\t\tacc_statistics.loc[i,'nans_calculated'] = nan_reduction\n",
    "\t\t\t# Columns which could be solved entirely using equations in block_gdf\n",
    "\t\t\tacc_statistics.loc[i,'block_calculated'] = solved_using_blocks\n",
    "\t\t\t# Columns which required AGEB filling\n",
    "\t\t\tacc_statistics.loc[i,'ageb_filling'] = solved_using_ageb\n",
    "\t\t\t# All could be solved, so\n",
    "\t\t\tacc_statistics.loc[i,'unable_to_solve'] = 0\n",
    "\n",
    "\t\telse: #current AGEB is in missing_agebs list (Present in mza_gdf, but not in ageb_gdf)\n",
    "\t\t\tif extended_logs:\n",
    "\t\t\t\tprint(f\"NANs on AGEB {ageb} cannot be calculated using AGEB data because it doesn't exist.\")\n",
    "\n",
    "\t\t\t# Solving method used to solve column\n",
    "\t\t\tsolved_using_blocks = 0 # for log statistics\n",
    "\t\t\tunable_tosolve = 0 # for log statistics\n",
    "\t\t\t\n",
    "\t\t\t# # Statistical Loop\n",
    "\t\t\tfor col in ageb_filling_cols:\n",
    "\t\t\t\t# Find number of nan values in current col\n",
    "\t\t\t\tcol_nan_values = blocks_calc.isna().sum()[col]\n",
    "\t\t\t\t# If there are no nan values left in col, pass.\n",
    "\t\t\t\tif col_nan_values == 0:\n",
    "\t\t\t\t\tsolved_using_blocks += 1 # for log statistics\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tunable_tosolve += 1 # for log statistics\n",
    "\n",
    "\t\t\t# Logs Statistics - How was this AGEB solved?\n",
    "\t\t\tif extended_logs:\n",
    "\t\t\t\tpct_col_byblocks = (solved_using_blocks / len(ageb_filling_cols))*100\n",
    "\t\t\t\tpct_col_notsolved = (unable_tosolve / len(ageb_filling_cols))*100\n",
    "\t\t\t\tprint(f\"{pct_col_byblocks}% of columns solved using block data only.\")\n",
    "\t\t\t\tprint(f\"{pct_col_notsolved}% of columns couldn't be solved.\")\n",
    "\n",
    "\t\t\t# Logs Statistics - Add currently examined AGEB statistics to log df\n",
    "\t\t\tacc_statistics.loc[i,'ageb'] = ageb\n",
    "\t\t\t# Percentage of NaNs found using blocks gdf\n",
    "\t\t\tacc_statistics.loc[i,'nans_calculated'] = nan_reduction\n",
    "\t\t\t# Columns which could be solved entirely using equations in block_gdf\n",
    "\t\t\tacc_statistics.loc[i,'block_calculated'] = solved_using_blocks\n",
    "\t\t\t# There wasn't AGEB filling, therefore:\n",
    "\t\t\tacc_statistics.loc[i,'ageb_filling'] = 0\n",
    "\t\t\t# Columns which couldn't be solved because there was no AGEB filling\n",
    "\t\t\tacc_statistics.loc[i,'unable_to_solve'] = unable_tosolve\n",
    "\n",
    "\t\t# --------------- NaNs CALCULATION 5) Return calculated data from this AGEB to original block gdf (mza_ageb_gdf)\n",
    "\t\t# 2.5a) Change original cols for calculated cols\n",
    "\t\tcalculated_cols = ['POBTOT'] + ageb_filling_cols\n",
    "\t\t\n",
    "\t\tmza_ageb_gdf = mza_ageb_gdf.drop(columns=calculated_cols) #Drops current block pop cols\n",
    "\t\tmza_ageb_gdf = pd.merge(mza_ageb_gdf, blocks_calc, on='CVEGEO') #Replaces with blocks_calc cols\n",
    "\n",
    "\t\t# 2.5b) Restore original column order\n",
    "\t\tcolumn_order = list(pop_mza_gdf.columns.values)\n",
    "\t\tmza_ageb_gdf = mza_ageb_gdf[column_order]\n",
    "\n",
    "\t\t# 2.5c) Save to mza_calc gdf (Function output)\n",
    "\t\tif i == 1:\n",
    "\t\t\tmza_calc = mza_ageb_gdf.copy()\n",
    "\t\telse:\n",
    "\t\t\tmza_calc = pd.concat([mza_calc,mza_ageb_gdf])\n",
    "\n",
    "\t\ti += 1\n",
    "\n",
    "\t# Format final output and release final log statistics.\n",
    "\tmza_calc.reset_index(inplace=True)\n",
    "\tmza_calc.drop(columns=['index'],inplace=True)\n",
    "\n",
    "\t# Delivers output cols as .lower()\n",
    "\tmza_calc.columns = mza_calc.columns.str.lower()\n",
    "\n",
    "\tprint(\"Finished calculating NaNs.\")\n",
    "\tprint(f\"Percentage of NaNs found using blocks gdf: {round(acc_statistics['nans_calculated'].mean(),2)}%.\")\n",
    "\tprint(f\"Columns which could be solved entirely using equations in block_gdf: {acc_statistics['block_calculated'].sum()}.\")\n",
    "\tprint(f\"Columns which required AGEB filling: {acc_statistics['ageb_filling'].sum()}.\")\n",
    "\tprint(f\"Columns which couldn't be solved: {acc_statistics['unable_to_solve'].sum()}.\")\n",
    "\t\n",
    "\treturn mza_calc \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea94ece2-3b99-4918-8260-edd09879851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No problem\n",
      "STARTING NANs calculation.\n",
      "----------------------------------------\n",
      "Calculating NaNs for AGEB 0515 (1/1.)\n",
      "Calculating NaNs. 10% done.\n",
      "Calculating NaNs using block data for AGEB 0515.\n",
      "Round 1 Starting with 268 nan values. Finishing with 75 nan values.\n",
      "Round 2 Starting with 75 nan values. Finishing with 47 nan values.\n",
      "Round 3 Starting with 47 nan values. Finishing with 47 nan values.\n",
      "Originally had 268 nan values, now there are 47. A 82.46% reduction.\n",
      "(44, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVEGEO</th>\n",
       "      <th>POBTOT</th>\n",
       "      <th>POBFEM</th>\n",
       "      <th>POBMAS</th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "      <th>P_3A5</th>\n",
       "      <th>P_3A5_F</th>\n",
       "      <th>P_3A5_M</th>\n",
       "      <th>...</th>\n",
       "      <th>P_15YMAS</th>\n",
       "      <th>P_15YMAS_F</th>\n",
       "      <th>P_15YMAS_M</th>\n",
       "      <th>P_18YMAS</th>\n",
       "      <th>P_18YMAS_F</th>\n",
       "      <th>P_18YMAS_M</th>\n",
       "      <th>REL_H_M</th>\n",
       "      <th>POB0_14</th>\n",
       "      <th>POB15_64</th>\n",
       "      <th>POB65_MAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0100100010515001</td>\n",
       "      <td>179</td>\n",
       "      <td>117.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>52.99</td>\n",
       "      <td>31.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0100100010515002</td>\n",
       "      <td>176</td>\n",
       "      <td>95.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>157.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>85.26</td>\n",
       "      <td>19.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0100100010515003</td>\n",
       "      <td>81</td>\n",
       "      <td>47.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>72.34</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CVEGEO  POBTOT  POBFEM  POBMAS  P_0A2  P_0A2_F  P_0A2_M  P_3A5  \\\n",
       "444  0100100010515001     179   117.0    62.0    6.0      4.0      2.0    9.0   \n",
       "445  0100100010515002     176    95.0    81.0    4.0      1.0      3.0    2.0   \n",
       "446  0100100010515003      81    47.0    34.0    4.0      4.0      0.0    3.0   \n",
       "\n",
       "     P_3A5_F  P_3A5_M  ...  P_15YMAS  P_15YMAS_F  P_15YMAS_M  P_18YMAS  \\\n",
       "444      7.0      2.0  ...     148.0        95.0        53.0     142.0   \n",
       "445      1.0      1.0  ...     157.0        86.0        71.0     153.0   \n",
       "446      1.0      2.0  ...      71.0        41.0        30.0      69.0   \n",
       "\n",
       "     P_18YMAS_F  P_18YMAS_M  REL_H_M  POB0_14  POB15_64  POB65_MAS  \n",
       "444        92.0        50.0    52.99     31.0     114.0       34.0  \n",
       "445        83.0        70.0    85.26     19.0     123.0       34.0  \n",
       "446        40.0        29.0    72.34     10.0      60.0       11.0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_calc, blocks_values_org = calculate_censo_nan_values_v1(pop_ageb_gdf_chosen, pop_mza_gdf_chosen,extended_logs=True)\n",
    "\n",
    "# Show\n",
    "print(blocks_values_org.shape)\n",
    "blocks_values_org.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e93885-d75a-4493-8930-22f44812991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVEGEO</th>\n",
       "      <th>POBTOT</th>\n",
       "      <th>POBFEM</th>\n",
       "      <th>POBMAS</th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "      <th>P_3A5</th>\n",
       "      <th>P_3A5_F</th>\n",
       "      <th>P_3A5_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0100100010515001</td>\n",
       "      <td>179</td>\n",
       "      <td>117</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0100100010515002</td>\n",
       "      <td>176</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0100100010515003</td>\n",
       "      <td>81</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CVEGEO  POBTOT POBFEM POBMAS P_0A2 P_0A2_F P_0A2_M P_3A5  \\\n",
       "444  0100100010515001     179    117     62     6       4    None     9   \n",
       "445  0100100010515002     176     95     81     4    None       3  None   \n",
       "446  0100100010515003      81     47     34     4       4       0     3   \n",
       "\n",
       "    P_3A5_F P_3A5_M  \n",
       "444       7    None  \n",
       "445    None    None  \n",
       "446    None    None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pop_mza_gdf_chosen[['CVEGEO','POBTOT','POBFEM','POBMAS','P_0A2','P_0A2_F','P_0A2_M','P_3A5','P_3A5_F','P_3A5_M']]\n",
    "\n",
    "# Show\n",
    "print(original_data.shape)\n",
    "original_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b953e-792b-4fb0-8a0e-bedb61a5878c",
   "metadata": {},
   "source": [
    "## Planteo de solución Chat GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2d936-a7da-482b-9e26-7d2904c6c16e",
   "metadata": {},
   "source": [
    "### Simplificación del problema para ver si se puede resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "df22cc76-c9f4-47a2-9fb8-3450bafa75ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_0A2  P_0A2_F  P_0A2_M\n",
       "0    4.0      4.0      0.0\n",
       "1    NaN      5.0      2.0\n",
       "2    3.0      NaN      2.0\n",
       "3    4.0      3.0      NaN\n",
       "4    NaN      NaN      NaN"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_values_simplified = pd.DataFrame( {'P_0A2': [4, None, 3, 4,None],\n",
    "                                          'P_0A2_F': [4, 5, None, 3,None],\n",
    "                                          'P_0A2_M': [0, 2, 2, None,None]})\n",
    "# Respuesta a los unknowns:\n",
    "# 4 | 4 | 0\n",
    "# (7) | 5 | 2\n",
    "# 3 | (1) | 2\n",
    "# 4 | 3 | (1)\n",
    "# (10) | (5) | (5)\n",
    "# Totales: 28 | 18 | 10\n",
    "\n",
    "total_values = [28,18,10]\n",
    "blocks_values_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "48ff4769-5794-4a41-9026-b28ee719405f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_0A2  P_0A2_F  P_0A2_M\n",
       "0    4.0      4.0      0.0\n",
       "1    7.0      5.0      2.0\n",
       "2    3.0      1.0      2.0\n",
       "3    4.0      3.0      1.0\n",
       "4    7.0      1.0      1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_values_simplified_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "91a7c977-c272-485e-b580-d850e144df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores desconocidos: 6\n",
      "4.0\n",
      "4.0\n",
      "0.0\n",
      "Case 0: Values complete\n",
      "nan\n",
      "5.0\n",
      "2.0\n",
      "Case 1: Unknown P_0A2_val\n",
      "appended 0\n",
      "3.0\n",
      "nan\n",
      "2.0\n",
      "Case 2: Unknown P_0A2_F_val\n",
      "appended 1\n",
      "4.0\n",
      "3.0\n",
      "nan\n",
      "Case 3: Unknown P_0A2_M_val\n",
      "appended 2\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "Case 7: All unknown\n",
      "appended 3\n",
      "appended 4\n",
      "appended 5\n",
      "Unknown variables found: 6.\n",
      "Constraints: 7.\n",
      "Starting optimization using minimize.\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 0.0.\n",
      "0.0\n",
      "28\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 0.0.\n",
      "0.0\n",
      "28\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function x[0] - (5.0 + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 3.0 - (x[1] + 2.0).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function 4.0 - (3.0 + x[2]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function x[3] - (x[4] +  x[5]).\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 0.0.\n",
      "0.0\n",
      "28\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 1.4901161193847656e-08.\n",
      "x[3]: 0.0.\n",
      "1.4901161193847656e-08\n",
      "28\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 0.0.\n",
      "0.0\n",
      "28\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 0.0.\n",
      "0.0\n",
      "28\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 1.4901161193847656e-08.\n",
      "1.4901161193847656e-08\n",
      "28\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 0.0.\n",
      "0.0\n",
      "28\n",
      "Reading function for col P_0A2.\n",
      "11.0\n",
      "[0, 3]\n",
      "x[0]: 0.0.\n",
      "x[3]: 0.0.\n",
      "0.0\n",
      "28\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_F.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function for col P_0A2_.\n",
      "Reading function for col P_0A2_.\n",
      " message: More equality constraints than independent variables\n",
      " success: False\n",
      "  status: 2\n",
      "     fun: 6\n",
      "       x: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "            0.000e+00]\n",
      "     nit: 1\n",
      "     jac: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "            0.000e+00]\n",
      "    nfev: 7\n",
      "    njev: 1\n",
      "index:1\n",
      "col:P_0A2\n",
      "Result: 0.0\n",
      "index:2\n",
      "col:P_0A2_F\n",
      "Result: 0.0\n",
      "index:3\n",
      "col:P_0A2_M\n",
      "Result: 0.0\n",
      "index:4\n",
      "col:P_0A2\n",
      "Result: 0.0\n",
      "index:4\n",
      "col:P_0A2_F\n",
      "Result: 0.0\n",
      "index:4\n",
      "col:P_0A2_M\n",
      "Result: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Esta función recibe y opera en las rows de blocks.\n",
    "def fill_nans(blocks):\n",
    "\n",
    "    # Por ahora intentamos solo con el grupo de 0 a 2 años\n",
    "    # Seleccionar solo las columnas relevantes\n",
    "    relevant_columns = ['P_0A2', 'P_0A2_F', 'P_0A2_M']\n",
    "    \n",
    "    # Aislar la información de las columnas relevantes\n",
    "    blocks_relevant = blocks[relevant_columns]\n",
    "\n",
    "    # Cantidad de valores desconocidos (Si dejo la cantidad completa, crashea. 3 es otra).\n",
    "    print(f\"Valores desconocidos: {np.isnan(blocks_relevant.values).sum()}\")\n",
    "    unknown_values = np.isnan(blocks_relevant.values).sum()\n",
    "    \n",
    "    # Convertir las columnas relevantes a un tipo de datos numéricos\n",
    "    blocks_relevant_numeric = blocks_relevant.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Definir la función objetivo (Lo que queremos minimizar con la función minimize): la cantidad de NaNs.\n",
    "    def objective_function(x, blocks_relevant_numeric):\n",
    "        return np.isnan(blocks_relevant_numeric.values).sum()\n",
    "\n",
    "    # Crear las restricciones (Requisitos a cumplir, se pasan a manera de lista de diccionarios)\n",
    "    def create_constraints(total_values,blocks_relevant_numeric):\n",
    "\n",
    "        constraints = []\n",
    "\n",
    "        # EXPLICACIÓN DE LAS CONSTRAINTS: Las constraints se agregan en la función minimize como lista de diccionarios..\n",
    "        # En cada diccionario de restricciones, 'type':'eq' significa que la restricción es de tipo igualdad. \n",
    "        # Esto indica que queremos que una función de igualdad (definida en 'fun') sea igual a cero.\n",
    "        # La función de igualdad que se debe colocar en 'fun' se crea en las siguientes definiciones. Lo que va después del return debe ser igual a cero.\n",
    "\n",
    "        #----- RESTRICCIONES QUE SON POR FILA -----\n",
    "        # En este caso, la restricción debería asegurar que por fila (por .iterrows) P_0A2 sea igual a P_0A2_F + P_0A2_M.\n",
    "        # El número de variables encontradas (i) corresponderá al número de nans que hay en este caso.\n",
    "\n",
    "        i = 0\n",
    "        # Lista de variables desconocidas encontradas (Necesario para las restricciones por columna)\n",
    "        P_0A2_unknown_vars = []\n",
    "        P_0A2_F_unknown_vars = []\n",
    "        P_0A2_M_unknown_vars = []\n",
    "\n",
    "        unknown_vars = {} # i:(index,col)\n",
    "        \n",
    "        for index, row in blocks_relevant_numeric.iterrows():\n",
    "            P_0A2_val = row['P_0A2']\n",
    "            print(P_0A2_val)\n",
    "            P_0A2_F_val = row['P_0A2_F']\n",
    "            print(P_0A2_F_val)\n",
    "            P_0A2_M_val = row['P_0A2_M']\n",
    "            print(P_0A2_M_val)\n",
    "\n",
    "            # Orden de las variables\n",
    "            # P_0A2_val - (P_0A2_F_val + P_0A2_M_val) --> x[0] - (x[1] + x[2])\n",
    "\n",
    "            ### ---------- ---------- CASOS EN DONDE SE AGREGAN 0 VARIABLES DESCONOCIDAS. ---------- ----------\n",
    "            # Case 0: All values are known (skip)\n",
    "            if not (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 0: Values complete\")\n",
    "                continue\n",
    "                \n",
    "            ### ---------- ---------- CASOS EN DONDE SE AGREGA 1 VARIABLE DESCONOCIDA. ---------- ----------\n",
    "            # Case 1: Unknown P_0A2_val\n",
    "            elif (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 1: Unknown P_0A2_val\")\n",
    "                # Se crea el constraint\n",
    "                def case_1_row_constraint(x, P_0A2_F_val, P_0A2_M_val,i):\n",
    "                    print(f\"Reading function x[{i}] - ({P_0A2_F_val} + {P_0A2_M_val}).\")\n",
    "                    return x[i] - (P_0A2_F_val + P_0A2_M_val)\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': case_1_row_constraint, \n",
    "                                    'args': (P_0A2_F_val, P_0A2_M_val,i)})\n",
    "                # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                P_0A2_unknown_vars.append(i)\n",
    "                unknown_vars[i] = (index,'P_0A2')\n",
    "                print(f\"appended {i}\")\n",
    "                \n",
    "                i += 1\n",
    "\n",
    "            # Case 2: Unknown P_0A2_F_val\n",
    "            elif not (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 2: Unknown P_0A2_F_val\")\n",
    "                # Se crea el constraint\n",
    "                def case_2_row_constraint(x, P_0A2_val, P_0A2_M_val,i):\n",
    "                    print(f\"Reading function {P_0A2_val} - (x[{i}] + {P_0A2_M_val}).\")\n",
    "                    return P_0A2_val - (x[i] + P_0A2_M_val)\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': case_2_row_constraint, \n",
    "                                    'args': (P_0A2_val, P_0A2_M_val,i)})\n",
    "                # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                P_0A2_F_unknown_vars.append(i)\n",
    "                unknown_vars[i] = (index,'P_0A2_F')\n",
    "                print(f\"appended {i}\")\n",
    "                \n",
    "                i += 1\n",
    "\n",
    "            # Case 3: Unknown P_0A2_M_val\n",
    "            elif not (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 3: Unknown P_0A2_M_val\")\n",
    "                # Se crea el constraint\n",
    "                def case_3_row_constraint(x, P_0A2_val, P_0A2_F_val,i):\n",
    "                    print(f\"Reading function {P_0A2_val} - ({P_0A2_F_val} + x[{i}]).\")\n",
    "                    return P_0A2_val - (P_0A2_F_val + x[i])\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': case_3_row_constraint, \n",
    "                                    'args': (P_0A2_val, P_0A2_F_val,i)})\n",
    "                # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                unknown_vars[i] = (index,'P_0A2_M')\n",
    "                P_0A2_M_unknown_vars.append(i)\n",
    "                print(f\"appended {i}\")\n",
    "                \n",
    "                i += 1\n",
    "                \n",
    "            ### ---------- ---------- CASOS EN DONDE SE AGREGAN 2 VARIABLES DESCONOCIDAS. ---------- ----------\n",
    "            # Case 4: Unknown P_0A2_F_val and P_0A2_M_val\n",
    "            elif not (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 4: Unknown P_0A2_F_val and P_0A2_M_val\")\n",
    "                # Se crea el constraint\n",
    "                def case_4_row_constraint(x, P_0A2_val,i):\n",
    "                    print(f\"Reading function {P_0A2_val} - (x[{i}] + x[{i+1}]).\")\n",
    "                    return P_0A2_val - (x[i] + x[i+1])\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': case_4_row_constraint, \n",
    "                                    'args': (P_0A2_val,i)})\n",
    "                # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                P_0A2_F_unknown_vars.append(i)\n",
    "                unknown_vars[i] = (index,'P_0A2_F')\n",
    "                print(f\"appended {i}\")\n",
    "                \n",
    "                P_0A2_M_unknown_vars.append(i+1)\n",
    "                unknown_vars[i+1] = (index,'P_0A2_M')\n",
    "                print(f\"appended {i+1}\")\n",
    "                \n",
    "                i += 2\n",
    "                \n",
    "            # Case 5: Unknown P_0A2_val and P_0A2_M_val\n",
    "            elif (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 5: Unknown P_0A2_val and P_0A2_M_val\")\n",
    "                # Se crea el constraint\n",
    "                def case_5_row_constraint(x, P_0A2_F_val,i):\n",
    "                    print(f\"Reading function x[{i}] - ({P_0A2_F_val} + x[{i+1}]).\")\n",
    "                    return x[i] - (P_0A2_F_val + x[i+1])\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': case_5_row_constraint, \n",
    "                                    'args': (P_0A2_F_val,i)})\n",
    "                # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                P_0A2_unknown_vars.append(i)\n",
    "                unknown_vars[i] = (index,'P_0A2')\n",
    "                print(f\"appended {i}\")\n",
    "                \n",
    "                P_0A2_M_unknown_vars.append(i+1)\n",
    "                unknown_vars[i+1] = (index,'P_0A2_M')\n",
    "                print(f\"appended {i+1}\")\n",
    "                \n",
    "                i += 2\n",
    "                \n",
    "            # Case 6: Unknown P_0A2_val and P_0A2_F_val\n",
    "            elif (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 6: Unknown P_0A2_val and P_0A2_F_val\")\n",
    "                # Se crea el constraint\n",
    "                def case_6_row_constraint(x, P_0A2_M_val,i):\n",
    "                    print(f\"Reading function x[{i}] - (x[{i+1}] + {P_0A2_M_val}).\")\n",
    "                    return x[i] - (x[i+1] + P_0A2_M_val)\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': case_6_row_constraint, \n",
    "                                    'args': (P_0A2_M_val,i)})\n",
    "                # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                P_0A2_unknown_vars.append(i)\n",
    "                unknown_vars[i] = (index,'P_0A2')\n",
    "                print(f\"appended {i}\")\n",
    "                \n",
    "                P_0A2_F_unknown_vars.append(i+1)\n",
    "                unknown_vars[i+1] = (index,'P_0A2_F')\n",
    "                print(f\"appended {i+1}\")\n",
    "                \n",
    "                i += 2\n",
    "                \n",
    "            ### ---------- ---------- CASOS EN DONDE SE AGREGAN 3 VARIABLES DESCONOCIDAS. ---------- ----------\n",
    "            # Case 7: All unknown\n",
    "            elif (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                print(\"Case 7: All unknown\")\n",
    "                # Se crea el constraint\n",
    "                def case_7_row_constraint(x,i):\n",
    "                    print(f\"Reading function x[{i}] - (x[{i+1}] +  x[{i+2}]).\")\n",
    "                    return x[i] - (x[i+1] + x[i+2])\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': case_7_row_constraint,\n",
    "                                    'args': (i,)})\n",
    "                # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                P_0A2_unknown_vars.append(i)\n",
    "                unknown_vars[i] = (index,'P_0A2')\n",
    "                print(f\"appended {i}\")\n",
    "                \n",
    "                P_0A2_F_unknown_vars.append(i+1)\n",
    "                unknown_vars[i+1] = (index,'P_0A2_F')\n",
    "                print(f\"appended {i+1}\")\n",
    "                \n",
    "                P_0A2_M_unknown_vars.append(i+2)\n",
    "                unknown_vars[i+2] = (index,'P_0A2_M')\n",
    "                print(f\"appended {i+2}\")\n",
    "                \n",
    "                i += 3\n",
    "            else:\n",
    "                print(\"Error\")\n",
    "\n",
    "        print(f\"Unknown variables found: {i}.\")\n",
    "\n",
    "        #----- RESTRICCIONES QUE SON POR COLUMNA -----\n",
    "        # Restricción para P_0A2\n",
    "        def constraint_total_P_0A2(x,blocks_relevant_numeric,P_0A2_unknown_vars,total_values):\n",
    "            #Restricción: La suma de los valores actuales en la columna + los valores encontrados - el valor total conocido[1] debe ser igual a 0.\n",
    "            print(f\"Reading function for col P_0A2.\")\n",
    "            print(np.nansum(blocks_relevant_numeric['P_0A2']))\n",
    "            print(P_0A2_unknown_vars)\n",
    "            for i_value in P_0A2_unknown_vars:\n",
    "                print(f\"x[{i_value}]: {x[i_value]}.\")\n",
    "            print(np.nansum(x[P_0A2_unknown_vars]))\n",
    "            print(total_values[0] )\n",
    "            \n",
    "            return np.nansum(blocks_relevant_numeric['P_0A2']) + np.nansum(x[P_0A2_unknown_vars]) - total_values[0] \n",
    "        constraints.append({'type': 'eq', \n",
    "                            'fun': constraint_total_P_0A2,\n",
    "                            'args':(blocks_relevant_numeric,P_0A2_unknown_vars,total_values)})\n",
    "        \n",
    "        # Restricción para P_0A2_F\n",
    "        def constraint_total_P_0A2_F(x,blocks_relevant_numeric,P_0A2_F_unknown_vars,total_values):\n",
    "            #Restricción: La suma de los valores actuales en la columna + los valores encontrados - el valor total conocido[2] debe ser igual a 0.\n",
    "            print(f\"Reading function for col P_0A2_F.\")\n",
    "            return np.nansum(blocks_relevant_numeric['P_0A2_F']) + np.nansum(x[P_0A2_F_unknown_vars]) - total_values[1]\n",
    "        constraints.append({'type': 'eq', \n",
    "                            'fun': constraint_total_P_0A2_F,\n",
    "                            'args':(blocks_relevant_numeric,P_0A2_F_unknown_vars,total_values)})\n",
    "        \n",
    "        # Restricción para P_0A2_M\n",
    "        def constraint_total_P_0A2_M(x,blocks_relevant_numeric,P_0A2_M_unknown_vars,total_values):\n",
    "            #Restricción: La suma de los valores actuales en la columna + los valores encontrados - el valor total conocido[3] debe ser igual a 0.\n",
    "            print(f\"Reading function for col P_0A2_.\")\n",
    "            return np.nansum(blocks_relevant_numeric['P_0A2_M']) + np.nansum(x[P_0A2_M_unknown_vars]) - total_values[2]\n",
    "        constraints.append({'type': 'eq', \n",
    "                            'fun': constraint_total_P_0A2_M,\n",
    "                            'args':(blocks_relevant_numeric,P_0A2_M_unknown_vars,total_values)})\n",
    "        \n",
    "        return constraints, unknown_vars\n",
    "\n",
    "    # Definir las restricciones (Correr lo anterior)\n",
    "    constraints, unknown_vars = create_constraints(total_values, blocks_relevant_numeric)\n",
    "    print(f\"Constraints: {len(constraints)}.\")\n",
    "\n",
    "    # Initial guess - El número de elementos en initial_guess debe corresponder al número de variables de decisión en tu problema de optimización.\n",
    "    # Está crasheando si dejo todas, por eso unknown_values = 3.\n",
    "    initial_guess = np.zeros(unknown_values)\n",
    "\n",
    "    # Resolver el problema de optimización\n",
    "    print(\"Starting optimization using minimize.\")\n",
    "    i = 0\n",
    "    resultado = minimize(objective_function, initial_guess, \n",
    "                         args=(blocks_relevant_numeric,),\n",
    "                         constraints=constraints,\n",
    "                         bounds=[(0, None)] * (unknown_values))\n",
    "    print(resultado)\n",
    "\n",
    "    # Preparación para remplazar nans\n",
    "    filled_blocks = blocks_relevant_numeric.copy()\n",
    "    # Reemplazar NaN con los valores óptimos encontrados\n",
    "    for i in unknown_vars.keys():\n",
    "        \n",
    "        # Find unknown value location\n",
    "        index = unknown_vars[i][0]\n",
    "        print(f\"index:{index}\")\n",
    "        \n",
    "        col = unknown_vars[i][1]\n",
    "        print(f\"col:{col}\")\n",
    "        \n",
    "        # Replace unknown value in location\n",
    "        filled_blocks.loc[index,col] = list(resultado.x)[i]\n",
    "        print(f\"Result: {list(resultado.x)[i]}\")\n",
    "\n",
    "    #print({col: val for col, val in zip(blocks_relevant.columns, resultado.x)})\n",
    "    #filled_blocks = blocks_relevant.fillna({col: val for col, val in zip(blocks_relevant.columns, resultado.x)})\n",
    "\n",
    "    # Unir las columnas llenas con el resto de las columnas\n",
    "    #filled_blocks_full = pd.concat([filled_blocks, blocks.drop(relevant_columns, axis=1)], axis=1)\n",
    "\n",
    "    return filled_blocks, resultado\n",
    "\n",
    "# Ejemplo de uso\n",
    "filled_blocks, resultado = fill_nans(blocks_values_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "27144fd5-7d99-46a2-a230-7e1050b42aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_0A2  P_0A2_F  P_0A2_M\n",
       "0    4.0      4.0      0.0\n",
       "1    NaN      5.0      2.0\n",
       "2    3.0      NaN      2.0\n",
       "3    4.0      3.0      NaN\n",
       "4    NaN      NaN      NaN"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks_values_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "05cd1e8f-b545-4b8c-aa4d-e814e4886443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_0A2  P_0A2_F  P_0A2_M\n",
       "0    4.0      4.0      0.0\n",
       "1    0.0      5.0      2.0\n",
       "2    3.0      0.0      2.0\n",
       "3    4.0      3.0      0.0\n",
       "4    0.0      0.0      0.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec28c4a-986a-4a55-b29c-1485c237b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb1636-dff5-4077-91d6-d9bdcbaccbfe",
   "metadata": {},
   "source": [
    "### Chat GPT paso 1: Resolver para un grupo de edad, P_0A2 = P_0A2_F + P_0A2_M [DONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f3da3eea-64b5-462c-8ee2-ab7291d325c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_censo_nan_values_v2(pop_ageb_gdf, pop_mza_gdf,extended_logs=False):\n",
    "    ##########################################################################################\n",
    "\t# STEP 1: CHECK FOR DIFFERENCES IN AVAILABLE AGEBs (PREVENTS CRASH)\n",
    "\n",
    "\t# --------------- 1.1 SET COLUMNS TO .UPPER() EXCEPT FOR GEOMETRY\n",
    "\t# (When the equations were written, we used UPPER names, easier to change it this way and then return output with .lower columns)\n",
    "    pop_ageb_gdf.columns = pop_ageb_gdf.columns.str.upper()\n",
    "    pop_ageb_gdf.rename(columns={'GEOMETRY':'geometry'},inplace=True)\n",
    "    \n",
    "    pop_mza_gdf.columns = pop_mza_gdf.columns.str.upper()\n",
    "    pop_mza_gdf.rename(columns={'GEOMETRY':'geometry'},inplace=True)\n",
    "\n",
    "\t# --------------- 1.2 CHECK FOR DIFFERENCES IN AGEBs\n",
    "\t# Look for AGEBs in both gdfs\n",
    "    agebs_in_ageb_gdf = list(pop_ageb_gdf['CVE_AGEB'].unique())\n",
    "    agebs_in_mza_gdf = list(pop_mza_gdf['CVE_AGEB'].unique())\n",
    "    \n",
    "    if (len(agebs_in_ageb_gdf) == 0) and (len(agebs_in_mza_gdf) == 0):\n",
    "        print(\"Error: Area of interest has no pop data.\")\n",
    "        intended_crash\n",
    "\n",
    "\t# Test for AGEBs present in mza_gdf but not in AGEB_gdf\n",
    "    missing_agebs = list(set(agebs_in_mza_gdf) - set(agebs_in_ageb_gdf))\n",
    "    if len(missing_agebs) > 0:\n",
    "        print(f'WARNING: AGEBs {missing_agebs} present in mza_gdf but missing from ageb_gdf.')\n",
    "        print(f'WARNING: Removing AGEBs {missing_agebs} from AGEB analysis.')\n",
    "    else:\n",
    "        print(\"No problem\")\n",
    "    \n",
    "\t##########################################################################################\n",
    "\t# STEP 2: CALCULATE NAN VALUES\n",
    "    print(\"STARTING NANs calculation.\")\n",
    "\n",
    "\t# STATISTICS - LOG DATA\n",
    "\t# Will create progress logs when progress reaches these percentages:\n",
    "    progress_logs = [10,20,30,40,50,60,70,80,90,100]\n",
    "\t# This df stores accumulative (All AGEBs) statistics for logs.\n",
    "    acc_statistics = pd.DataFrame()\n",
    "\n",
    "\t# --------------- NaNs CALCULATION 2.0) Start\n",
    "    i = 1\n",
    "    for ageb in agebs_in_mza_gdf: # Most of the code of this function iterates over each AGEB\n",
    "        if extended_logs:\n",
    "            print('--'*20)\n",
    "            print(f'Calculating NaNs for AGEB {ageb} ({i}/{len(agebs_in_mza_gdf)}.)')\n",
    "\t\t\n",
    "\t\t# STATISTICS - PROGRESS LOG DATA\n",
    "\t\t# Measures current progress, prints if passed a checkpoint of progress_logs list.\n",
    "        current_progress = (i / len(agebs_in_mza_gdf))*100\n",
    "        for checkpoint in progress_logs:\n",
    "            if current_progress >= checkpoint:\n",
    "                print(f'Calculating NaNs. {checkpoint}% done.')\n",
    "                progress_logs.remove(checkpoint)\n",
    "                break\n",
    "        \n",
    "\t\t# --------------- NaNs CALCULATION 2.1) FIND CURRENT AGEB BLOCK DATA\n",
    "        mza_ageb_gdf = pop_mza_gdf.loc[pop_mza_gdf['CVE_AGEB'] == ageb].copy()\n",
    "        \n",
    "\t\t# --------------- NaNs CALCULATION 2.2) KEEP OUT OF THE PROCESS ROWS WHICH HAVE 0 VALUES (ALL values are NaNs)\n",
    "\t\t# 2.2a) Set columns to be analysed\n",
    "        columns_of_interest = ['POBFEM','POBMAS',\n",
    "\t\t\t\t\t\t\t'P_0A2','P_0A2_F','P_0A2_M',\n",
    "\t\t\t\t\t\t\t'P_3A5','P_3A5_F','P_3A5_M',\n",
    "\t\t\t\t\t\t\t'P_6A11','P_6A11_F','P_6A11_M',\n",
    "\t\t\t\t\t\t\t'P_12A14','P_12A14_F','P_12A14_M',\n",
    "\t\t\t\t\t\t\t'P_15A17','P_15A17_F','P_15A17_M',\n",
    "\t\t\t\t\t\t\t'P_18A24','P_18A24_F','P_18A24_M',\n",
    "\t\t\t\t\t\t\t'P_60YMAS','P_60YMAS_F','P_60YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_3YMAS','P_3YMAS_F','P_3YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_12YMAS','P_12YMAS_F','P_12YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_15YMAS','P_15YMAS_F','P_15YMAS_M',\n",
    "\t\t\t\t\t\t\t'P_18YMAS','P_18YMAS_F','P_18YMAS_M',\n",
    "\t\t\t\t\t\t\t'REL_H_M','POB0_14','POB15_64','POB65_MAS']\n",
    "        blocks = mza_ageb_gdf[['CVEGEO','POBTOT'] + columns_of_interest].copy()\n",
    "\t\t\n",
    "\t\t# 2.2b) Set found values to 0\n",
    "        blocks['found_values'] = 0\n",
    "\t\t\n",
    "\t\t# 2.2c) Find rows with nan values and sum of nan values\n",
    "        for col in columns_of_interest:\n",
    "\t\t\t# Turn to numeric\n",
    "            blocks[col] = pd.to_numeric(blocks[col])\n",
    "\t\t\t# Set checker column to 'exist' (1)\n",
    "            blocks[f'check_{col}'] = 1\n",
    "\t\t\t# If it doesn't exist, set that row's check to (0)\n",
    "            idx = blocks[col].isna()\n",
    "            blocks.loc[idx, f'check_{col}'] = 0\n",
    "\t\t\t# Sum total row nan values\n",
    "            blocks['found_values'] = blocks['found_values'] + blocks[f'check_{col}']\n",
    "\t\t\t# Drop checker column\n",
    "            blocks.drop(columns=[f'check_{col}'],inplace=True)\n",
    "\t\t\n",
    "\t\t# 2.2d) Loc rows with values in columns_of_interest (Can calculate NaNs)\n",
    "        blocks_values = blocks.loc[blocks['found_values'] > 0].copy()\n",
    "        blocks_values.drop(columns=['found_values'],inplace=True)\n",
    "\t\t\n",
    "\t\t# 2.2e) Save rows with 0 values for later. (Can't calculate NaNs, must distribute values).\n",
    "        blocks_nans = blocks.loc[blocks['found_values'] == 0].copy()\n",
    "        blocks_nans.drop(columns=['found_values'],inplace=True)\n",
    "        \n",
    "        del blocks\n",
    "\t\t\n",
    "\t\t# --------------- NaNs CALCULATION 3) CALCULATE NaN values in blocks\n",
    "        if extended_logs:\n",
    "            print(f'Calculating NaNs using block data for AGEB {ageb}.')\n",
    "        \n",
    "        # 2.3a) Count current (original) nan values\n",
    "        original_nan_values = int(blocks_values.isna().sum().sum())\n",
    "\n",
    "        ##############################################################################################################################################\n",
    "        #--------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        #----------------------------------------------------Finding a way to calculate all nan values ----------------------------------------------#\n",
    "        #--------------------------------------------------------------- USING CHAT GPT -------------------------------------------------------------#\n",
    "        #-------------------------------------------------------------- WORK IN PROGRESS ------------------------------------------------------------#\n",
    "        #--------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        ##############################################################################################################################################\n",
    "\n",
    "        # Valores conocidos (Totales del AGEB)\n",
    "        ageb_ageb_gdf = pop_ageb_gdf.loc[pop_ageb_gdf['CVE_AGEB'] == ageb].copy()\n",
    "        \n",
    "        P_0A2_tot = ageb_ageb_gdf['P_0A2'].unique()[0]  # Total de la población de 0 a 2 años\n",
    "        P_0A2_F_tot = ageb_ageb_gdf['P_0A2_F'].unique()[0]  # Total de la población femenina de 0 a 2 años\n",
    "        P_0A2_M_tot = ageb_ageb_gdf['P_0A2_M'].unique()[0]  # Total de la población masculina de 0 a 2 años\n",
    "        \n",
    "        chat_gpt_first_sol = \"\"\"\n",
    "        def equations(vars, *args):\n",
    "            P_0A2, P_0A2_F, P_0A2_M = vars\n",
    "            P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot = args\n",
    "            \n",
    "            # Definir las ecuaciones basadas en las relaciones dadas\n",
    "            eq1 = P_0A2 - (P_0A2_F + P_0A2_M)\n",
    "            eq2 = P_0A2 - P_0A2_tot\n",
    "            eq3 = P_0A2_F - P_0A2_F_tot\n",
    "            eq4 = P_0A2_M - P_0A2_M_tot\n",
    "            \n",
    "            return [eq1, eq2, eq3]\n",
    "        \n",
    "        # Estimaciones iniciales para P_0A2, P_0A2_F, P_0A2_M (pueden ser cualquier valor)\n",
    "        initial_guess = [250, 125, 125]\n",
    "        \n",
    "        # Resolver las ecuaciones\n",
    "        result = fsolve(equations, initial_guess, args=(P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot))\n",
    "        \n",
    "        # Asignar los valores encontrados de nuevo al DataFrame\n",
    "        blocks_values.loc[:, 'P_0A2'] = result[0]\n",
    "        blocks_values.loc[:, 'P_0A2_F'] = result[1]\n",
    "        blocks_values.loc[:, 'P_0A2_M'] = result[2]\n",
    "        \"\"\"\n",
    "        \n",
    "        chat_gpt_second_sol = \"\"\"\n",
    "        def equations(vars, *args):\n",
    "            P_0A2, P_0A2_F, P_0A2_M = vars\n",
    "            P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot = args\n",
    "            \n",
    "            # Definir las ecuaciones basadas en las relaciones dadas\n",
    "            eq1 = P_0A2 - (P_0A2_F + P_0A2_M)\n",
    "            eq2 = P_0A2 - P_0A2_tot\n",
    "            eq3 = P_0A2_F - P_0A2_F_tot\n",
    "            eq4 = P_0A2_M - P_0A2_M_tot\n",
    "                    \n",
    "            return [eq1, eq2, eq3]\n",
    "        \n",
    "        def solve_equations(row):\n",
    "            # Solo resolver ecuaciones si hay valores desconocidos (NaN)\n",
    "            if np.isnan(row['P_0A2']) or np.isnan(row['P_0A2_F']) or np.isnan(row['P_0A2_M']):\n",
    "                # Estimaciones iniciales para P_0A2, P_0A2_F, P_0A2_M (pueden ser cualquier valor)\n",
    "                initial_guess = [250, 125, 125]\n",
    "        \n",
    "                # Resolver las ecuaciones\n",
    "                result = fsolve(equations, initial_guess, args=(P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot))\n",
    "                \n",
    "                # Asignar los valores encontrados solo a las filas con NaN\n",
    "                row['P_0A2'] = result[0] if np.isnan(row['P_0A2']) else row['P_0A2']\n",
    "                row['P_0A2_F'] = result[1] if np.isnan(row['P_0A2_F']) else row['P_0A2_F']\n",
    "                row['P_0A2_M'] = result[2] if np.isnan(row['P_0A2_M']) else row['P_0A2_M']\n",
    "            \n",
    "            return row\n",
    "        \n",
    "        # Aplicar la función solve_equations a cada fila del DataFrame\n",
    "        blocks_values = blocks_values.apply(solve_equations, axis=1)\n",
    "\n",
    "        return blocks_values\"\"\"\n",
    "         \n",
    "        chat_gpt_third_solution = \"\"\"\n",
    "        def equations(vars, *args):\n",
    "            P_0A2, P_0A2_F, P_0A2_M = vars\n",
    "            P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot = args\n",
    "            \n",
    "            # Definir las ecuaciones basadas en las relaciones dadas\n",
    "            eq1 = P_0A2 - (P_0A2_F + P_0A2_M)\n",
    "            eq2 = P_0A2 - P_0A2_tot\n",
    "            eq3 = P_0A2_F - P_0A2_F_tot\n",
    "            eq4 = P_0A2_M - P_0A2_M_tot\n",
    "                        \n",
    "            return [eq1, eq2, eq3]\n",
    "        \n",
    "        def solve_equations(row, P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot):\n",
    "            # Solo resolver ecuaciones si hay valores desconocidos (NaN)\n",
    "            if np.isnan(row['P_0A2']) or np.isnan(row['P_0A2_F']) or np.isnan(row['P_0A2_M']):\n",
    "                # Estimaciones iniciales para P_0A2, P_0A2_F, P_0A2_M (pueden ser cualquier valor)\n",
    "                initial_guess = [250, 125, 125]\n",
    "        \n",
    "                # Resolver las ecuaciones\n",
    "                result = fsolve(equations, initial_guess, args=(P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot))\n",
    "                \n",
    "                # Asignar los valores encontrados solo a las filas con NaN\n",
    "                row['P_0A2'] = result[0] if np.isnan(row['P_0A2']) else row['P_0A2']\n",
    "                row['P_0A2_F'] = result[1] if np.isnan(row['P_0A2_F']) else row['P_0A2_F']\n",
    "                row['P_0A2_M'] = result[2] if np.isnan(row['P_0A2_M']) else row['P_0A2_M']\n",
    "            \n",
    "            return row\n",
    "        \n",
    "        # Aplicar la función solve_equations a cada fila del DataFrame\n",
    "        blocks_values = blocks_values.apply(solve_equations, axis=1, args=(P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot), )\n",
    "\n",
    "        return blocks_values\"\"\"\n",
    "        \n",
    "        chat_gpt_fourth_solution = \"\"\"\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        def fill_nans(blocks):\n",
    "            # Seleccionar solo las columnas relevantes\n",
    "            relevant_columns = ['P_0A2', 'P_0A2_F', 'P_0A2_M']\n",
    "            blocks_relevant = blocks[relevant_columns]\n",
    "        \n",
    "            # Convertir las columnas relevantes a un tipo de datos numéricos\n",
    "            blocks_relevant_numeric = blocks_relevant.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "            # Definir la función objetivo y las restricciones\n",
    "            def objective_function(x, blocks_relevant_numeric):\n",
    "                return np.isnan(blocks_relevant_numeric.values).sum()\n",
    "        \n",
    "            def constraint1(x):\n",
    "                return x[0] - (x[1] + x[2])\n",
    "        \n",
    "            def constraint2(x):\n",
    "                return x[0] - 71\n",
    "        \n",
    "            def constraint3(x):\n",
    "                return x[1] - 37\n",
    "        \n",
    "            def constraint4(x):\n",
    "                return x[2] - 34\n",
    "        \n",
    "            # Resolver el problema de optimización\n",
    "            initial_guess = np.zeros(3)\n",
    "            resultado = minimize(objective_function, initial_guess, args=(blocks_relevant_numeric,),\n",
    "                                 constraints=[{'type': 'eq', 'fun': constraint1},\n",
    "                                              {'type': 'eq', 'fun': constraint2},\n",
    "                                              {'type': 'eq', 'fun': constraint3},\n",
    "                                              {'type': 'eq', 'fun': constraint4}],\n",
    "                                 bounds=[(0, None), (0, None), (0, None)])\n",
    "            \n",
    "            # Reemplazar NaN con los valores óptimos encontrados\n",
    "            filled_blocks = blocks_relevant.fillna({col: val for col, val in zip(blocks_relevant.columns, resultado.x)})\n",
    "            \n",
    "            # Unir las columnas llenas con el resto de las columnas\n",
    "            filled_blocks_full = pd.concat([filled_blocks, blocks.drop(relevant_columns, axis=1)], axis=1)\n",
    "            \n",
    "            return filled_blocks_full\n",
    "        \n",
    "        # Ejemplo de uso\n",
    "        blocks_values_filled = fill_nans(blocks_values)\n",
    "\n",
    "        return blocks_values_filled\"\"\"\n",
    "\n",
    "        chat_gpt_fifth_solution = \"\"\"\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        def fill_nans(blocks):\n",
    "            # Seleccionar solo las columnas relevantes\n",
    "            relevant_columns = ['P_0A2', 'P_0A2_F', 'P_0A2_M']\n",
    "            blocks_relevant = blocks[relevant_columns]\n",
    "\n",
    "            # Convertir las columnas relevantes a un tipo de datos numéricos\n",
    "            blocks_relevant_numeric = blocks_relevant.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Encontrar los valores totales por columna conocidos (por AGEB)\n",
    "            total_values = [ageb_ageb_gdf[relevant_columns[0]].unique()[0],\n",
    "                            ageb_ageb_gdf[relevant_columns[1]].unique()[0],\n",
    "                            ageb_ageb_gdf[relevant_columns[2]].unique()[0]]\n",
    "        \n",
    "            # Definir la función objetivo (Lo que queremos minimizar con la función minimize): la cantidad de NaNs.\n",
    "            def objective_function(x, blocks_relevant_numeric):\n",
    "                return np.isnan(blocks_relevant_numeric.values).sum()\n",
    "\n",
    "            # Crear los constraints (Requisitos a cumplir, se pasan a manera de lista de diccionarios)\n",
    "            def create_constraints(total_values):\n",
    "                constraints = []\n",
    "                \n",
    "                # Restricción para P_0A2 = P_0A2_F + P_0A2_M por fila\n",
    "                def row_constraint(x):\n",
    "                    return x[0] - (x[1] + x[2])\n",
    "                constraints.append({'type': 'eq', 'fun': row_constraint})\n",
    "                # En el diccionario de restricciones, 'type':'eq' significa que la restricción es de tipo igualdad. \n",
    "                # Esto indica que queremos que una función de igualdad (definida en 'fun') sea igual a cero. \n",
    "                # La función constraint contiene la definición de la restricción. En este caso, cada restricción asegura que \n",
    "                # la suma de los valores en una columna específica sea igual al valor total dado.\n",
    "        \n",
    "                # Restricciones para verificar que la suma total de cada columna sea igual al valor esperado\n",
    "                # Restricción para P_0A2\n",
    "                def constraint_total_P_0A2(x):\n",
    "                    #Restricción: La suma de los valores comprendidos del primero al primer tercio del array (Columnas 1 de 3) - el valor total conocido[0] debe ser igual a 0.\n",
    "                    return np.nansum(x[:len(x)//3]) - total_values[0] \n",
    "                constraints.append({'type': 'eq', 'fun': constraint_total_P_0A2})\n",
    "            \n",
    "                # Restricción para P_0A2_F\n",
    "                def constraint_total_P_0A2_F(x):\n",
    "                    #Restricción: La suma de los valores comprendidos del primer tercio del array al segundo tercio del array (Columna 2 de 3) - el valor total conocido[1] debe ser igual a 0.\n",
    "                    return np.nansum(x[len(x)//3:2*len(x)//3]) - total_values[1]\n",
    "                constraints.append({'type': 'eq', 'fun': constraint_total_P_0A2_F})\n",
    "            \n",
    "                # Restricción para P_0A2_M\n",
    "                def constraint_total_P_0A2_M(x):\n",
    "                    #Restricción: La suma de los valores comprendidos del segundo tercio del array al final del array (Columna 3 de 3) - el valor total conocido[2] debe ser igual a 0.\n",
    "                    return np.nansum(x[2*len(x)//3:]) - total_values[2]\n",
    "                constraints.append({'type': 'eq', 'fun': constraint_total_P_0A2_M})\n",
    "            \n",
    "                return constraints\n",
    "\n",
    "            # Definir las restricciones\n",
    "            constraints = create_constraints(total_values)\n",
    "        \n",
    "            # Initial guess - El número de elementos en initial_guess debe corresponder al \n",
    "            # número de variables de decisión en tu problema de optimización.  \n",
    "            initial_guess = np.zeros(len(relevant_columns))\n",
    "\n",
    "            # Función que regresa la solución actual (para logs)\n",
    "            def callback_function(xk):\n",
    "                print(\"Current solution:\", xk)\n",
    "\n",
    "            # Resolver el problema de optimización\n",
    "            resultado = minimize(objective_function, \n",
    "                                 initial_guess, \n",
    "                                 args=(blocks_relevant_numeric,),\n",
    "                                 constraints=constraints,\n",
    "                                # Los límites (bounds) especifican los límites inferiores y superiores permitidos \n",
    "                                # para las variables de optimización. En este caso, cada variable de optimización \n",
    "                                # se refiere a los valores que se están ajustando para minimizar la función objetivo. (Relevant columns)\n",
    "                                # El valor (0, None) indica que la variable puede ser cualquier valor mayor o igual a cero, \n",
    "                                # sin límite superior. En otras palabras, no hay límite superior para los valores de las variables.\n",
    "                                 bounds=[(0, None)] * len(relevant_columns),\n",
    "                                # El argumento Callback es para generar logs\n",
    "                                 callback=callback_function)\n",
    "\n",
    "            print(\"Result:\")\n",
    "            print(resultado)\n",
    "            \n",
    "            # Reemplazar NaN con los valores óptimos encontrados\n",
    "            filled_blocks = blocks_relevant.fillna({col: val for col, val in zip(blocks_relevant.columns, resultado.x)})\n",
    "            \n",
    "            # Unir las columnas llenas con el resto de las columnas\n",
    "            filled_blocks_full = pd.concat([filled_blocks, blocks.drop(relevant_columns, axis=1)], axis=1)\n",
    "            \n",
    "            return filled_blocks_full, resultado\n",
    "        \n",
    "        # Ejemplo de uso\n",
    "        filled_blocks_full, resultado = fill_nans(blocks_values)\n",
    "\n",
    "        return filled_blocks_full, resultado\"\"\" \n",
    "\n",
    "        # Hasta este punto he llegado, aún no funciona.\n",
    "        # El problema por ahora es que, ya que las funciones de los constraints de [https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html] deben ser callables,\n",
    "        # cada constraint debe de tener una función callable única (Para cada caso específico, por ejemplo en una fila falta P_0A2_F, es necesario tener una función que relacione esa variable faltante con el resto.)\n",
    "        # Es decir, imposible.\n",
    "        \n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        # Esta función recibe y opera en las rows de blocks.\n",
    "        def fill_nans(blocks):\n",
    "        \n",
    "            # Por ahora intentamos solo con el grupo de 0 a 2 años\n",
    "            # Seleccionar solo las columnas relevantes\n",
    "            relevant_columns = ['P_0A2', 'P_0A2_F', 'P_0A2_M']\n",
    "        \n",
    "            # Encontrar los valores totales por columna conocidos (por AGEB)\n",
    "            total_values = [ageb_ageb_gdf[relevant_columns[0]].unique()[0],\n",
    "                            ageb_ageb_gdf[relevant_columns[1]].unique()[0],\n",
    "                            ageb_ageb_gdf[relevant_columns[2]].unique()[0]]\n",
    "            \n",
    "            # Aislar la información de las columnas relevantes\n",
    "            blocks_relevant = blocks[relevant_columns]\n",
    "        \n",
    "            # Cantidad de valores desconocidos (Si dejo la cantidad completa, crashea. 3 es otra).\n",
    "            print(f\"Valores desconocidos: {np.isnan(blocks_relevant.values).sum()}\")\n",
    "            unknown_values = np.isnan(blocks_relevant.values).sum()\n",
    "            \n",
    "            # Convertir las columnas relevantes a un tipo de datos numéricos\n",
    "            blocks_relevant_numeric = blocks_relevant.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "            # Definir la función objetivo (Lo que queremos minimizar con la función minimize): la cantidad de NaNs.\n",
    "            def objective_function(x, blocks_relevant_numeric):\n",
    "                return np.isnan(blocks_relevant_numeric.values).sum()\n",
    "        \n",
    "            # Crear las restricciones (Requisitos a cumplir, se pasan a manera de lista de diccionarios)\n",
    "            def create_constraints(total_values,blocks_relevant_numeric):\n",
    "        \n",
    "                constraints = []\n",
    "        \n",
    "                # EXPLICACIÓN DE LAS CONSTRAINTS: Las constraints se agregan en la función minimize como lista de diccionarios..\n",
    "                # En cada diccionario de restricciones, 'type':'eq' significa que la restricción es de tipo igualdad. \n",
    "                # Esto indica que queremos que una función de igualdad (definida en 'fun') sea igual a cero.\n",
    "                # La función de igualdad que se debe colocar en 'fun' se crea en las siguientes definiciones. Lo que va después del return debe ser igual a cero.\n",
    "        \n",
    "                #----- RESTRICCIONES QUE SON POR FILA -----\n",
    "                # En este caso, la restricción debería asegurar que por fila (por .iterrows) P_0A2 sea igual a P_0A2_F + P_0A2_M.\n",
    "                # El número de variables encontradas (i) corresponderá al número de nans que hay en este caso.\n",
    "        \n",
    "                i = 0\n",
    "                # Lista de variables desconocidas encontradas (Necesario para las restricciones por columna)\n",
    "                P_0A2_unknown_vars = []\n",
    "                P_0A2_F_unknown_vars = []\n",
    "                P_0A2_M_unknown_vars = []\n",
    "        \n",
    "                unknown_vars = {} # i:(index,col)\n",
    "                \n",
    "                for index, row in blocks_relevant_numeric.iterrows():\n",
    "                    P_0A2_val = row['P_0A2']\n",
    "                    #print(P_0A2_val) #Verification log\n",
    "                    P_0A2_F_val = row['P_0A2_F']\n",
    "                    #print(P_0A2_F_val) #Verification log\n",
    "                    P_0A2_M_val = row['P_0A2_M']\n",
    "                    #print(P_0A2_M_val) #Verification log\n",
    "        \n",
    "                    # Orden de las variables\n",
    "                    # P_0A2_val - (P_0A2_F_val + P_0A2_M_val) --> x[0] - (x[1] + x[2])\n",
    "        \n",
    "                    ### ---------- ---------- CASOS EN DONDE SE AGREGAN 0 VARIABLES DESCONOCIDAS. ---------- ----------\n",
    "                    # Case 0: All values are known (skip)\n",
    "                    if not (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 0: Values complete\") #Verification log\n",
    "                        continue\n",
    "                        \n",
    "                    ### ---------- ---------- CASOS EN DONDE SE AGREGA 1 VARIABLE DESCONOCIDA. ---------- ----------\n",
    "                    # Case 1: Unknown P_0A2_val\n",
    "                    elif (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 1: Unknown P_0A2_val\") #Verification log\n",
    "                        # Se crea el constraint\n",
    "                        def case_1_row_constraint(x, P_0A2_F_val, P_0A2_M_val,i):\n",
    "                            # print(f\"Reading function x[{i}] - ({P_0A2_F_val} + {P_0A2_M_val}).\")#Verification log\n",
    "                            return x[i] - (P_0A2_F_val + P_0A2_M_val)\n",
    "                        constraints.append({'type': 'eq', \n",
    "                                            'fun': case_1_row_constraint, \n",
    "                                            'args': (P_0A2_F_val, P_0A2_M_val,i)})\n",
    "                        # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                        P_0A2_unknown_vars.append(i)\n",
    "                        unknown_vars[i] = (index,'P_0A2')\n",
    "                        print(f\"appended {i}\") #Verification log\n",
    "                        \n",
    "                        i += 1\n",
    "        \n",
    "                    # Case 2: Unknown P_0A2_F_val\n",
    "                    elif not (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 2: Unknown P_0A2_F_val\") #Verification log\n",
    "                        # Se crea el constraint\n",
    "                        def case_2_row_constraint(x, P_0A2_val, P_0A2_M_val,i):\n",
    "                            #print(f\"Reading function {P_0A2_val} - (x[{i}] + {P_0A2_M_val}).\") #Verification log\n",
    "                            return P_0A2_val - (x[i] + P_0A2_M_val)\n",
    "                        constraints.append({'type': 'eq', \n",
    "                                            'fun': case_2_row_constraint, \n",
    "                                            'args': (P_0A2_val, P_0A2_M_val,i)})\n",
    "                        # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                        P_0A2_F_unknown_vars.append(i)\n",
    "                        unknown_vars[i] = (index,'P_0A2_F')\n",
    "                        print(f\"appended {i}\") #Verification log\n",
    "                        \n",
    "                        i += 1\n",
    "        \n",
    "                    # Case 3: Unknown P_0A2_M_val\n",
    "                    elif not (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 3: Unknown P_0A2_M_val\") #Verification log\n",
    "                        # Se crea el constraint\n",
    "                        def case_3_row_constraint(x, P_0A2_val, P_0A2_F_val,i):\n",
    "                            #print(f\"Reading function {P_0A2_val} - ({P_0A2_F_val} + x[{i}]).\") #Verification log\n",
    "                            return P_0A2_val - (P_0A2_F_val + x[i])\n",
    "                        constraints.append({'type': 'eq', \n",
    "                                            'fun': case_3_row_constraint, \n",
    "                                            'args': (P_0A2_val, P_0A2_F_val,i)})\n",
    "                        # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                        unknown_vars[i] = (index,'P_0A2_M')\n",
    "                        P_0A2_M_unknown_vars.append(i)\n",
    "                        print(f\"appended {i}\") #Verification log\n",
    "                        \n",
    "                        i += 1\n",
    "                        \n",
    "                    ### ---------- ---------- CASOS EN DONDE SE AGREGAN 2 VARIABLES DESCONOCIDAS. ---------- ----------\n",
    "                    # Case 4: Unknown P_0A2_F_val and P_0A2_M_val\n",
    "                    elif not (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 4: Unknown P_0A2_F_val and P_0A2_M_val\") #Verification log\n",
    "                        # Se crea el constraint\n",
    "                        def case_4_row_constraint(x, P_0A2_val,i):\n",
    "                            #print(f\"Reading function {P_0A2_val} - (x[{i}] + x[{i+1}]).\") #Verification log\n",
    "                            return P_0A2_val - (x[i] + x[i+1])\n",
    "                        constraints.append({'type': 'eq', \n",
    "                                            'fun': case_4_row_constraint, \n",
    "                                            'args': (P_0A2_val,i)})\n",
    "                        # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                        P_0A2_F_unknown_vars.append(i)\n",
    "                        unknown_vars[i] = (index,'P_0A2_F')\n",
    "                        print(f\"appended {i}\") #Verification log\n",
    "                        \n",
    "                        P_0A2_M_unknown_vars.append(i+1)\n",
    "                        unknown_vars[i+1] = (index,'P_0A2_M')\n",
    "                        print(f\"appended {i+1}\") #Verification log\n",
    "                        \n",
    "                        i += 2\n",
    "                        \n",
    "                    # Case 5: Unknown P_0A2_val and P_0A2_M_val\n",
    "                    elif (np.isnan(P_0A2_val)) and not (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 5: Unknown P_0A2_val and P_0A2_M_val\") #Verification log\n",
    "                        # Se crea el constraint\n",
    "                        def case_5_row_constraint(x, P_0A2_F_val,i):\n",
    "                            #print(f\"Reading function x[{i}] - ({P_0A2_F_val} + x[{i+1}]).\") #Verification log\n",
    "                            return x[i] - (P_0A2_F_val + x[i+1])\n",
    "                        constraints.append({'type': 'eq', \n",
    "                                            'fun': case_5_row_constraint, \n",
    "                                            'args': (P_0A2_F_val,i)})\n",
    "                        # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                        P_0A2_unknown_vars.append(i)\n",
    "                        unknown_vars[i] = (index,'P_0A2')\n",
    "                        print(f\"appended {i}\") #Verification log\n",
    "                        \n",
    "                        P_0A2_M_unknown_vars.append(i+1)\n",
    "                        unknown_vars[i+1] = (index,'P_0A2_M')\n",
    "                        print(f\"appended {i+1}\") #Verification log\n",
    "                        \n",
    "                        i += 2\n",
    "                        \n",
    "                    # Case 6: Unknown P_0A2_val and P_0A2_F_val\n",
    "                    elif (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and not (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 6: Unknown P_0A2_val and P_0A2_F_val\") #Verification log\n",
    "                        # Se crea el constraint\n",
    "                        def case_6_row_constraint(x, P_0A2_M_val,i):\n",
    "                            #print(f\"Reading function x[{i}] - (x[{i+1}] + {P_0A2_M_val}).\") #Verification log\n",
    "                            return x[i] - (x[i+1] + P_0A2_M_val)\n",
    "                        constraints.append({'type': 'eq', \n",
    "                                            'fun': case_6_row_constraint, \n",
    "                                            'args': (P_0A2_M_val,i)})\n",
    "                        # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                        P_0A2_unknown_vars.append(i)\n",
    "                        unknown_vars[i] = (index,'P_0A2')\n",
    "                        print(f\"appended {i}\") #Verification log\n",
    "                        \n",
    "                        P_0A2_F_unknown_vars.append(i+1)\n",
    "                        unknown_vars[i+1] = (index,'P_0A2_F')\n",
    "                        print(f\"appended {i+1}\") #Verification log\n",
    "                        \n",
    "                        i += 2\n",
    "                        \n",
    "                    ### ---------- ---------- CASOS EN DONDE SE AGREGAN 3 VARIABLES DESCONOCIDAS. ---------- ----------\n",
    "                    # Case 7: All unknown\n",
    "                    elif (np.isnan(P_0A2_val)) and (np.isnan(P_0A2_F_val)) and (np.isnan(P_0A2_M_val)):\n",
    "                        #print(\"Case 7: All unknown\") #Verification log\n",
    "                        # Se crea el constraint\n",
    "                        def case_7_row_constraint(x,i):\n",
    "                            #print(f\"Reading function x[{i}] - (x[{i+1}] +  x[{i+2}]).\") #Verification log\n",
    "                            return x[i] - (x[i+1] + x[i+2])\n",
    "                        constraints.append({'type': 'eq', \n",
    "                                            'fun': case_7_row_constraint,\n",
    "                                            'args': (i,)})\n",
    "                        # Se registra la posición de la variable en la columna faltante correspondiente y se incrementa i (next case)\n",
    "                        P_0A2_unknown_vars.append(i)\n",
    "                        unknown_vars[i] = (index,'P_0A2')\n",
    "                        print(f\"appended {i}\") #Verification log\n",
    "                        \n",
    "                        P_0A2_F_unknown_vars.append(i+1)\n",
    "                        unknown_vars[i+1] = (index,'P_0A2_F')\n",
    "                        print(f\"appended {i+1}\") #Verification log\n",
    "                        \n",
    "                        P_0A2_M_unknown_vars.append(i+2)\n",
    "                        unknown_vars[i+2] = (index,'P_0A2_M')\n",
    "                        print(f\"appended {i+2}\") #Verification log\n",
    "                        \n",
    "                        i += 3\n",
    "                    else:\n",
    "                        print(\"Error\")\n",
    "        \n",
    "                print(f\"Unknown variables found: {i}.\")\n",
    "        \n",
    "                #----- RESTRICCIONES QUE SON POR COLUMNA -----\n",
    "                # Restricción para P_0A2\n",
    "                def constraint_total_P_0A2(x,blocks_relevant_numeric,P_0A2_unknown_vars,total_values):\n",
    "                    #Restricción: La suma de los valores actuales en la columna + los valores encontrados - el valor total conocido[1] debe ser igual a 0.\n",
    "                    #print(f\"Reading function for col P_0A2.\") #Verification log\n",
    "                    return np.nansum(blocks_relevant_numeric['P_0A2']) + np.nansum(x[P_0A2_unknown_vars]) - total_values[0] \n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': constraint_total_P_0A2,\n",
    "                                    'args':(blocks_relevant_numeric,P_0A2_unknown_vars,total_values)})\n",
    "                \n",
    "                # Restricción para P_0A2_F\n",
    "                def constraint_total_P_0A2_F(x,blocks_relevant_numeric,P_0A2_F_unknown_vars,total_values):\n",
    "                    #Restricción: La suma de los valores actuales en la columna + los valores encontrados - el valor total conocido[2] debe ser igual a 0.\n",
    "                    #print(f\"Reading function for col P_0A2_F.\") #Verification log\n",
    "                    return np.nansum(blocks_relevant_numeric['P_0A2_F']) + np.nansum(x[P_0A2_F_unknown_vars]) - total_values[1]\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': constraint_total_P_0A2_F,\n",
    "                                    'args':(blocks_relevant_numeric,P_0A2_F_unknown_vars,total_values)})\n",
    "                \n",
    "                # Restricción para P_0A2_M\n",
    "                def constraint_total_P_0A2_M(x,blocks_relevant_numeric,P_0A2_M_unknown_vars,total_values):\n",
    "                    #Restricción: La suma de los valores actuales en la columna + los valores encontrados - el valor total conocido[3] debe ser igual a 0.\n",
    "                    #print(f\"Reading function for col P_0A2_M.\") #Verification log\n",
    "                    return np.nansum(blocks_relevant_numeric['P_0A2_M']) + np.nansum(x[P_0A2_M_unknown_vars]) - total_values[2]\n",
    "                constraints.append({'type': 'eq', \n",
    "                                    'fun': constraint_total_P_0A2_M,\n",
    "                                    'args':(blocks_relevant_numeric,P_0A2_M_unknown_vars,total_values)})\n",
    "                \n",
    "                return constraints, unknown_vars\n",
    "        \n",
    "            # Definir las restricciones (Correr lo anterior para generar la lista de diccionarios)\n",
    "            constraints, unknown_vars = create_constraints(total_values, blocks_relevant_numeric)\n",
    "            print(f\"Constraints: {len(constraints)}.\")\n",
    "        \n",
    "            # Initial guess - El número de elementos en initial_guess debe corresponder al número de variables de decisión en tu problema de optimización.\n",
    "            initial_guess = np.zeros(unknown_values)\n",
    "        \n",
    "            # Resolver el problema de optimización\n",
    "            print(\"Starting optimization using minimize.\")\n",
    "            i = 0\n",
    "            resultado = minimize(objective_function, initial_guess, \n",
    "                                 args=(blocks_relevant_numeric,),\n",
    "                                 constraints=constraints,\n",
    "                                 bounds=[(0, None)] * (unknown_values))\n",
    "            print(resultado)\n",
    "        \n",
    "            # Preparación para remplazar nans\n",
    "            filled_blocks = blocks_relevant_numeric.copy()\n",
    "            # Reemplazar NaN con los valores óptimos encontrados\n",
    "            for i in unknown_vars.keys():\n",
    "                \n",
    "                # Find unknown value location\n",
    "                index = unknown_vars[i][0]\n",
    "                #print(f\"index:{index}\") #Verification log\n",
    "                \n",
    "                col = unknown_vars[i][1]\n",
    "                #print(f\"col:{col}\") #Verification log\n",
    "                \n",
    "                # Replace unknown value in location\n",
    "                filled_blocks.loc[index,col] = list(resultado.x)[i]\n",
    "                #print(f\"Result: {list(resultado.x)[i]}\") #Verification log\n",
    "        \n",
    "            # Unir las columnas llenas con el resto de las columnas\n",
    "            filled_blocks_full = pd.concat([filled_blocks, blocks.drop(relevant_columns, axis=1)], axis=1)\n",
    "        \n",
    "            return filled_blocks_full, resultado\n",
    "\n",
    "        # Ejemplo de uso\n",
    "        filled_blocks_full, resultado = fill_nans(blocks_values)\n",
    "        \n",
    "        return filled_blocks_full, resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4c7aef64-d648-49e0-8b0f-4ea0f37a4d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No problem\n",
      "STARTING NANs calculation.\n",
      "----------------------------------------\n",
      "Calculating NaNs for AGEB 0515 (1/1.)\n",
      "Calculating NaNs. 10% done.\n",
      "Calculating NaNs using block data for AGEB 0515.\n",
      "Valores desconocidos: 39\n",
      "appended 0\n",
      "appended 1\n",
      "appended 2\n",
      "appended 3\n",
      "appended 4\n",
      "appended 5\n",
      "appended 6\n",
      "appended 7\n",
      "appended 8\n",
      "appended 9\n",
      "appended 10\n",
      "appended 11\n",
      "appended 12\n",
      "appended 13\n",
      "appended 14\n",
      "appended 15\n",
      "appended 16\n",
      "appended 17\n",
      "appended 18\n",
      "appended 19\n",
      "appended 20\n",
      "appended 21\n",
      "appended 22\n",
      "appended 23\n",
      "appended 24\n",
      "appended 25\n",
      "appended 26\n",
      "appended 27\n",
      "appended 28\n",
      "appended 29\n",
      "appended 30\n",
      "appended 31\n",
      "appended 32\n",
      "appended 33\n",
      "appended 34\n",
      "appended 35\n",
      "appended 36\n",
      "appended 37\n",
      "appended 38\n",
      "Unknown variables found: 39.\n",
      "Constraints: 23.\n",
      "Starting optimization using minimize.\n",
      " message: Inequality constraints incompatible\n",
      " success: False\n",
      "  status: 4\n",
      "     fun: 39\n",
      "       x: [ 0.000e+00  0.000e+00 ...  0.000e+00  0.000e+00]\n",
      "     nit: 1\n",
      "     jac: [ 0.000e+00  0.000e+00 ...  0.000e+00  0.000e+00]\n",
      "    nfev: 40\n",
      "    njev: 1\n"
     ]
    }
   ],
   "source": [
    "blocks_values_2, resultado = calculate_censo_nan_values_v2(pop_ageb_gdf_chosen, pop_mza_gdf_chosen, extended_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04f46739-b8c1-4262-8ecd-87c86211309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.0\n",
      "21.0\n",
      "17.0\n"
     ]
    }
   ],
   "source": [
    "test = original_data.copy()\n",
    "test = test.apply(pd.to_numeric, errors='coerce')\n",
    "print(test.P_0A2.sum())\n",
    "print(test.P_0A2_F.sum())\n",
    "print(test.P_0A2_M.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8eeef799-ebd9-4830-b742-eff1097d831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVEGEO</th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "      <th>P_0A2_x</th>\n",
       "      <th>P_0A2_F_x</th>\n",
       "      <th>P_0A2_M_x</th>\n",
       "      <th>P_0A2_y</th>\n",
       "      <th>P_0A2_F_y</th>\n",
       "      <th>P_0A2_M_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0100100010515001</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0100100010515002</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0100100010515003</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0100100010515004</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0100100010515005</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0100100010515006</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0100100010515007</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0100100010515008</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0100100010515009</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0100100010515011</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0100100010515012</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0100100010515013</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0100100010515014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0100100010515015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0100100010515016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0100100010515017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0100100010515018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0100100010515019</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0100100010515020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0100100010515021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0100100010515022</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0100100010515023</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0100100010515024</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0100100010515025</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0100100010515026</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0100100010515027</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0100100010515030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0100100010515031</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0100100010515032</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0100100010515034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0100100010515035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0100100010515036</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0100100010515037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0100100010515039</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0100100010515040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0100100010515041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0100100010515042</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0100100010515043</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0100100010515044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0100100010515048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0100100010515049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0100100010515050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0100100010515051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0100100010515028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CVEGEO P_0A2 P_0A2_F P_0A2_M  P_0A2_x  P_0A2_F_x  P_0A2_M_x  \\\n",
       "0   0100100010515001     6       4    None      6.0        4.0        2.0   \n",
       "1   0100100010515002     4    None       3      4.0        1.0        3.0   \n",
       "2   0100100010515003     4       4       0      4.0        4.0        0.0   \n",
       "3   0100100010515004  None       0    None      1.0        0.0        1.0   \n",
       "4   0100100010515005  None    None       0      1.0        1.0        0.0   \n",
       "5   0100100010515006     4    None       3      4.0        1.0        3.0   \n",
       "6   0100100010515007     3    None    None      3.0        2.0        1.0   \n",
       "7   0100100010515008  None    None       0      1.0        1.0        0.0   \n",
       "8   0100100010515009     8       3       5      8.0        3.0        5.0   \n",
       "9   0100100010515011     3    None    None      3.0        1.0        2.0   \n",
       "10  0100100010515012  None    None    None      2.0        1.0        1.0   \n",
       "11  0100100010515013  None    None    None      2.0        1.0        1.0   \n",
       "12  0100100010515014     0       0       0      0.0        0.0        0.0   \n",
       "13  0100100010515015     0       0       0      0.0        0.0        0.0   \n",
       "14  0100100010515016     4       4       0      4.0        4.0        0.0   \n",
       "15  0100100010515017     3       0       3      3.0        0.0        3.0   \n",
       "16  0100100010515018     0       0       0      0.0        0.0        0.0   \n",
       "17  0100100010515019  None    None    None      2.0        1.0        1.0   \n",
       "18  0100100010515020     0       0       0      0.0        0.0        0.0   \n",
       "19  0100100010515021     0       0       0      0.0        0.0        0.0   \n",
       "20  0100100010515022     3       3       0      3.0        3.0        0.0   \n",
       "21  0100100010515023  None       0    None      1.0        0.0        1.0   \n",
       "22  0100100010515024     5    None       3      5.0        2.0        3.0   \n",
       "23  0100100010515025     3    None    None      3.0        1.0        2.0   \n",
       "24  0100100010515026  None       0    None      1.0        0.0        1.0   \n",
       "25  0100100010515027  None       0    None      1.0        0.0        1.0   \n",
       "26  0100100010515030     0       0       0      0.0        0.0        0.0   \n",
       "27  0100100010515031     3       3       0      3.0        3.0        0.0   \n",
       "28  0100100010515032  None    None       0      1.0        1.0        0.0   \n",
       "29  0100100010515034     0       0       0      0.0        0.0        0.0   \n",
       "30  0100100010515035     0       0       0      0.0        0.0        0.0   \n",
       "31  0100100010515036     3    None    None      3.0        1.0        2.0   \n",
       "32  0100100010515037     0       0       0      0.0        0.0        0.0   \n",
       "33  0100100010515039  None       0    None      1.0        0.0        1.0   \n",
       "34  0100100010515040     0       0       0      0.0        0.0        0.0   \n",
       "35  0100100010515041     0       0       0      0.0        0.0        0.0   \n",
       "36  0100100010515042  None    None       0      1.0        1.0        0.0   \n",
       "37  0100100010515043     0       0       0      0.0        0.0        0.0   \n",
       "38  0100100010515044     0       0       0      0.0        0.0        0.0   \n",
       "39  0100100010515048     0       0       0      0.0        0.0        0.0   \n",
       "40  0100100010515049     0       0       0      0.0        0.0        0.0   \n",
       "41  0100100010515050     0       0       0      0.0        0.0        0.0   \n",
       "42  0100100010515051     0       0       0      0.0        0.0        0.0   \n",
       "43  0100100010515028     0       0       0      0.0        0.0        0.0   \n",
       "\n",
       "    P_0A2_y  P_0A2_F_y  P_0A2_M_y  \n",
       "0       6.0        4.0        0.0  \n",
       "1       4.0        0.0        3.0  \n",
       "2       4.0        4.0        0.0  \n",
       "3       0.0        0.0        0.0  \n",
       "4       0.0        0.0        0.0  \n",
       "5       4.0        0.0        3.0  \n",
       "6       3.0        0.0        0.0  \n",
       "7       0.0        0.0        0.0  \n",
       "8       8.0        3.0        5.0  \n",
       "9       3.0        0.0        0.0  \n",
       "10      0.0        0.0        0.0  \n",
       "11      0.0        0.0        0.0  \n",
       "12      0.0        0.0        0.0  \n",
       "13      0.0        0.0        0.0  \n",
       "14      4.0        4.0        0.0  \n",
       "15      3.0        0.0        3.0  \n",
       "16      0.0        0.0        0.0  \n",
       "17      0.0        0.0        0.0  \n",
       "18      0.0        0.0        0.0  \n",
       "19      0.0        0.0        0.0  \n",
       "20      3.0        3.0        0.0  \n",
       "21      0.0        0.0        0.0  \n",
       "22      5.0        0.0        3.0  \n",
       "23      3.0        0.0        0.0  \n",
       "24      0.0        0.0        0.0  \n",
       "25      0.0        0.0        0.0  \n",
       "26      0.0        0.0        0.0  \n",
       "27      3.0        3.0        0.0  \n",
       "28      0.0        0.0        0.0  \n",
       "29      0.0        0.0        0.0  \n",
       "30      0.0        0.0        0.0  \n",
       "31      3.0        0.0        0.0  \n",
       "32      0.0        0.0        0.0  \n",
       "33      0.0        0.0        0.0  \n",
       "34      0.0        0.0        0.0  \n",
       "35      0.0        0.0        0.0  \n",
       "36      0.0        0.0        0.0  \n",
       "37      0.0        0.0        0.0  \n",
       "38      0.0        0.0        0.0  \n",
       "39      0.0        0.0        0.0  \n",
       "40      0.0        0.0        0.0  \n",
       "41      0.0        0.0        0.0  \n",
       "42      0.0        0.0        0.0  \n",
       "43      0.0        0.0        0.0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare1 = pd.merge(blocks_values_org[['CVEGEO','P_0A2','P_0A2_F','P_0A2_M']],blocks_values_2[['CVEGEO','P_0A2','P_0A2_F','P_0A2_M']],on='CVEGEO')\n",
    "compare = pd.merge(original_data[['CVEGEO','P_0A2','P_0A2_F','P_0A2_M']],compare1,on='CVEGEO')\n",
    "\n",
    "# Diffs (Must be 0)\n",
    "#compare['calcnans_diff_P_0A2'] = compare['P_0A2_x'] - compare['P_0A2_y']\n",
    "#compare['calcnans_diff_P_0A2_F'] = compare['P_0A2_F_x'] - compare['P_0A2_F_y']\n",
    "#compare['calcnans_diff_P_0A2_M'] = compare['P_0A2_M_x'] - compare['P_0A2_M_y']\n",
    "\n",
    "# '_x' data is goal (current calculate_censo_nan_values_v1) '_y' data is current status.\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e135318d-ddb0-4abc-a152-58125140d9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_0A2\n",
      "71.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'blocks_calc_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP_0A2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(blocks_calc\u001b[38;5;241m.\u001b[39mP_0A2\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mblocks_calc_2\u001b[49m\u001b[38;5;241m.\u001b[39mP_0A2\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP_0A2_F\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(blocks_calc\u001b[38;5;241m.\u001b[39mP_0A2_F\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blocks_calc_2' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"P_0A2\")\n",
    "print(blocks_calc.P_0A2.sum())\n",
    "print(blocks_calc_2.P_0A2.sum())\n",
    "print(\"P_0A2_F\")\n",
    "print(blocks_calc.P_0A2_F.sum())\n",
    "print(blocks_calc_2.P_0A2_F.sum())\n",
    "print(\"P_0A2_M\")\n",
    "print(blocks_calc.P_0A2_M.sum())\n",
    "print(blocks_calc_2.P_0A2_M.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "127cbc98-3c36-4fa9-b10b-eb7cf8969a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_0A2</th>\n",
       "      <th>P_0A2_F</th>\n",
       "      <th>P_0A2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>71.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     P_0A2  P_0A2_F  P_0A2_M\n",
       "191   71.0     37.0     34.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_ageb_gdf_chosen[['P_0A2','P_0A2_F','P_0A2_M']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51052c05-661a-4771-9415-e14934e93e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equations(vars, *args):\n",
    "    P_0A2, P_0A2_F, P_0A2_M = vars\n",
    "    P_0A2_tot, P_0A2_F_tot, P_0A2_M_tot = args\n",
    "    \n",
    "    # Definir las ecuaciones basadas en las relaciones dadas\n",
    "    eq1 = P_0A2 - (P_0A2_F + P_0A2_M)\n",
    "    eq2 = P0_2 - P_0A2_tot\n",
    "    eq3 = P_0A2_F - P_0A2_F_tot\n",
    "    eq4 = P_0A2_M - P_0A2_M_tot\n",
    "    \n",
    "    return [eq1, eq2, eq3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e304c2b-73a5-403d-8e4d-2d91493de448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS-10.0",
   "language": "python",
   "name": "gds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
