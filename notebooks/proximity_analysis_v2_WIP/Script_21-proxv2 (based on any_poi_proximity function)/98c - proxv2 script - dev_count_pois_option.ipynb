{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67abf553-9ca7-4d41-a815-308d0e65e3e8",
   "metadata": {},
   "source": [
    "# 98c - Script 21 - dev count pois function at requested time proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458cecb7-157f-4b0d-8983-e62e874660e2",
   "metadata": {},
   "source": [
    "This notebook helped modify Script 21, function aup.pois_time, function aup.calculate_distance_nodes and function aup.get_distances in order to add the argument count_pois.The argument adds to output (optional, if requested) the number of amenities at a given time from each node (average in hexs).\n",
    "\n",
    "Example:\n",
    "count_pois = (True,15) will return how many of each amenity is within 15 minutes in the form of eje_15min and amenity_15min columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c3e5e-e5dc-4ab6-8617-dd28b7dc5eca",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ace2cd4-cfc1-4cb2-97d2-0d39eca03b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/aup/data.py:25: UserWarning: The `utils.config` function is deprecated and will be removed in a future release. Instead, use the `settings` module directly to configure a global setting's value. For example, `ox.settings.log_console=True`.\n",
      "  ox.config(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    import aup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5547906f-9bfa-4814-bc11-0e9e6098f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a311f-da69-42ae-9ffc-276b9ae1ab47",
   "metadata": {},
   "source": [
    "## Required script 21 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ee368c1-fab8-4f81-a210-5de1b9fc783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Aguascalientes'\n",
    "version = 2\n",
    "\n",
    "if version == 1: #Prox analysis 2020 version\n",
    "    cultural_dicc = {'denue_cines':[512130],\n",
    "                     'denue_museos':[712111, 712112]}\n",
    "    cultural_weight =  'min' # Will choose min time to source because measuring access to nearest source, doesn't matter which.\n",
    "\n",
    "elif version == 2: #Prox analysis 2024 version\n",
    "    cultural_dicc = {'denue_cines':[512130],\n",
    "                    'denue_museos':[712111, 712112],\n",
    "                    'denue_bibliotecas':[519121,519122],\n",
    "                    'denue_centrocultural':[711312]}\n",
    "    cultural_weight =  'two-method'\n",
    "else:\n",
    "    aup.log(\"--- Error in specified proximity analysis version.\")\n",
    "    aup.log(\"--- Must pass integers 1 or 2.\")\n",
    "    intended_crash\n",
    "\n",
    "# ---------------------------- BASE DATA REQUIRED ----------------------------\n",
    "# Area of interest (city)\n",
    "metro_schema = 'metropolis'\n",
    "metro_table = 'metro_gdf_2015' #'metro_gdf_2015' or 'metro_gdf_2020'\n",
    "# Network data (nodes and edges table for distance analysis,\n",
    "# also used to generate the network G with which the nearest OSMID is assigned to each poi)\n",
    "network_schema = 'osmnx'\n",
    "nodes_table = 'nodes' #'nodes' or 'nodes_23_point'\n",
    "edges_table = 'edges_speed' ################################# PENDIENTE\n",
    "# Points of interest - DENUE\n",
    "denue_schema = 'denue'\n",
    "denue_table = 'denue_2020' #'denue_2020' or 'denue_23_point'\n",
    "# Points of interest - CLUES\n",
    "clues_schema = 'denue'\n",
    "clues_table = 'clues' #'clues' or 'clues_23_point'\n",
    "# Points of interest - SIP\n",
    "sip_schema = 'denue'\n",
    "sip_table = 'sip_2020' #'sip_2020' or 'sip_23_point'\n",
    "# Hexgrid\n",
    "hex_schema = 'hexgrid'\n",
    "# Population data\n",
    "pop_schema = 'censo'\n",
    "pop_table = 'hex_bins_pop_2020' ################################# PENDIENTE\n",
    "\n",
    "# ---------------------------- ANALYSIS AND OUTPUT OPTIONS ----------------------------\n",
    "# Network distance method used in function pois_time. (If length, assumes pedestrian speed of 4km/hr.)\n",
    "prox_measure = 'time_min' # Must pass 'length' or 'time_min'\n",
    "\n",
    "# Count available amenities at given time proximity (minutes)?\n",
    "count_pois = (True,15) # Must pass a tupple containing a boolean (True or False) and time proximity of interest in minutes (Boolean,time)\n",
    "\n",
    "# If pop_output = True, loads pop data from pop_schema and pop_table.\n",
    "# If pop_output = False, loads empty hexgrid.\n",
    "pop_output = False\n",
    "\n",
    "# Hexagon resolutions of output\n",
    "# If pop_output == True, allows res 8 only.\n",
    "# If pop_output == False and version == 1, allows res 8 and 9 only (res 10 available, but doesn't have a 'metropolis' or 'city' column.\n",
    "# If pop_output == False and version == 2 , allows res 8, 9, 10 and 11 only.\n",
    "res_list = [7,8,9,10,11,12] \n",
    "\n",
    "# SAVING\n",
    "# Save final output to db?\n",
    "save = False\n",
    "save_schema = 'prox_analysis'\n",
    "save_table = 'proximityanalysis_24_ageb_hex'\n",
    "# Local save? (Runs Aguascalientes for tests)\n",
    "local_save = False\n",
    "local_save_dir = '../../data/external/temporal_fromjupyter/proximity_v2/test_proxanalysis_scriptv2_poisproxcount.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af9141ff-3d88-4c90-9deb-96d88e3ad4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# Simplified diccs for notebook testing.\n",
    "####################################################################################################################################\n",
    "\n",
    "parameters = {'Entretenimiento':{'Social':{'denue_restaurante_insitu':[722511, 722512, 722513, 722514, 722519],\n",
    "                                            'denue_restaurante_llevar':[722516, 722518, 722517],\n",
    "                                            'denue_bares':[722412],\n",
    "                                            'denue_cafe':[722515]},\n",
    "                                    'Actividad física':{'sip_cancha':[93110],\n",
    "                                                        'sip_unidad_deportiva':[93111],\n",
    "                                                        'sip_espacio_publico':[9321],\n",
    "                                                        'denue_parque_natural':[712190]},\n",
    "                                    'Cultural':cultural_dicc\n",
    "                                } \n",
    "             }\n",
    "\n",
    "source_weight = {'Entretenimiento':{'Social':'max', # ////////////////////////////////////////////////// Will choose max time to source because measuring access to all of them.\n",
    "                                    'Actividad física':'min', # //////////////////////////////////////// Will choose min time to source because measuring access to nearest source, doesn't matter which.\n",
    "                                    'Cultural':cultural_weight} # //////////////////////////////////////////////// Depends on version.\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cc2f16-9e0c-4bce-b6f1-84bc7fb581f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "# Simplified version, for centro cultural only. Full code filters dif (Not used in this notebook test).\n",
    "####################################################################################################################################\n",
    "def get_denue_pois(denue_schema,denue_table,poly_wkt,code,version):\n",
    "    # This function downloads the codigo_act denue poi requested for the analysis.\n",
    "    # If it is version 2.0, applies a filter to certain pois.\n",
    "\n",
    "    # Download denue pois\n",
    "    query = f\"SELECT * FROM {denue_schema}.{denue_table} WHERE (ST_Intersects(geometry, \\'SRID=4326;{poly_wkt}\\')) AND (\\\"codigo_act\\\" = \\'{code}\\')\"\n",
    "    code_pois = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "\n",
    "     # Version 2.0 pois filter\n",
    "    if version == 1:\n",
    "        aup.log(\"--- No filter applied.\")\n",
    "    elif version == 2:\n",
    "        if code == 931610: #denue_dif\n",
    "            aup.log(f\"--- Applying filtering to code {code}.\")\n",
    "            dif = code_pois.copy()\n",
    "            # Sets word of amenity to avoid in nom_estab\n",
    "            words_toavoid = [# Culturales\n",
    "                            'ARTE', #incluye ARTES, CONARTE\n",
    "                            'MEDIATECA', 'MUSICA','ORQUESTA', #incluye MUSICAL, ORQUESTAS\n",
    "                            # Instituciones\n",
    "                            'CONAFE','CONACYT', #incluye CULTURAL\n",
    "                            'TRIBUNAL','PROTECCION CIVIL','IMM',\n",
    "                            # Salud\n",
    "                            'IMMS','ISSTE','INAPAM','SEGURO','POPULAR','FOVI', #incluye FOVISSTE, FOVILEON, etc #\n",
    "                            'CAPASITIS',#Centro ambulatorio para la prevención y atención del SIDA e infecciones de transmision sexual\n",
    "                            'SANITARI', #SANITARIO/SANITARIA\n",
    "                            'MEDIC', #MEDICO/MEDICA\n",
    "                            # Educación\n",
    "                            'INEA','PRIMARIA','SECUNDARIA','PREPARATORIA','MAESTROS','BECA','ASESORIA','APOYO',\n",
    "                            'USAER', #Unidad de Servicio de Apoyo a la Educación Regular\n",
    "                            'EDUCA', #EDUCACION, EDUCACIÓN, EDUCATIVO, EDUCATIVA\n",
    "                            # Vivienda\n",
    "                            'VIVIENDA','INFONAVIT',\n",
    "                            # Oficinas\n",
    "                            'COORDINA','CORDINA', #incluye COORDINACION, y typos (CORDINACION)\n",
    "                            'DIRECCION','DIVISION','INSPECCION','INSTITUTO','JEFATURA','JURISDICCION','OFICINA','PROGRAMA','PROCURADORIA','PROCURADURIA',\n",
    "                            'RECAUDACION','PAPELERIA','REGION ','REGULACION','SECRETARIA','DELEGACION','SUPERVI',\n",
    "                            'ADMINISTRA',#ADMINISTRATIVO, ADMINISTRATIVA\n",
    "                            'ANALISIS', 'SEGUIMIENTO','MICRORED','MICRO RED',\n",
    "                            # Almacenes y bodegas\n",
    "                            'ALMACEN','BODEGA','ARCHIVO','ACTIVO',\n",
    "                            'PROVEED', #PROVEEDOR, PROVEEDORA\n",
    "                            # Otros\n",
    "                            'JUNTA', # para juntas de mejoras\n",
    "                            'POLIVALENTE',\n",
    "                            'SERVICIO',\n",
    "                            'GIMNASIO']\n",
    "            # Set checker\n",
    "            dif['keep'] = 1\n",
    "            for word in words_toavoid:\n",
    "                # Reset word_coincidence_count column\n",
    "                dif['word_coincidence_count'] = 0\n",
    "                # Look for word coincidence (0 = absent, 1 = present)\n",
    "                dif['word_coincidence_count'] = dif['nom_estab'].apply(lambda x: x.count(word))\n",
    "                # If the word is present, do not keep\n",
    "                dif.loc[dif.word_coincidence_count > 0,'keep'] = 0\n",
    "            # Filter and return to rest of function (Formats later)\n",
    "            dif_filtered = dif.loc[dif['keep'] == 1]\n",
    "            dif_filtered.drop_duplicates(inplace=True)\n",
    "            code_pois = dif_filtered.copy()\n",
    "        \n",
    "        elif code == 711312: #denue_centro_cultural\n",
    "            aup.log(f\"--- Applying filtering to code {code}.\")\n",
    "            centro_cultural = code_pois.copy()\n",
    "            amenities_ofinterest = ['CENTRO',\n",
    "                                    'CULTURA', #incluye CULTURAL\n",
    "                                    'LIENZO',\n",
    "                                    'PLAZA',\n",
    "                                    'ARENA',\n",
    "                                    'AUDITORIO',\n",
    "                                    'TEATRO',\n",
    "                                    'ARTE', # incluye ARTES\n",
    "                                    'MUSEO']\n",
    "            # Filter \n",
    "            centro_cultural_filtered = gpd.GeoDataFrame()\n",
    "            for amenity in amenities_ofinterest:\n",
    "                tmp = centro_cultural.loc[centro_cultural['nom_estab'].str.contains(amenity, regex=False)]\n",
    "                centro_cultural_filtered = pd.concat([centro_cultural_filtered, tmp])\n",
    "            # Return to rest of function\n",
    "            centro_cultural_filtered.drop_duplicates(inplace=True)\n",
    "            code_pois = centro_cultural_filtered.copy()\n",
    "        else:\n",
    "            aup.log(\"--- No filter applied.\")\n",
    "    else:\n",
    "        aup.log(\"--- Error in specified proximity analysis version.\")\n",
    "        aup.log(\"--- Must pass integers 1 or 2.\")\n",
    "        intended_crash\n",
    "\n",
    "    # Format denue pois\n",
    "    code_pois = code_pois[['codigo_act', 'geometry']]\n",
    "    code_pois = code_pois.rename(columns={'codigo_act':'code'})\n",
    "    code_pois['code'] = code_pois['code'].astype('int64')\n",
    "\n",
    "    return code_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c031b263-8358-4bba-8288-c93de29ee193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_method_check(row):\n",
    "    # This function is used to decide which time to choose for cultural amenities.\n",
    "    # Why:\n",
    "        # In version 2 we aded 'Bibliotecas'. The source contains plenty of pois.\n",
    "        # This might dilute other cultural sources. Therefore:\n",
    "\n",
    "    # If 2 or more source amenities are within 15 minutes, \n",
    "    # chooses max time of the sources within 15 minutes.\n",
    "    # (Measures proximity to an amenity which we know is close.)\n",
    "    if row['check_count'] > 1:\n",
    "        # Identify sources within 15 minutes\n",
    "        prox_sources=[]\n",
    "        for s in check_lst:\n",
    "            if row[s] == 1:\n",
    "                prox_sources.append(s.replace('_check',''))\n",
    "        # Find max of those sources\n",
    "        row['max_'+a.lower()] = row[prox_sources].max()\n",
    "\n",
    "    # Else (just 1 or 0 source amenities are within 15 minutes),\n",
    "    # chooses min time of the amenities outside 15 minutes. \n",
    "    # (Ignores if only one is close (most likely bibliotecas), takes next closest)\n",
    "    else:\n",
    "        # Identify sources outside 15 minutes\n",
    "        prox_sources=[]\n",
    "        for s in check_lst:\n",
    "            if row[s] == 0:\n",
    "                prox_sources.append(s.replace('_check',''))\n",
    "        # Find min of those sources\n",
    "        row['max_'+a.lower()] = row[prox_sources].min()\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1028785-32af-4ded-b6b2-9ca673a2a44f",
   "metadata": {},
   "source": [
    "## Script 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82e307a-035b-4887-bddb-d24d6f2d16eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51434, 4)\n",
      "(121037, 19)\n"
     ]
    }
   ],
   "source": [
    "############################################################### PART 1 ###############################################################\n",
    "#################################################### FIND NODES PROXIMITY TO POIS ####################################################\n",
    "###################################################### (PREV. SCRIPT 01 + 02) ########################################################\n",
    "\n",
    "# 1.1 --------------- BASE DATA FOR POIS-NODES ANALYSIS\n",
    "# ------------------- This first step downloads the area of interest and network used to measure distance.\n",
    "\n",
    "# Download area of interest\n",
    "query = f\"SELECT * FROM {metro_schema}.{metro_table} WHERE \\\"city\\\" LIKE \\'{city}\\'\"\n",
    "mun_gdf = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "mun_gdf = mun_gdf.set_crs(\"EPSG:4326\")\n",
    "aoi = mun_gdf.dissolve()\n",
    "\n",
    "# Download Network used to calculate nearest note to each poi\n",
    "G, nodes, edges = aup.graph_from_hippo(aoi, schema=network_schema, edges_folder=edges_table, nodes_folder=nodes_table)\n",
    "\n",
    "# Show\n",
    "print(nodes.shape)\n",
    "print(edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d36b56d-fe82-4ca0-b7be-b7e515e9014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/opt/conda/envs/gds/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# 1.2 --------------- DOWNLOAD POINTS OF INTEREST (clues and sip pois, not denue)\n",
    "# ------------------- This step downloads SIP and CLUES points of interest (denue pois are downloaded later.)\n",
    "sip_clues_gdf = gpd.GeoDataFrame()\n",
    "\n",
    "# CLUES (Salud)\n",
    "aup.log(f\"--- Downloading CLUES pois for {city}.\")\n",
    "# Download\n",
    "clues_gdf = aup.gdf_from_polygon(aoi, clues_schema, clues_table, geom_col=\"geometry\")\n",
    "# Filter\n",
    "clues_pois = clues_gdf.loc[clues_gdf['nivel_atencion'] == 'PRIMER NIVEL']\n",
    "del clues_gdf\n",
    "# Format\n",
    "clues_pois.loc[:,'code'] = 8610\n",
    "clues_pois = clues_pois[['code','geometry']]\n",
    "# Save to pois_tmp\n",
    "sip_clues_gdf = pd.concat([sip_clues_gdf,clues_pois])\n",
    "del clues_pois\n",
    "\n",
    "# SIP (Marco geoestadistico)\n",
    "aup.log(f\"--- Downloading SIP pois for {city}.\")\n",
    "# Download\n",
    "sip_gdf = aup.gdf_from_polygon(aoi, sip_schema, sip_table, geom_col=\"geometry\")\n",
    "sip_amenities = {'GEOGRAFICO':['Mercado','Plaza'], \n",
    "                 'TIPO':['Cancha','Unidad Deportiva','Áreas Verdes','Jardín','Parque']}\n",
    "# Filter - SIP pois of interest\n",
    "sip_amenities_codes = {'Mercado':4721, #sip_mercado\n",
    "                       'Cancha':93110, #sip_cancha\n",
    "                       'Unidad Deportiva':93111, #sip_unidad_deportiva \n",
    "                       'Áreas Verdes':9321, #sip_espacio_publico \n",
    "                       'Jardín':9321, #sip_espacio_publico\n",
    "                       'Parque':9321, #sip_espacio_publico\n",
    "                       'Plaza':9321 #sip_espacio_publico\n",
    "                        }\n",
    "# Filter - Iterate over sip_amenities and filter sip gdf\n",
    "sip_pois = gpd.GeoDataFrame()\n",
    "for col in sip_amenities:\n",
    "    for amenity in sip_amenities[col]:\n",
    "        sip_tmp = sip_gdf.loc[sip_gdf[col] == amenity]\n",
    "        sip_tmp.loc[:,'code'] = sip_amenities_codes[amenity]\n",
    "        sip_pois = pd.concat([sip_pois,sip_tmp])\n",
    "del sip_gdf\n",
    "# Format\n",
    "sip_pois = sip_pois[['code','geometry']]\n",
    "# Save to pois_tmp\n",
    "sip_clues_gdf = pd.concat([sip_clues_gdf,sip_pois])\n",
    "del sip_pois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2aa6b-4693-4607-89bf-bacafbef37a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# STARTS FUNCTIONS REDEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deedac2b-3bb7-4808-9242-c50b60a3ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    poly_wkt = aoi.dissolve().geometry.to_wkt()[0]\n",
    "\n",
    "    i = 0\n",
    "    source_list = []\n",
    "    \n",
    "    for eje in parameters.keys():\n",
    "        for amenity in parameters[eje]:\n",
    "            for source in parameters[eje][amenity]:\n",
    "    \n",
    "                source_list.append(source)\n",
    "                # ANALYSIS - Select source points of interest\n",
    "                source_pois = gpd.GeoDataFrame()\n",
    "                for code in parameters[eje][amenity][source]:\n",
    "                    #If source is denue:\n",
    "                    if source[0] == 'd':\n",
    "                        print(f'--- Downloading denue source pois code {code} from db.')\n",
    "                        code_pois = get_denue_pois(denue_schema,denue_table,poly_wkt,code,version)\n",
    "                    #If source is clues or sip:\n",
    "                    elif source[0] == 'c' or source[0] == 's':\n",
    "                        print(f'--- Getting clues/sip source pois code {code} from previously downloaded.')\n",
    "                        code_pois = sip_clues_gdf.loc[sip_clues_gdf['code'] == code]\n",
    "                    else:\n",
    "                        print(f'--- Error, check parameters dicctionary.')\n",
    "                        print(f'--- Sources must start with denue_, clues_ or sip_.')\n",
    "                        intended_crash\n",
    "                        \n",
    "                    source_pois = pd.concat([source_pois,code_pois])\n",
    "    \n",
    "                # ANALYSIS - Calculate times from nodes to source\n",
    "                #source_nodes_time = aup.pois_time(G, nodes, edges, source_pois, source, prox_measure)\n",
    "    \n",
    "    # Show\n",
    "    print(source_pois.shape)\n",
    "    source_pois.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd20c12-026c-47db-96fd-77665a897400",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DESGLOSE DE LA FUNCIÓN aup.pois_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3796755d-11e9-43ac-9936-f7b1966dc4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DESGLOSE DE LA FUNCIÓN aup.pois_time\n",
    "\n",
    "if test:\n",
    "    # Objetivo:\n",
    "    #source_nodes_time = aup.pois_time(G, nodes, edges, source_pois, source, prox_measure)\n",
    "    \n",
    "    # Función usada:\n",
    "    #def pois_time(G, nodes, edges, pois, poi_name, prox_measure):\n",
    "    \n",
    "    # Base data needed:\n",
    "    pois = source_pois.copy()\n",
    "    poi_name = source\n",
    "    count_pois = (True,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2035a3-d335-43cf-ad35-aae8e97a865b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DESGLOSE DE LAS FUNCIONES aup.calculate_distance_nearest_poi & aup.get_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd20201-7691-4802-9c7d-6bafe862e6a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 00 - Llegar a la función de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5e0b03-19eb-43ff-b9c8-ca914fde0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DESGLOSE DE LA FUNCIÓN aup.pois_time hasta llegar a calculate_distance_nearest_poi\n",
    "\n",
    "if test:\n",
    "    ##########################################################################################\n",
    "    # Step 1: NEAREST. Finds and assigns nearest node OSMID to each point of interest.\n",
    "       \n",
    "    # Defines projection for downloaded data\n",
    "    pois = pois.set_crs(\"EPSG:4326\")\n",
    "    nodes = nodes.set_crs(\"EPSG:4326\")\n",
    "    edges = edges.set_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # In case there are no amenities of the type in the city, prevents it from crashing if len = 0\n",
    "    if len(pois) == 0:\n",
    "        nodes_time = nodes.copy()\n",
    "        # Time is set to np.nan\n",
    "        nodes_time['time'] = np.nan\n",
    "        print(f\"0 {poi_name} found. Time set to 0.\")\n",
    "        # Format\n",
    "        nodes_time['source'] = poi_name\n",
    "        nodes_time.reset_index(inplace=True)\n",
    "        nodes_time = nodes_time.set_crs(\"EPSG:4326\")\n",
    "        nodes_time = nodes_time[['osmid','time','source','x','y','geometry']]\n",
    "        #return nodes_time\n",
    "    \n",
    "    else:\n",
    "        ### Calculate nearest node for each DENUE point\n",
    "        nearest = aup.find_nearest(G, nodes, pois, return_distance= True)\n",
    "        nearest = nearest.set_crs(\"EPSG:4326\")\n",
    "        print(f\"Found and assigned nearest node osmid to each {poi_name}.\")\n",
    "    \n",
    "        ##########################################################################################\n",
    "        # Step 2: DISTANCE NEAREST POI. Calculates distance from each node to its nearest point of interest.\n",
    "            \n",
    "        # --------------- 2.1 FORMAT NETWORK\n",
    "        # Fill NANs with mean times\n",
    "        edges[prox_measure].fillna(edges[prox_measure].mean(),inplace=True)\n",
    "        \n",
    "        # --------------- 2.2 ELEMENTS NEEDED OUTSIDE THE LOOP\n",
    "        # The pois are divided by batches of 200 or 250 pois and analysed using the function calculate_distance_nearest_poi\n",
    "        # nodes_analysis is a nodes (index reseted) used in the function.\n",
    "        nodes_analysis = nodes.reset_index().copy()\n",
    "        # df_temp: Each column will store a batch of procesed nodes.\n",
    "        df_temp = nodes.copy()\n",
    "        #nodes_distance: Minimum time/distance found in all batches will be added from df_min (within if/elif/else) \n",
    "        #\t\t\t\t to nodes_distance (output) keeping x,y and geometry data.\n",
    "        nodes_distance = nodes.copy()\n",
    "        \n",
    "        # --------------- 2.3 PROCESSING DISTANCE\n",
    "        print (f\"Starting time analysis for {poi_name}.\")\n",
    "        \n",
    "        # If possible, analyses by batches of 200 pois.\n",
    "        if len(nearest) % 250:\n",
    "            batch_size = len(nearest)/200\n",
    "            for k in range(int(batch_size)+1):\n",
    "                print(f\"Starting range k = {k+1} of {int(batch_size)+1} for {poi_name}.\")\n",
    "                source_process = nearest.iloc[int(200*k):int(200*(1+k))].copy()\n",
    "                #nodes_distance_prep = calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure)\n",
    "        print(len(source_process))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87474ab0-85f2-4882-ac93-7cf38a09faf2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 01 - Exploración del código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda7f8a0-82ea-4303-be63-d55d0d4b635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESGLOSE DE LA FUNCIÓN aup.calculate_distance_nearest_poi\n",
    "\n",
    "if test:\n",
    "    # Objetivo:\n",
    "    #nodes_distance_prep = aup.calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure, get_nearest_poi=(False, 'osmid'))\n",
    "    \n",
    "    # Función usada:\n",
    "    # def calculate_distance_nearest_poi(gdf_f, nodes, edges, amenity_name, column_name, wght='length', get_nearest_poi=(False, 'poi_id_column') max_distance=(0,'distance_node'))\n",
    "    \n",
    "    # Base data needed:\n",
    "    gdf_f = source_process.copy()\n",
    "    nodes = nodes_analysis.copy()\n",
    "    amenity_name = poi_name\n",
    "    column_name = 'osmid'\n",
    "    wght = prox_measure\n",
    "    get_nearest_poi=(True, 'osmid')\n",
    "    max_distance=(0,'distance_node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e3b2f1-3964-4388-a87a-af3b42570010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESGLOSE DE LA FUNCIÓN aup.calculate_distance_nearest_poi\n",
    "\n",
    "if test:\n",
    "    # --- Required processing\n",
    "\tnodes = nodes.copy()\n",
    "\tedges = edges.copy()\n",
    "\tif max_distance[0] > 0:\n",
    "\t\tgdf_f = gdf_f.loc[gdf_f[max_distance[1]]<=max_distance[0]]\n",
    "\tg, weights, node_mapping = aup.to_igraph(nodes,edges,wght=wght) #convert to igraph to run the calculations\n",
    "\tseeds = aup.get_seeds(gdf_f, node_mapping, column_name)\n",
    "\tvoronoi_assignment = aup.voronoi_cpu(g, weights, seeds)\n",
    "\n",
    "    #if get_nearest_poi[0]: # Return distances and nearest poi idx\n",
    "    \t#distances, nearest_poi_idx = get_distances(g,seeds,weights,voronoi_assignment,get_nearest_poi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d57bf99-e09f-4858-89e0-545ab12a00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESGLOSE DE LA FUNCIÓN aup.get_distances\n",
    "\n",
    "if test:\n",
    "    # Objetivo:\n",
    "    # distances, nearest_poi_idx = get_distances(g,seeds,weights,voronoi_assignment,get_nearest_poi=True)\n",
    "    \n",
    "    # Función usada:\n",
    "    # def get_distances(g, seeds, weights, voronoi_assignment, get_nearest_poi=False):\n",
    "    \n",
    "    # Base data needed:\n",
    "    get_nearest_poi=True\n",
    "    shortest_paths = np.array(g.shortest_paths_dijkstra(seeds,weights=weights))\n",
    "    distances = [np.min(shortest_paths[:,i]) for i in range(len(voronoi_assignment))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2162fbc-09d6-4000-a74a-8f38b9b7b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Matriz de interés. Contiene los tiempos.\n",
    "    # 51434 elementos en la fila 1\n",
    "    # 95 elementos en la columna 1\n",
    "\n",
    "    # Show\n",
    "    print(shortest_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d210c0-98d3-4565-8315-3a8615ab1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Ejemplo de función que se utiliza para conocer la nearest amenity\n",
    "    # nearest_poi_idx = [np.argmin(shortest_paths[:,i]) for i in range(len(voronoi_assignment))]\n",
    "    \n",
    "    # Show\n",
    "    print(len(shortest_paths[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b730b89-d094-4ee0-95a3-d4e5dd80a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    print(len(voronoi_assignment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8731699-377f-4bbe-95d2-aaa8e81ce55f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 02 - Desarrollo del cambio a realizar para que cuente las amenidades a x tiempo (e.g. 15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f49a8ed-81f7-45bc-a3bd-26e7bb94f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRUEBA DEL MÉTODO PARA LA FUNCIÓN get_distances\n",
    "\n",
    "if test:\n",
    "    # Base data\n",
    "    data = np.array([[10, 20],\n",
    "                     [20, 83],\n",
    "                     [1, 15]])\n",
    "    \n",
    "    # Test 1 (failed)\n",
    "    #prueba = np.where( data <= 15 )\n",
    "    # Test 2 (Success)\n",
    "    prueba = [len(np.where(data[:,i] <= 15)[0]) for i in range(2)] #in range of number of columns (in function, nodes available (voronoi_assignment))\n",
    "    # Show\n",
    "    print(prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7fcd52-c5c2-4aa1-b12e-9e55993e25d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 03 - Prueba de redefinición de las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24478664-daa3-4493-acf3-a14162e97ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    def get_distances(g, seeds, weights, voronoi_assignment, get_nearest_poi=False, count_pois = (False,0)):\n",
    "    \n",
    "        shortest_paths = np.array(g.shortest_paths_dijkstra(seeds,weights=weights))\n",
    "        distances = [np.min(shortest_paths[:,i]) for i in range(len(voronoi_assignment))]\n",
    "        \n",
    "        if get_nearest_poi:\n",
    "            nearest_poi_idx = [np.argmin(shortest_paths[:,i]) for i in range(len(voronoi_assignment))]\n",
    "        \n",
    "        if count_pois[0]:\n",
    "            near_count = [len(np.where(shortest_paths[:,i] <= count_pois[1])[0]) for i in range(len(voronoi_assignment))]\n",
    "    \n",
    "        # Return options\n",
    "        if get_nearest_poi and count_pois[0]:\n",
    "            return distances, nearest_poi_idx, near_count\n",
    "        elif get_nearest_poi:\n",
    "            return distances, nearest_poi_idx\n",
    "        elif count_pois[0]:\n",
    "            return distances, near_count\n",
    "        else:\n",
    "            return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8666e447-24fc-4b86-b288-1f98055a904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    def calculate_distance_nearest_poi(gdf_f, nodes, edges, amenity_name, column_name, \n",
    "    wght='length', get_nearest_poi=(False, 'poi_id_column'),count_pois=(False,0), max_distance=(0,'distance_node')):\n",
    "                                       \n",
    "        nodes = nodes.copy()\n",
    "        edges = edges.copy()\n",
    "        if max_distance[0] > 0:\n",
    "            gdf_f = gdf_f.loc[gdf_f[max_distance[1]]<=max_distance[0]]\n",
    "        g, weights, node_mapping = aup.to_igraph(nodes,edges,wght=wght) #convert to igraph to run the calculations\n",
    "        col_weight = f'dist_{amenity_name}'\n",
    "        seeds = aup.get_seeds(gdf_f, node_mapping, column_name)\n",
    "        voronoi_assignment = aup.voronoi_cpu(g, weights, seeds)\n",
    "    \n",
    "        # Return distances, nearest poi and near count\n",
    "        if get_nearest_poi[0] and (count_pois[0]):\n",
    "            distances, nearest_poi_idx, near_count = get_distances(g,seeds,weights,voronoi_assignment,\n",
    "                                                                   get_nearest_poi=True, \n",
    "                                                                   count_pois=count_pois)\n",
    "            nearest_poi = [gdf_f.iloc[i][get_nearest_poi[1]] for i in nearest_poi_idx]\n",
    "            nodes[f'{count_pois[1]}min_{amenity_name}'] = near_count\n",
    "            nodes[f'nearest_{amenity_name}'] = nearest_poi\n",
    "            \n",
    "        # Return distances and nearest poi\n",
    "        elif get_nearest_poi[0]:\n",
    "            distances, nearest_poi_idx = get_distances(g,seeds,weights,voronoi_assignment,\n",
    "                                                       get_nearest_poi=True)\n",
    "            nearest_poi = [gdf_f.iloc[i][get_nearest_poi[1]] for i in nearest_poi_idx]\n",
    "            nodes[f'nearest_{amenity_name}'] = nearest_poi\n",
    "    \n",
    "        # Return distances and near count\n",
    "        elif (count_pois[0]):\n",
    "            distances, near_count = get_distances(g,seeds,weights,voronoi_assignment,\n",
    "                                                  count_pois=count_pois)\n",
    "            nodes[f'{count_pois[1]}min_{amenity_name}'] = near_count\n",
    "    \n",
    "        # Return distances only\n",
    "        else:\n",
    "            distances = get_distances(g,seeds,weights,voronoi_assignment)\n",
    "    \n",
    "        nodes[col_weight] = distances\n",
    "    \n",
    "        nodes.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        idx = pd.notnull(nodes[col_weight])\n",
    "        nodes = nodes[idx].copy()\n",
    "    \n",
    "        return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4ce98-127f-46cf-88ea-8ae46edcb9d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 04 - Resultado de las funciones redefinidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f83f1c21-e19b-40ff-9e48-b5ecc2247b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Prueba 1: return distance\n",
    "    nodes_distance_prep_01 = calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure)\n",
    "    \n",
    "    # Show\n",
    "    print(nodes_distance_prep_01.shape)\n",
    "    print(nodes_distance_prep_01.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "065c5586-6ceb-456a-a5d4-a9d455881c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Prueba 2: return distance and nearest_poi\n",
    "    nodes_distance_prep_02 = calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure,\n",
    "                                                         get_nearest_poi=(True, 'osmid'))\n",
    "    \n",
    "    # Show\n",
    "    print(nodes_distance_prep_02.shape)\n",
    "    print(nodes_distance_prep_02.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "207686b3-1773-4939-b0e0-3c75ecda5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Prueba 3: return distance and count amenities at 15 mins\n",
    "    nodes_distance_prep_02 = calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure,\n",
    "                                                         count_pois = (True,15))\n",
    "    \n",
    "    # Show\n",
    "    print(nodes_distance_prep_02.shape)\n",
    "    print(nodes_distance_prep_02.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa2af79c-c448-46a8-9496-d83bcdabcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Prueba 4: return distance and count amenities at 30 mins\n",
    "    nodes_distance_prep_02 = calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure,\n",
    "                                                         count_pois = (True,30))\n",
    "    \n",
    "    # Show\n",
    "    print(nodes_distance_prep_02.shape)\n",
    "    print(nodes_distance_prep_02.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c7ec1a7-7405-4bfe-9518-f7b3ad35070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Prueba 5: return distance, nearest poi and count amenities at 45 mins\n",
    "    nodes_distance_prep_03 = calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure,\n",
    "                                                         get_nearest_poi=(True, 'osmid'),\n",
    "                                                         count_pois = (True,45),\n",
    "                                                         max_distance=(0,'distance_node'))\n",
    "    \n",
    "    # Show\n",
    "    print(nodes_distance_prep_03.shape)\n",
    "    print(nodes_distance_prep_03.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6645b1-a188-45d6-bbaf-d90683c408e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CONTINUA DESGLOSE DE LA FUNCIÓN aup.pois_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331d186-6ccf-4cd4-a7b5-2ef3bd548d16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 01 - Iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "275d6ef8-24ed-4eb4-9d0a-29b4d726de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DESGLOSE DE LA FUNCIÓN aup.pois_time (original modificada, version 1)\n",
    "\n",
    "if test:\n",
    "    ##########################################################################################\n",
    "    # Step 1: NEAREST. Finds and assigns nearest node OSMID to each point of interest.\n",
    "       \n",
    "    # Defines projection for downloaded data\n",
    "    pois = pois.set_crs(\"EPSG:4326\")\n",
    "    nodes = nodes.set_crs(\"EPSG:4326\")\n",
    "    edges = edges.set_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # In case there are no amenities of the type in the city, prevents it from crashing if len = 0\n",
    "    if len(pois) == 0:\n",
    "        nodes_time = nodes.copy()\n",
    "        # Time is set to np.nan\n",
    "        nodes_time['time'] = np.nan\n",
    "        print(f\"0 {poi_name} found. Time set to nan.\")\n",
    "        # If requested, pois_count is set to nan.\n",
    "        if count_pois[0]:\n",
    "            nodes_time['pois_count'] = np.nan\n",
    "            print(f\"0 {poi_name} found. Pois count set to nan.\")\n",
    "        \n",
    "        # Format\n",
    "        nodes_time['source'] = poi_name\n",
    "        nodes_time.reset_index(inplace=True)\n",
    "        nodes_time = nodes_time.set_crs(\"EPSG:4326\")\n",
    "        nodes_time = nodes_time[['osmid','time','source','x','y','geometry']]\n",
    "        #return nodes_time\n",
    "    \n",
    "    else:\n",
    "        ### Calculate nearest node for each DENUE point\n",
    "        nearest = aup.find_nearest(G, nodes, pois, return_distance= True)\n",
    "        nearest = nearest.set_crs(\"EPSG:4326\")\n",
    "        print(f\"Found and assigned nearest node osmid to each {poi_name}.\")\n",
    "    \n",
    "        ##########################################################################################\n",
    "        # Step 2: DISTANCE NEAREST POI. Calculates distance from each node to its nearest point of interest.\n",
    "            \n",
    "        # --------------- 2.1 FORMAT NETWORK\n",
    "        # Fill NANs with mean times\n",
    "        edges[prox_measure].fillna(edges[prox_measure].mean(),inplace=True)\n",
    "        \n",
    "        # --------------- 2.2 ELEMENTS NEEDED OUTSIDE THE LOOP\n",
    "        # The pois are divided by batches of 200 or 250 pois and analysed using the function calculate_distance_nearest_poi\n",
    "        # nodes_analysis is a nodes (index reseted) used in the function.\n",
    "        nodes_analysis = nodes.reset_index().copy()\n",
    "        # df_temp: Each column will store a batch of procesed nodes.\n",
    "        df_temp = nodes.copy()\n",
    "        if count_pois[0]:\n",
    "            df_temp_2 = nodes.copy()\n",
    "        #nodes_distance: Minimum time/distance found in all batches will be added from df_min (within if/elif/else) \n",
    "        #\t\t\t\t to nodes_distance (output) keeping x,y and geometry data.\n",
    "        nodes_distance = nodes.copy()\n",
    "        \n",
    "        # --------------- 2.3 PROCESSING DISTANCE\n",
    "        print (f\"Starting time analysis for {poi_name}.\")\n",
    "        \n",
    "        # If possible, analyses by batches of 200 pois.\n",
    "        if len(nearest) % 250:\n",
    "            batch_size = len(nearest)/200\n",
    "            for k in range(int(batch_size)+1):\n",
    "                print(f\"Starting range k = {k+1} of {int(batch_size)+1} for {poi_name}.\")\n",
    "                source_process = nearest.iloc[int(200*k):int(200*(1+k))].copy()\n",
    "                nodes_distance_prep = aup.calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure,\n",
    "                                                                         count_pois=count_pois)\n",
    "                #A middle gdf is created whose columns will be the name of the poi and the batch number it belongs to\n",
    "                df_int = pd.DataFrame()\n",
    "                df_int['dist_'+str(k)+poi_name] = nodes_distance_prep['dist_'+poi_name]\n",
    "                if count_pois[0]:\n",
    "                    df_int_2 = pd.DataFrame()\n",
    "                    df_int_2[f'{count_pois[1]}min_'+str(k)+poi_name] = nodes_distance_prep[f'{count_pois[1]}min_'+poi_name]\n",
    "                    \n",
    "                #The middle gdf is merged into the previously created temporary gdf to store the data by node, each batch in a column.\n",
    "                df_temp = df_temp.merge(df_int, left_index=True, right_index=True)\n",
    "                if count_pois[0]:\n",
    "                    df_temp_2 = df_temp_2.merge(df_int_2, left_index=True, right_index=True)\n",
    "                    \n",
    "            # Once finished, drop the non-distance values from the temporary gdf\n",
    "            df_temp.drop(['x', 'y', 'street_count','geometry'], inplace = True, axis=1)\n",
    "            if count_pois[0]:\n",
    "                df_temp_2.drop(['x', 'y', 'street_count','geometry'], inplace = True, axis=1)\n",
    "            \n",
    "            #We apply the min function to find the minimum value. This value is sent to a new df_min\n",
    "            df_min = pd.DataFrame()\n",
    "            df_min['dist_'+poi_name] = df_temp.min(axis=1)\n",
    "            # For pois count, we apply the sum function to find the total value. This value is sent to a new df_sum\n",
    "            if count_pois[0]:\n",
    "                df_sum = pd.DataFrame()\n",
    "                df_sum[f'{count_pois[1]}min_'+poi_name] = df_temp_2.sum(axis=1)\n",
    "            \n",
    "            #We merge df_min which contains the shortest distance to the POI with nodes_distance which will store all final data\n",
    "            nodes_distance = nodes_distance.merge(df_min, left_index=True, right_index=True)\n",
    "            # For pois count, we merge df_sum which contains the total pois found ad given a given time to the POI with nodes_distance which will store all final data\n",
    "            if count_pois[0]:\n",
    "                nodes_distance = nodes_distance.merge(df_sum, left_index=True, right_index=True)\n",
    "\n",
    "    # Show\n",
    "    print(nodes_distance.shape)\n",
    "    print(nodes_distance.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3039763d-ca7e-4ad4-a883-22106d3a048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DESGLOSE DE LA FUNCIÓN aup.pois_time (simplificada, version 2)\n",
    "\n",
    "if test:\n",
    "    ##########################################################################################\n",
    "    # Step 1: NEAREST. Finds and assigns nearest node OSMID to each point of interest.\n",
    "       \n",
    "    # Defines projection for downloaded data\n",
    "    pois = pois.set_crs(\"EPSG:4326\")\n",
    "    nodes = nodes.set_crs(\"EPSG:4326\")\n",
    "    edges = edges.set_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # In case there are no amenities of the type in the city, prevents it from crashing if len = 0\n",
    "    if len(pois) == 0:\n",
    "        nodes_time = nodes.copy()\n",
    "        # Time is set to np.nan\n",
    "        nodes_time['time'] = np.nan\n",
    "        print(f\"0 {poi_name} found. Time set to nan.\")        \n",
    "        # Format\n",
    "        nodes_time['source'] = poi_name\n",
    "        nodes_time.reset_index(inplace=True)\n",
    "        nodes_time = nodes_time.set_crs(\"EPSG:4326\")\n",
    "        # If requested, pois_count is set to nan.\n",
    "        if count_pois[0]:\n",
    "            nodes_time['pois_count'] = np.nan\n",
    "            print(f\"0 {poi_name} found. Pois count set to nan.\")\n",
    "            nodes_time = nodes_time[['osmid','time','pois_count','source','x','y','geometry']]\n",
    "            #return nodes_time\n",
    "        else:\n",
    "            nodes_time = nodes_time[['osmid','time','source','x','y','geometry']]\n",
    "            #return nodes_time\n",
    "    \n",
    "    else:\n",
    "        ### Calculate nearest node for each DENUE point\n",
    "        nearest = aup.find_nearest(G, nodes, pois, return_distance= True)\n",
    "        nearest = nearest.set_crs(\"EPSG:4326\")\n",
    "        print(f\"Found and assigned nearest node osmid to each {poi_name}.\")\n",
    "    \n",
    "        ##########################################################################################\n",
    "        # Step 2: DISTANCE NEAREST POI. Calculates distance from each node to its nearest point of interest.\n",
    "            \n",
    "        # --------------- 2.1 FORMAT NETWORK\n",
    "        # Fill NANs with mean times\n",
    "        edges[prox_measure].fillna(edges[prox_measure].mean(),inplace=True)\n",
    "        \n",
    "        # --------------- 2.2 ELEMENTS NEEDED OUTSIDE THE LOOP\n",
    "        # The pois are divided by batches of 200 or 250 pois and analysed using the function calculate_distance_nearest_poi\n",
    "        # nodes_analysis is a nodes (index reseted) used in the function.\n",
    "        nodes_analysis = nodes.reset_index().copy()\n",
    "        # df_batch: Each column will store a batch of procesed nodes. \n",
    "        #           After all nodes are processed, min (time) is calculated.\n",
    "        nodes_time = nodes.copy()\n",
    "        #nodes_distance: Minimum time/distance found in all batches will be added from df_min (within if/elif/else) \n",
    "        #\t\t\t\t to nodes_distance (output) keeping x,y and geometry data.\n",
    "        nodes_distance = nodes.copy()\n",
    "        \n",
    "        # --------------- 2.3 PROCESSING DISTANCE\n",
    "        print (f\"Starting time analysis for {poi_name}.\")\n",
    "        \n",
    "        # If possible, analyses by batches of 200 pois.\n",
    "        if len(nearest) % 250:\n",
    "            batch_size = len(nearest)/200\n",
    "\n",
    "            time_cols = []\n",
    "            poiscount_cols = []\n",
    "            \n",
    "            for k in range(int(batch_size)+1):\n",
    "                print(f\"Starting range k = {k+1} of {int(batch_size)+1} for {poi_name}.\")\n",
    "                source_process = nearest.iloc[int(200*k):int(200*(1+k))].copy()\n",
    "                nodes_distance_prep = aup.calculate_distance_nearest_poi(source_process, nodes_analysis, edges, poi_name, 'osmid', wght=prox_measure,\n",
    "                                                                         count_pois=count_pois)\n",
    "                #A middle gdf is created whose columns will be the name of the poi and the batch number it belongs to\n",
    "                batch_time_col = 'dist_'+str(k)+poi_name\n",
    "                time_cols.append(batch_time_col)\n",
    "                nodes_time[batch_time_col] = nodes_distance_prep['dist_'+poi_name]\n",
    "                \n",
    "                if count_pois[0]:\n",
    "                    batch_poiscount_col = f'{count_pois[1]}min_'+str(k)+poi_name\n",
    "                    poiscount_cols.append(batch_poiscount_col)\n",
    "                    nodes_time[batch_poiscount_col] = nodes_distance_prep[f'{count_pois[1]}min_'+poi_name]\n",
    "\n",
    "            # Apply the min function to find the minimum time (And the sum function to find the sum of pois at given time if requested)\n",
    "            nodes_time['dist_'+poi_name] = nodes_time[time_cols].min(axis=1)\n",
    "            if count_pois[0]:\n",
    "                nodes_time[f'{count_pois[1]}min_'+poi_name] = nodes_time[poiscount_cols].sum(axis=1)\n",
    "                nodes_time = nodes_time[['x','y','street_count','dist_'+poi_name,f'{count_pois[1]}min_'+poi_name,'geometry']]\n",
    "            else:\n",
    "                nodes_time = nodes_time[['x','y','street_count','dist_'+poi_name,f'{count_pois[1]}min_'+poi_name,'geometry']]\n",
    "\n",
    "    # Show\n",
    "    print(nodes_time.shape)\n",
    "    print(nodes_time.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc9785-b82f-4990-8b4b-10d8902488e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###  02 - Prueba de la función definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5b9ed9c-6091-4b73-81c6-84cb9d1e8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    # Show\n",
    "    print(source_pois.shape)\n",
    "    print(source_pois.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "923c6e68-ef13-49f8-8596-c94215dbc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    prueba = source_pois[source_pois.code == 2233]\n",
    "    \n",
    "    source_nodes_time = aup.pois_time(G, nodes, edges, prueba, source, prox_measure,count_pois=(True,15))\n",
    "    \n",
    "    # Show\n",
    "    print(source_nodes_time.shape)\n",
    "    print(source_nodes_time.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6b1b6-d210-4d29-9512-426611728245",
   "metadata": {},
   "source": [
    "# FINISHES FUNCTIONS REDEVELOPMENT. CONTINUES SCRIPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fda9ae6-4642-4e01-8f01-0440356ce93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing source denue_restaurante_insitu.\n",
      "--- Downloading denue source pois code 722511 from db.\n",
      "--- Downloading denue source pois code 722512 from db.\n",
      "--- Downloading denue source pois code 722513 from db.\n",
      "--- Downloading denue source pois code 722514 from db.\n",
      "--- Downloading denue source pois code 722519 from db.\n",
      "--- 4926 denue_restaurante_insitu pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_restaurante_insitu.\n",
      "Starting time analysis for denue_restaurante_insitu.\n",
      "Starting range k = 1 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 2 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 3 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 4 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 5 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 6 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 7 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 8 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 9 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 10 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 11 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 12 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 13 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 14 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 15 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 16 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 17 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 18 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 19 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 20 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 21 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 22 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 23 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 24 of 25 for denue_restaurante_insitu.\n",
      "Starting range k = 25 of 25 for denue_restaurante_insitu.\n",
      "Finished time analysis for denue_restaurante_insitu.\n",
      "--- FINISHED source denue_restaurante_insitu. Mean city time = 27.0165546933015\n",
      "Analysing source denue_restaurante_llevar.\n",
      "--- Downloading denue source pois code 722516 from db.\n",
      "--- Downloading denue source pois code 722518 from db.\n",
      "--- Downloading denue source pois code 722517 from db.\n",
      "--- 1055 denue_restaurante_llevar pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_restaurante_llevar.\n",
      "Starting time analysis for denue_restaurante_llevar.\n",
      "Starting range k = 1 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 2 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 3 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 4 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 5 of 6 for denue_restaurante_llevar.\n",
      "Starting range k = 6 of 6 for denue_restaurante_llevar.\n",
      "Finished time analysis for denue_restaurante_llevar.\n",
      "--- FINISHED source denue_restaurante_llevar. Mean city time = 33.645540946448484\n",
      "Analysing source denue_bares.\n",
      "--- Downloading denue source pois code 722412 from db.\n",
      "--- 278 denue_bares pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_bares.\n",
      "Starting time analysis for denue_bares.\n",
      "Starting range k = 1 of 2 for denue_bares.\n",
      "Starting range k = 2 of 2 for denue_bares.\n",
      "Finished time analysis for denue_bares.\n",
      "--- FINISHED source denue_bares. Mean city time = 54.69010579237759\n",
      "Analysing source denue_cafe.\n",
      "--- Downloading denue source pois code 722515 from db.\n",
      "--- 957 denue_cafe pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_cafe.\n",
      "Starting time analysis for denue_cafe.\n",
      "Starting range k = 1 of 5 for denue_cafe.\n",
      "Starting range k = 2 of 5 for denue_cafe.\n",
      "Starting range k = 3 of 5 for denue_cafe.\n",
      "Starting range k = 4 of 5 for denue_cafe.\n",
      "Starting range k = 5 of 5 for denue_cafe.\n",
      "Finished time analysis for denue_cafe.\n",
      "--- FINISHED source denue_cafe. Mean city time = 30.951618707461428\n",
      "Analysing source sip_cancha.\n",
      "--- Getting clues/sip source pois code 93110 from previously downloaded.\n",
      "--- 25 sip_cancha pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_cancha.\n",
      "Starting time analysis for sip_cancha.\n",
      "Starting range k = 1 of 1 for sip_cancha.\n",
      "Finished time analysis for sip_cancha.\n",
      "--- FINISHED source sip_cancha. Mean city time = 131.6102281232431\n",
      "Analysing source sip_unidad_deportiva.\n",
      "--- Getting clues/sip source pois code 93111 from previously downloaded.\n",
      "--- 4 sip_unidad_deportiva pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_unidad_deportiva.\n",
      "Starting time analysis for sip_unidad_deportiva.\n",
      "Starting range k = 1 of 1 for sip_unidad_deportiva.\n",
      "Finished time analysis for sip_unidad_deportiva.\n",
      "--- FINISHED source sip_unidad_deportiva. Mean city time = 112.37620133313291\n",
      "Analysing source sip_espacio_publico.\n",
      "--- Getting clues/sip source pois code 9321 from previously downloaded.\n",
      "--- 272 sip_espacio_publico pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each sip_espacio_publico.\n",
      "Starting time analysis for sip_espacio_publico.\n",
      "Starting range k = 1 of 2 for sip_espacio_publico.\n",
      "Starting range k = 2 of 2 for sip_espacio_publico.\n",
      "Finished time analysis for sip_espacio_publico.\n",
      "--- FINISHED source sip_espacio_publico. Mean city time = 29.558058698670447\n",
      "Analysing source denue_parque_natural.\n",
      "--- Downloading denue source pois code 712190 from db.\n",
      "--- 0 denue_parque_natural pois. Analysing source pois proximity to nodes.\n",
      "0 denue_parque_natural found. Time set to np.nan for all nodes.\n",
      "0 denue_parque_natural found. Pois count set to nan for all nodes.\n",
      "--- FINISHED source denue_parque_natural. Mean city time = nan\n",
      "Analysing source denue_cines.\n",
      "--- Downloading denue source pois code 512130 from db.\n",
      "--- 9 denue_cines pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_cines.\n",
      "Starting time analysis for denue_cines.\n",
      "Starting range k = 1 of 1 for denue_cines.\n",
      "Finished time analysis for denue_cines.\n",
      "--- FINISHED source denue_cines. Mean city time = 105.6534675560215\n",
      "Analysing source denue_museos.\n",
      "--- Downloading denue source pois code 712111 from db.\n",
      "--- Downloading denue source pois code 712112 from db.\n",
      "--- 14 denue_museos pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_museos.\n",
      "Starting time analysis for denue_museos.\n",
      "Starting range k = 1 of 1 for denue_museos.\n",
      "Finished time analysis for denue_museos.\n",
      "--- FINISHED source denue_museos. Mean city time = 128.87819266239387\n",
      "Analysing source denue_bibliotecas.\n",
      "--- Downloading denue source pois code 519121 from db.\n",
      "--- Downloading denue source pois code 519122 from db.\n",
      "--- 29 denue_bibliotecas pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_bibliotecas.\n",
      "Starting time analysis for denue_bibliotecas.\n",
      "Starting range k = 1 of 1 for denue_bibliotecas.\n",
      "Finished time analysis for denue_bibliotecas.\n",
      "--- FINISHED source denue_bibliotecas. Mean city time = 61.859031476080055\n",
      "Analysing source denue_centrocultural.\n",
      "--- Downloading denue source pois code 711312 from db.\n",
      "--- 18 denue_centrocultural pois. Analysing source pois proximity to nodes.\n",
      "Found and assigned nearest node osmid to each denue_centrocultural.\n",
      "Starting time analysis for denue_centrocultural.\n",
      "Starting range k = 1 of 1 for denue_centrocultural.\n",
      "Finished time analysis for denue_centrocultural.\n",
      "--- FINISHED source denue_centrocultural. Mean city time = 95.74208895980841\n",
      "FINISHED source pois proximity to nodes analysis for Aguascalientes.\n",
      "(51434, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>denue_restaurante_insitu</th>\n",
       "      <th>denue_restaurante_insitu_15min</th>\n",
       "      <th>denue_restaurante_llevar</th>\n",
       "      <th>denue_restaurante_llevar_15min</th>\n",
       "      <th>denue_bares</th>\n",
       "      <th>denue_bares_15min</th>\n",
       "      <th>denue_cafe</th>\n",
       "      <th>denue_cafe_15min</th>\n",
       "      <th>sip_cancha</th>\n",
       "      <th>...</th>\n",
       "      <th>denue_cines_15min</th>\n",
       "      <th>denue_museos</th>\n",
       "      <th>denue_museos_15min</th>\n",
       "      <th>denue_bibliotecas</th>\n",
       "      <th>denue_bibliotecas_15min</th>\n",
       "      <th>denue_centrocultural</th>\n",
       "      <th>denue_centrocultural_15min</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272921360</td>\n",
       "      <td>0.58794</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.097719</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.25473</td>\n",
       "      <td>21.0</td>\n",
       "      <td>156.885198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.589368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.761478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102.295073</td>\n",
       "      <td>21.872876</td>\n",
       "      <td>POINT (-102.29507 21.87288)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       osmid  denue_restaurante_insitu  denue_restaurante_insitu_15min  \\\n",
       "0  272921360                   0.58794                           132.0   \n",
       "\n",
       "   denue_restaurante_llevar  denue_restaurante_llevar_15min  denue_bares  \\\n",
       "0                       0.0                            13.0     4.097719   \n",
       "\n",
       "   denue_bares_15min  denue_cafe  denue_cafe_15min  sip_cancha  ...  \\\n",
       "0               18.0     5.25473              21.0  156.885198  ...   \n",
       "\n",
       "   denue_cines_15min  denue_museos  denue_museos_15min  denue_bibliotecas  \\\n",
       "0                0.0      7.589368                 1.0          17.761478   \n",
       "\n",
       "   denue_bibliotecas_15min  denue_centrocultural  denue_centrocultural_15min  \\\n",
       "0                      0.0             15.222128                         0.0   \n",
       "\n",
       "            x          y                     geometry  \n",
       "0 -102.295073  21.872876  POINT (-102.29507 21.87288)  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 --------------- ANALYSE POINTS OF INTEREST (If denue, downloads)\n",
    "# ------------------- This step analysis times (and count of pois at given time proximity if requested) using function aup.pois_time.\n",
    "\n",
    "poly_wkt = aoi.dissolve().geometry.to_wkt()[0]\n",
    "\n",
    "i = 0\n",
    "analysis_cols = []\n",
    "\n",
    "for eje in parameters.keys():\n",
    "    for amenity in parameters[eje]:\n",
    "        for source in parameters[eje][amenity]:\n",
    "\n",
    "            print(f\"\"\"Analysing source {source}.\"\"\")\n",
    "            \n",
    "            analysis_cols.append(source)\n",
    "            if count_pois[0]:\n",
    "                count_col = f'{source}_{count_pois[1]}min'\n",
    "                analysis_cols.append(count_col)\n",
    "            \n",
    "            # ANALYSIS - Select source points of interest\n",
    "            source_pois = gpd.GeoDataFrame()\n",
    "            for code in parameters[eje][amenity][source]:\n",
    "                #If source is denue:\n",
    "                if source[0] == 'd':\n",
    "                    print(f'--- Downloading denue source pois code {code} from db.')\n",
    "                    code_pois = get_denue_pois(denue_schema,denue_table,poly_wkt,code,version)\n",
    "                #If source is clues or sip:\n",
    "                elif source[0] == 'c' or source[0] == 's':\n",
    "                    print(f'--- Getting clues/sip source pois code {code} from previously downloaded.')\n",
    "                    code_pois = sip_clues_gdf.loc[sip_clues_gdf['code'] == code]\n",
    "                else:\n",
    "                    print(f'--- Error, check parameters dicctionary.')\n",
    "                    print(f'--- Sources must start with denue_, clues_ or sip_.')\n",
    "                    intended_crash\n",
    "                    \n",
    "                source_pois = pd.concat([source_pois,code_pois])\n",
    "\n",
    "            print(f\"--- {source_pois.shape[0]} {source} pois. Analysing source pois proximity to nodes.\")\n",
    "            \n",
    "            # ANALYSIS - Calculate times from nodes to source\n",
    "            source_nodes_time = aup.pois_time(G, nodes, edges, source_pois, source, prox_measure,count_pois)\n",
    "            source_nodes_time.rename(columns={'time_'+source:source},inplace=True)\n",
    "            if count_pois[0]:\n",
    "                source_nodes_time = source_nodes_time[['osmid',source,count_col,'x','y','geometry']]\n",
    "            else:\n",
    "                source_nodes_time = source_nodes_time[['osmid',source,'x','y','geometry']]\n",
    "\n",
    "            # ANALYSIS - Merge all times in one df\n",
    "            if i == 0: # For the first analysed source\n",
    "                nodes_analysis = source_nodes_time.copy()\n",
    "            else: # For the rest\n",
    "                if count_pois[0]:\n",
    "                    nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source,count_col]],on='osmid')\n",
    "                else:\n",
    "                    nodes_analysis = pd.merge(nodes_analysis,source_nodes_time[['osmid',source]],on='osmid')\n",
    "\n",
    "            i = i+1\n",
    "\n",
    "            print(f\"--- FINISHED source {source}. Mean city time = {nodes_analysis[source].mean()}\")\n",
    "        \n",
    "# Final format for nodes\n",
    "column_order = ['osmid'] + analysis_cols + ['x','y','geometry']\n",
    "nodes_analysis = nodes_analysis[column_order]\n",
    "\n",
    "print(f\"\"\"FINISHED source pois proximity to nodes analysis for {city}.\"\"\")\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis.shape)\n",
    "nodes_analysis.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5160cc8b-e34a-4567-8cce-d5461777d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################### PART 2 ###############################################################\n",
    "######################################################### AMENITIES ANALYSIS #########################################################\n",
    "######################################################### (PREV. SCRIPT 15) ##########################################################\n",
    "\n",
    "# 2.0 --------------- DEFINITIONS DICTIONARY\n",
    "# ------------------- On script 15 a dictionary (idx_15_min) is used to calculate the times to amenities.\n",
    "# ------------------- This step creates the definitions dicc out of the main parameters dicc.\n",
    "\n",
    "definitions = {}\n",
    "for eje in parameters.keys():\n",
    "    # tmp_dicc is {amenity:[source_list]} for each eje\n",
    "    tmp_dicc = {}\n",
    "    for amenity in parameters[eje]:\n",
    "        items_lst = []\n",
    "        items = list(parameters[eje][amenity].items())\n",
    "        for item in items:\n",
    "            items_lst.append(item[0])\n",
    "        tmp_dicc[amenity] = items_lst\n",
    "    # Each eje gets assigned its own tmp_dicc\n",
    "    definitions[eje] = tmp_dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48344a57-652f-42c8-b5f7-cf2552f9d811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished missing source amenities analysis. 0 not present source amenities were added as np.nan columns.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 --------------- FILL FOR MISSING AMENITIES\n",
    "# ------------------- This step originates on script 15, where each cities nodes time data was loaded from db.\n",
    "# ------------------- Even though its no longer needed, it remains usefull for avoiding crashes.\n",
    "# ------------------- Definitions dicc (Previously, on script 15, called idx_15_min dictionary) is also used in the next steps.\n",
    "\n",
    "all_sources = []\n",
    "# Gather all possible sources\n",
    "for eje in definitions.keys():\n",
    "    for amenity in definitions[eje].values():\n",
    "        for source in amenity:\n",
    "            all_sources.append(source)\n",
    "\n",
    "# If source not in currently analized city, fill column with np.nan\n",
    "column_list = list(nodes_analysis.columns)\n",
    "missing_sourceamenities = []\n",
    "for s in all_sources:\n",
    "        if s not in column_list:\n",
    "            nodes_analysis[s] = np.nan\n",
    "            print(f\"--- {s} source amenity is not present in {city}.\")\n",
    "            missing_sourceamenities.append(s)\n",
    "print(f\"--- Finished missing source amenities analysis. {len(missing_sourceamenities)} not present source amenities were added as np.nan columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcef1ac7-9030-4fd9-b777-7d5a164439d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting proximity to amenities analysis by node.\n",
      "--- Calculated proximity to amenities data by node.\n",
      "(51434, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.222128</td>\n",
       "      <td>5.254730</td>\n",
       "      <td>5.692959</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>272921360</td>\n",
       "      <td>POINT (-102.29507 21.87288)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.979920</td>\n",
       "      <td>6.647844</td>\n",
       "      <td>8.243084</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>272921393</td>\n",
       "      <td>POINT (-102.29510 21.87141)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            15.222128    5.254730              5.692959     15.222128   \n",
       "1            12.979920    6.647844              8.243084     12.979920   \n",
       "\n",
       "    max_time      osmid                     geometry  \n",
       "0  15.222128  272921360  POINT (-102.29507 21.87288)  \n",
       "1  12.979920  272921393  POINT (-102.29510 21.87141)  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2a -------------- AMENITIES ANALYSIS (amenities, ejes and max_time calculation)\n",
    "# ------------------- This step calculates times by amenity (preescolar/primaria/etc) using the previously created \n",
    "# ------------------- definitions dictionary (Previously, on script 15, called idx_15_min dictionary)\n",
    "# ------------------- and using weights dictionary to decide which time to use (min/max/other)\n",
    "\n",
    "print(\"--- Starting proximity to amenities analysis by node.\")\n",
    "\n",
    "column_max_all = [] # list with all max times column names\n",
    "column_max_ejes = [] # list with ejes max times column names\n",
    "\n",
    "#Goes through each eje in dictionary:\n",
    "for e in definitions.keys():\n",
    "\n",
    "    #Appends to lists currently examined eje\n",
    "    column_max_all.append('max_'+ e.lower())\n",
    "    column_max_ejes.append('max_'+ e.lower())\n",
    "    column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "    #Goes through each amenity of current eje:\n",
    "    for a in definitions[e].keys():\n",
    "\n",
    "        #Appends to lists currently examined amenity:\n",
    "        column_max_all.append('max_'+ a.lower())\n",
    "        column_max_amenities.append('max_'+ a.lower())\n",
    "\n",
    "        #Calculates time to currently examined amenity:\n",
    "        #Uses source_weight dictionary to decide which time to use.\n",
    "        weight = source_weight[e][a]\n",
    "        if weight == 'min': # To know distance to closest source amenity.\n",
    "                            # If it doesn't matter which one is closest (e.g. Alimentos).\n",
    "            nodes_analysis['max_'+ a.lower()] = nodes_analysis[definitions[e][a]].min(axis=1)\n",
    "\n",
    "        elif weight == 'max': # To know distance to farthest source amenity.\n",
    "                              # If need to know proximity to all of the options (e.g. Social)\n",
    "            nodes_analysis['max_'+ a.lower()] = nodes_analysis[definitions[e][a]].max(axis=1)\n",
    "\n",
    "        elif weight == 'two-method': #'two-method' (for cultural amenity's sources).\n",
    "                                     # See two_method_check function definition for explanation.\n",
    "            # Check which sources are within 15 minutes\n",
    "            check_lst = []\n",
    "            for s in definitions[e][a]:\n",
    "                nodes_analysis[s+'_check'] = nodes_analysis[s].apply(lambda x: 1 if x <= 15 else 0)\n",
    "                check_lst.append(s+'_check')\n",
    "            # Check how many sources are within 15 minutes\n",
    "            nodes_analysis['check_count'] = nodes_analysis[check_lst].sum(axis=1)\n",
    "            # Apply two method check\n",
    "            nodes_analysis = nodes_analysis.apply(two_method_check,axis='columns')\n",
    "            # Drop columns used for checking\n",
    "            check_lst.append('check_count')\n",
    "            nodes_analysis.drop(columns=check_lst,inplace=True)\n",
    "        else:\n",
    "            # Crash on purpose and raise error\n",
    "            print(\"--- Error in source_weight dicc.\")\n",
    "            print(\"--- Must pass 'min', 'max' or 'two-method'\")\n",
    "            intended_crash\n",
    "\n",
    "    #Calculates time to currently examined eje (max time of its amenities):\n",
    "    nodes_analysis['max_'+ e.lower()] = nodes_analysis[column_max_amenities].max(axis=1) \n",
    "\n",
    "# Set and calculate max time\n",
    "index_column = 'max_time' # column name for maximum time data\n",
    "column_max_all.append(index_column) #Adds to column_max_all list the attribute 'max_time'\n",
    "nodes_analysis[index_column] = nodes_analysis[column_max_ejes].max(axis=1) #Assigns \"max_time\" the max time for all ejes   \n",
    "\n",
    "# Add to column_max_all list the attributes 'osmid' and 'geometry' to filter nodes_analysis.\n",
    "# Looking for data of importance: columns in column_max_all list\n",
    "column_max_all.append('osmid')\n",
    "column_max_all.append('geometry')\n",
    "nodes_timeanalysis_filter = nodes_analysis[column_max_all].copy()\n",
    "    \n",
    "print(\"--- Calculated proximity to amenities data by node.\")\n",
    "\n",
    "# Show\n",
    "print(nodes_timeanalysis_filter.shape)\n",
    "nodes_timeanalysis_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98e55505-041f-4ebd-9e34-acdaaef1a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51434, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>osmid</th>\n",
       "      <th>geometry</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.222128</td>\n",
       "      <td>5.254730</td>\n",
       "      <td>5.692959</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>15.222128</td>\n",
       "      <td>272921360</td>\n",
       "      <td>POINT (-102.29507 21.87288)</td>\n",
       "      <td>188.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.979920</td>\n",
       "      <td>6.647844</td>\n",
       "      <td>8.243084</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>12.979920</td>\n",
       "      <td>272921393</td>\n",
       "      <td>POINT (-102.29510 21.87141)</td>\n",
       "      <td>209.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            15.222128    5.254730              5.692959     15.222128   \n",
       "1            12.979920    6.647844              8.243084     12.979920   \n",
       "\n",
       "    max_time      osmid                     geometry  entretenimiento_15min  \\\n",
       "0  15.222128  272921360  POINT (-102.29507 21.87288)                  188.0   \n",
       "1  12.979920  272921393  POINT (-102.29510 21.87141)                  209.0   \n",
       "\n",
       "   social_15min  actividad física_15min  cultural_15min  \n",
       "0         184.0                     3.0             1.0  \n",
       "1         204.0                     3.0             2.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2b -------------- AMENITIES COUNT ANALYSIS (amenities at given time count, optional)\n",
    "# ------------------- Similar to previous amenities analysis, this step (optional, added later)\n",
    "# ------------------- calculates how many amenities there are at a given time proximity (count_pois = (Boolean,time))\n",
    "\n",
    "if count_pois[0]:\n",
    "    column_count_all = []\n",
    "    \n",
    "    # Go through each eje\n",
    "    for eje in definitions.keys():\n",
    "        # Name of count eje\n",
    "        eje_count_colname = f'{eje}_{count_pois[1]}min'.lower()\n",
    "        # Append to lists\n",
    "        column_count_all.append(eje_count_colname)\n",
    "    \n",
    "        # Go through eje's amenities\n",
    "        column_count_amenities = []\n",
    "        for amenity in definitions[eje]:\n",
    "            # Name of count amenity\n",
    "            amenity_count_colname = f'{amenity}_{count_pois[1]}min'.lower()\n",
    "            # Append to lists\n",
    "            column_count_all.append(amenity_count_colname)\n",
    "            column_count_amenities.append(amenity_count_colname)\n",
    "    \n",
    "            # Gather amenities sources\n",
    "            column_count_sources = [] # Just used for sum function, not added at final output\n",
    "            for source in definitions[eje][amenity]:\n",
    "                # Add to sources list\n",
    "                source_count_colname = f'{source}_{count_pois[1]}min'\n",
    "                column_count_sources.append(source_count_colname)\n",
    "            # Find sum of all sources found within given time of each node (For current amenity)\n",
    "            nodes_analysis[amenity_count_colname] = nodes_analysis[column_count_sources].sum(axis=1)\n",
    "    \n",
    "        # Find sum of all sources found within given time of each node (For current eje)\n",
    "        nodes_analysis[eje_count_colname] = nodes_analysis[column_count_amenities].sum(axis=1)\n",
    "    \n",
    "    # Filter for columns of interest\n",
    "    column_count_all.append('osmid')\n",
    "    nodes_countanalysis_filter = nodes_analysis[column_count_all]\n",
    "    nodes_analysis_filter = pd.merge(nodes_timeanalysis_filter,nodes_countanalysis_filter,on='osmid')\n",
    "\n",
    "else:\n",
    "    nodes_analysis_filter = nodes_timeanalysis_filter.copy()\n",
    "\n",
    "# Show\n",
    "print(nodes_analysis_filter.shape)\n",
    "nodes_analysis_filter.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67dfbd13-b343-4bec-b625-d08ef35313b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 --------------- POPULATION DATA\n",
    "# ------------------- This step (optional) loads hexagons with population data.\n",
    "######################################################################################################################################\n",
    "# ------------------- This steps final code must be reviewed according to new pop data names in the db.\n",
    "# ------------------- Currently, only hex_bins_pop_2020 is 8\n",
    "if pop_output:\n",
    "    res_list = [8]\n",
    "    print(f\"--- Set res_list to 8 only. pop_output currently only generates res 8 data.\")\n",
    "######################################################################################################################################\n",
    "\n",
    "if pop_output:\n",
    "    hex_socio_gdf = gpd.GeoDataFrame()\n",
    "    # Downloads hex_socio_gdf for city area\n",
    "    for res in res_list:\n",
    "        # Download\n",
    "        hex_pop_res = aup.gdf_from_polygon(aoi, pop_schema, pop_table, geom_col=\"geometry\")\n",
    "        hex_pop_res = hex_pop_res.set_crs(\"EPSG:4326\")\n",
    "        print(f\"--- Downloaded pop gdf res {res}.\")\n",
    "\n",
    "        # Format\n",
    "        hex_pop_res.rename(columns={f'hex_id_{res}':'hex_id'},inplace=True)\n",
    "        hex_pop_res['res'] = res\n",
    "        \n",
    "        # Calculate fields of interest\n",
    "        hex_pop_res_tmp = hex_pop_res.to_crs(\"EPSG:6372\")\n",
    "        hex_pop_res_tmp['dens_pob_ha'] = hex_pop_res_tmp['pobtot'] / (hex_pop_res_tmp.area / 10000)\n",
    "\n",
    "        # Merge calculated fields to hex_pop_res gdf\n",
    "        hex_pop_res_tmp = hex_pop_res_tmp[['hex_id','dens_pob_ha']]\n",
    "        hex_pop_res = pd.merge(hex_pop_res,hex_pop_res_tmp,on='hex_id')\n",
    "\n",
    "        # Save fields of interest for current res\n",
    "        pop_fields = ['pobtot','dens_pob_ha']\n",
    "        hex_socio_gdf = pd.concat([hex_socio_gdf,hex_pop_res[['hex_id','res']+pop_fields+['geometry']]])\n",
    "        print(f\"--- Saved pop gdf res {res}.\")\n",
    "\n",
    "    # Show\n",
    "    print(hex_socio_gdf.shape)\n",
    "    print(hex_socio_gdf.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93799231-f2a1-4844-ad31-11e2d72772cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resolution 7 removed from res_list. This res is not allowed in version 2.\n",
      "--- Resolution 12 removed from res_list. This res is not allowed in version 2.\n",
      "--- Loaded hexgrid of resolution 8.\n",
      "--- Grouped nodes data by hexagons res 8.\n",
      "--- Saved grouped data by hexagons res 8.\n",
      "--- Loaded hexgrid of resolution 9.\n",
      "--- Grouped nodes data by hexagons res 9.\n",
      "--- Saved grouped data by hexagons res 9.\n",
      "--- Loaded hexgrid of resolution 10.\n",
      "--- Grouped nodes data by hexagons res 10.\n",
      "--- Saved grouped data by hexagons res 10.\n",
      "--- Loaded hexgrid of resolution 11.\n",
      "--- Grouped nodes data by hexagons res 11.\n",
      "--- Saved grouped data by hexagons res 11.\n",
      "(58255, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  88498e3289fffff  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "    max_time  entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0  59.692444                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  res  \n",
       "0             0.0    8  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.4 --------------- GROUP DATA BY HEX\n",
    "# ------------------- This groups nodes data by hexagon.\n",
    "# ------------------- If pop output, uses previously created hexes. Else, creates hexgrid.\n",
    "\n",
    "# Prevent crashing from trying not allowed resolutions.\n",
    "checked_res_list = []\n",
    "if version == 1:\n",
    "    allowed_res = [8,9]\n",
    "    for res in res_list:\n",
    "        if res in allowed_res:\n",
    "            checked_res_list.append(res)\n",
    "        else:\n",
    "            print(f\"--- Resolution {res} removed from res_list. This res is not allowed in version {version}.\")\n",
    "elif version == 2:\n",
    "    allowed_res = [8,9,10,11]\n",
    "    for res in res_list:\n",
    "        if res in allowed_res:\n",
    "            checked_res_list.append(res)\n",
    "        else:\n",
    "            print(f\"--- Resolution {res} removed from res_list. This res is not allowed in version {version}.\")\n",
    "res_list = checked_res_list.copy()\n",
    "\n",
    "hex_idx = gpd.GeoDataFrame()\n",
    "for res in res_list:\n",
    "    # Load or create hexgrid\n",
    "    # If pop_output is true, loads previously created hexgrid with pop data\n",
    "    if pop_output:\n",
    "        # Load hexgrid\n",
    "        hex_pop = hex_socio_gdf.loc[hex_socio_gdf['res'] == res]\n",
    "        # Function group_by_hex_mean requires ID to include resolution\n",
    "        hex_pop.rename(columns={'hex_id':f'hex_id_{res}'},inplace=True)\n",
    "        # Create hex_tmp (id and geometry)\n",
    "        hex_pop = hex_pop.to_crs(\"EPSG:4326\")\n",
    "        hex_tmp = hex_pop[[f'hex_id_{res}','geometry']].copy()\n",
    "        print(f\"--- Loaded pop hexgrid of resolution {res}.\")\n",
    "        \n",
    "    # If pop_output is false, creates hexgrid\n",
    "    else:\n",
    "        if version == 1:\n",
    "            hex_table = f'hexgrid_{res}_city'\n",
    "            query = f\"SELECT * FROM {hex_schema}.{hex_table} WHERE \\\"metropolis\\\" LIKE \\'{city}\\'\"\n",
    "        elif version == 2:\n",
    "            hex_table = f'hexgrid_{res}_city_2020'\n",
    "            query = f\"SELECT * FROM {hex_schema}.{hex_table} WHERE \\\"city\\\" LIKE \\'{city}\\'\"\n",
    "        else:\n",
    "            print(\"--- Error in specified proximity analysis version.\")\n",
    "            print(\"--- Must pass integers 1 or 2.\")\n",
    "            intended_crash\n",
    "\n",
    "        # Load hexgrid (which already has ID_res)\n",
    "        hexgrid = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "        # Create hex_tmp\n",
    "        hex_tmp = hexgrid.set_crs(\"EPSG:4326\")\n",
    "        hex_tmp = hex_tmp[[f'hex_id_{res}','geometry']].copy()\n",
    "        print(f\"--- Loaded hexgrid of resolution {res}.\")\n",
    "    \n",
    "    # Group time data by hex\n",
    "    hex_res_idx = aup.group_by_hex_mean(nodes_analysis_filter, hex_tmp, res, index_column)\n",
    "    hex_res_idx = hex_res_idx.loc[hex_res_idx[index_column]>0].copy()\n",
    "    print(f\"--- Grouped nodes data by hexagons res {res}.\")\n",
    "    \n",
    "    # If pop_output is true, add pop data\n",
    "    if pop_output:\n",
    "        pop_list = pop_fields.copy()\n",
    "        pop_list.append(f'hex_id_{res}')\n",
    "        hex_res_pop = pd.merge(hex_res_idx, hex_pop[pop_list], on=f'hex_id_{res}')\n",
    "    else:\n",
    "        hex_res_pop = hex_res_idx.copy()\n",
    "    \n",
    "    # After funtion group_by_hex_mean we can remove res from ID and set as a column\n",
    "    hex_res_pop.rename(columns={f'hex_id_{res}':'hex_id'},inplace=True)\n",
    "    hex_res_pop['res'] = res\n",
    "\n",
    "    # Finally, add to hex_idx each resolution processing\n",
    "    hex_idx = pd.concat([hex_idx,hex_res_pop])\n",
    "    print(f\"--- Saved grouped data by hexagons res {res}.\")\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5a7e222-9f4d-471e-a2c6-9c2ee9e20b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished recalculating ejes times in hexagons.\n",
      "(58255, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  88498e3289fffff  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "    max_time  entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0  59.692444                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  res  \n",
       "0             0.0    8  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################### PART 3 ###############################################################\n",
    "#################################################### RECALCULATION AND FINAL DATA ####################################################\n",
    "#################################################### (PREV. SCRIPT 15 + NEW DATA) ####################################################\n",
    "\n",
    "# 3.1 --------------- RE-CALCULATE MAX TIMES BY HEXAGON\n",
    "# ------------------- This step recalculates max time to each eje  \n",
    "# ------------------- from max times to calculated amenities \n",
    "\n",
    "#Goes (again) through each eje in dictionary:\n",
    "for e in definitions.keys():\n",
    "    column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "    #Goes (again) through each amenity of current eje:    \n",
    "    for a in definitions[e].keys():\n",
    "        column_max_amenities.append('max_'+ a.lower())\n",
    "    #Re-calculates time to currently examined eje (max time of its amenities):        \n",
    "    hex_idx['max_'+ e.lower()] = hex_idx[column_max_amenities].max(axis=1)\n",
    "\n",
    "print('--- Finished recalculating ejes times in hexagons.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea87895f-03d2-4fe0-a73a-fadbcbdbcc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished calculating index, mean, median and max time.\n",
      "(58255, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>max_time</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>res</th>\n",
       "      <th>idx_social</th>\n",
       "      <th>idx_actividad física</th>\n",
       "      <th>idx_cultural</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>idx_sum</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01275</td>\n",
       "      <td>0.248565</td>\n",
       "      <td>0.199486</td>\n",
       "      <td>45.576902</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>0.460801</td>\n",
       "      <td>Aguascalientes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id                                           geometry  \\\n",
       "0  88498e3289fffff  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "    max_time  entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0  59.692444                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  res  idx_social  idx_actividad física  idx_cultural  \\\n",
       "0             0.0    8     0.01275              0.248565      0.199486   \n",
       "\n",
       "   mean_time  median_time   idx_sum            city  \n",
       "0  45.576902    39.485914  0.460801  Aguascalientes  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 --------------- CALCULATE AND ADD ADDITIONAL AND FINAL DATA\n",
    "# ------------------- This step adds mean, median, city and idx data to each hex\n",
    "\n",
    "#Define idx function\n",
    "def apply_sigmoidal(x):\n",
    "    if x == -1:\n",
    "        return -1\n",
    "    elif x > 1000:\n",
    "        return 0\n",
    "    else:\n",
    "        val = aup.sigmoidal_function(0.1464814753435666, x, 30)\n",
    "        return val\n",
    "\n",
    "# Create all amenities list (previosly we had amenities list by eje) from column_max_ejes\n",
    "max_amenities_cols = [i for i in column_max_all if i not in column_max_ejes]\n",
    "max_amenities_cols.remove('max_time')\n",
    "max_amenities_cols.remove('osmid')\n",
    "max_amenities_cols.remove('geometry')\n",
    "# Create list with idx column names\n",
    "idx_amenities_cols = []\n",
    "for ac in max_amenities_cols:\n",
    "    idx_col = ac.replace('max','idx')\n",
    "    hex_idx[idx_col] = hex_idx[ac].apply(apply_sigmoidal)\n",
    "    idx_amenities_cols.append(idx_col)\n",
    "# Add final data\n",
    "hex_idx[index_column] = hex_idx[column_max_ejes].max(axis=1)\n",
    "hex_idx['mean_time'] = hex_idx[max_amenities_cols].mean(axis=1)\n",
    "hex_idx['median_time'] = hex_idx[max_amenities_cols].median(axis=1)\n",
    "hex_idx['idx_sum'] = hex_idx[idx_amenities_cols].sum(axis=1)\n",
    "hex_idx['city'] = city\n",
    "\n",
    "print('--- Finished calculating index, mean, median and max time.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx.shape)\n",
    "hex_idx.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6dfc035-4a3b-42e2-9b56-ef9c397df84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finished final format for gdf.\n",
      "(58255, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>res</th>\n",
       "      <th>geometry</th>\n",
       "      <th>max_entretenimiento</th>\n",
       "      <th>max_social</th>\n",
       "      <th>max_actividad física</th>\n",
       "      <th>max_cultural</th>\n",
       "      <th>entretenimiento_15min</th>\n",
       "      <th>social_15min</th>\n",
       "      <th>actividad física_15min</th>\n",
       "      <th>cultural_15min</th>\n",
       "      <th>idx_social</th>\n",
       "      <th>idx_actividad física</th>\n",
       "      <th>idx_cultural</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>idx_sum</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88498e3289fffff</td>\n",
       "      <td>8</td>\n",
       "      <td>POLYGON ((-102.16756 21.82626, -102.16297 21.8...</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>37.552347</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01275</td>\n",
       "      <td>0.248565</td>\n",
       "      <td>0.199486</td>\n",
       "      <td>45.576902</td>\n",
       "      <td>39.485914</td>\n",
       "      <td>59.692444</td>\n",
       "      <td>0.460801</td>\n",
       "      <td>Aguascalientes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id  res                                           geometry  \\\n",
       "0  88498e3289fffff    8  POLYGON ((-102.16756 21.82626, -102.16297 21.8...   \n",
       "\n",
       "   max_entretenimiento  max_social  max_actividad física  max_cultural  \\\n",
       "0            59.692444   59.692444             37.552347     39.485914   \n",
       "\n",
       "   entretenimiento_15min  social_15min  actividad física_15min  \\\n",
       "0                    0.0           0.0                     0.0   \n",
       "\n",
       "   cultural_15min  idx_social  idx_actividad física  idx_cultural  mean_time  \\\n",
       "0             0.0     0.01275              0.248565      0.199486  45.576902   \n",
       "\n",
       "   median_time   max_time   idx_sum            city  \n",
       "0    39.485914  59.692444  0.460801  Aguascalientes  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3 --------------- FINAL FORMAT\n",
    "# ------------------- This step gives final format to the gdf\n",
    "\n",
    "# First elements of ordered column list - ID and geometry\n",
    "final_column_ordered_list = ['hex_id','res','geometry']\n",
    "\n",
    "# Second elements of ordered column list - max_ejes and max_amenities \n",
    "# removing max_time, osmid and geometry.\n",
    "column_max_ejes_amenities = column_max_all.copy()\n",
    "column_max_ejes_amenities.remove('max_time')\n",
    "column_max_ejes_amenities.remove('osmid')\n",
    "column_max_ejes_amenities.remove('geometry')\n",
    "final_column_ordered_list = final_column_ordered_list + column_max_ejes_amenities\n",
    "\n",
    "# Third elements of ordered column list - count pois columns (if requested)\n",
    "# removing osmid and geometry.\n",
    "if count_pois[0]:\n",
    "    third_elements = column_count_all.copy()\n",
    "    third_elements.remove(\"osmid\")\n",
    "    final_column_ordered_list = final_column_ordered_list + third_elements\n",
    "\n",
    "# Fourth elements of ordered list are listed in idx_amenities_cols\n",
    "final_column_ordered_list = final_column_ordered_list + idx_amenities_cols\n",
    "\n",
    "# Fifth elements of ordered list - Final mean, median, max and idx\n",
    "fifth_elements = ['mean_time', 'median_time', 'max_time', 'idx_sum']\n",
    "final_column_ordered_list = final_column_ordered_list + fifth_elements\n",
    "\n",
    "# Sixth elements - If pop is calculated - Pop data\n",
    "if pop_output:\n",
    "    final_column_ordered_list = final_column_ordered_list + pop_fields\n",
    "\n",
    "# Last element - City data\n",
    "final_column_ordered_list.append('city')\n",
    "\n",
    "# Filter/reorder final output    \n",
    "hex_idx_city = hex_idx[final_column_ordered_list]\n",
    "    \n",
    "print('--- Finished final format for gdf.')\n",
    "\n",
    "# Show\n",
    "print(hex_idx_city.shape)\n",
    "hex_idx_city.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fab92b30-759e-4ea9-8ca7-43c502eaee34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['max_entretenimiento', 'max_social', 'max_actividad física', 'max_cultural']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_max_ejes_amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f8320-9466-427d-bcf9-24231ee71b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS-10.0",
   "language": "python",
   "name": "gds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
