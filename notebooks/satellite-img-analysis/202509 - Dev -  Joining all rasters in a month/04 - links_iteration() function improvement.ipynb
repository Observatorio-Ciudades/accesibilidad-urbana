{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4c7415-7e36-4962-b385-d00ad208064d",
   "metadata": {},
   "source": [
    "# links_iteration() function improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ae4ef-bf81-4bca-ab74-eab46aea16fc",
   "metadata": {},
   "source": [
    "* __About the function:__ function links_iteration() allows for the merging of ALL available tiles within an area of interest from ALL AVAILABLE DATES within a month (Used as a backup each month when specific dates failed).\n",
    "* __Current challenge:__ Currently, function merges ALL available tiles for ALL available dates, meaning that some tiles are duplicated since they can be found on two or more dates.\n",
    "* __Objective:__ For the month processing inside links_iteration() to use include in the mosaic each unique tile once, the one with less clouds percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71690cc5-a635-489a-af04-6948aee73116",
   "metadata": {},
   "source": [
    "## __Import libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ee308b-f830-41f9-a8e0-e7b40bb345d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "current_path = Path().resolve()\n",
    "for parent in current_path.parents:\n",
    "    if parent.name == \"accesibilidad-urbana\":\n",
    "        module_path = str(parent)+'/'\n",
    "        break\n",
    "print(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca79e32d-a4b1-4b08-b7c2-515b28c1ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import aup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa48a5b-2d49-4014-9afc-2881b14a9fbb",
   "metadata": {},
   "source": [
    "## __From Script 19: Config notebook__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3db464-966a-48e1-a780-18c27b52baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Tuxtla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f795d939-c586-4da4-be1d-e335beb26b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/data/processed/tmp_ndvi/\n"
     ]
    }
   ],
   "source": [
    "band_name_dict = {'nir':[False], #If GSD(resolution) of band is different, set True.\n",
    "                  'red':[False], #If GSD(resolution) of band is different, set True.\n",
    "                  'eq':['(nir-red)/(nir+red)']}\n",
    "sat_query = {\"eo:cloud_cover\": {\"lt\": 15}}\n",
    "index_analysis = 'ndvi'\n",
    "tmp_dir = module_path + f'data/processed/tmp_{index_analysis}/'\n",
    "res = [8,11]\n",
    "freq = 'MS'\n",
    "start_date = '2018-12-01'\n",
    "end_date = '2018-12-31'\n",
    "satellite = \"sentinel-2-l2a\"\n",
    "\n",
    "print(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b58be-07ab-40e7-b193-6d468ba5b2e9",
   "metadata": {},
   "source": [
    "## __From Script 19: Main function__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4a6c1-152f-4295-b061-dba122d1d71c",
   "metadata": {},
   "source": [
    "### __Main function__ - Create hex_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c16b36-c2ee-40b0-a95b-ceb5cf0c1b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 517 hexagon features\n",
      "(517, 2)\n",
      "epsg:4326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id_8</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>886d23cee7fffff</td>\n",
       "      <td>POLYGON ((-93.28477 16.78872, -93.28038 16.791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>886d23ceadfffff</td>\n",
       "      <td>POLYGON ((-93.28904 16.78097, -93.28465 16.783...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hex_id_8                                           geometry\n",
       "0  886d23cee7fffff  POLYGON ((-93.28477 16.78872, -93.28038 16.791...\n",
       "1  886d23ceadfffff  POLYGON ((-93.28904 16.78097, -93.28465 16.783..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "### Create city area of interest with biggest hexs\n",
    "big_res = min(res)\n",
    "schema_hex = 'hexgrid'\n",
    "table_hex = f'hexgrid_{big_res}_city_2020'\n",
    "\n",
    "# Download hexagons with type=urban\n",
    "type = 'urban'\n",
    "query = f\"SELECT hex_id_{big_res},geometry FROM {schema_hex}.{table_hex} WHERE \\\"city\\\" = '{city}\\' AND \\\"type\\\" = '{type}\\'\"\n",
    "hex_urban = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "\n",
    "# Download hexagons with type=rural within 500m buffer\n",
    "poly = hex_urban.to_crs(\"EPSG:6372\").buffer(500).reset_index()\n",
    "poly = poly.to_crs(\"EPSG:4326\")\n",
    "poly_wkt = poly.dissolve().geometry.to_wkt()[0]\n",
    "type = 'rural'\n",
    "query = f\"SELECT hex_id_{big_res},geometry FROM {schema_hex}.{table_hex} WHERE \\\"city\\\" = '{city}\\' AND \\\"type\\\" = '{type}\\' AND (ST_Intersects(geometry, \\'SRID=4326;{poly_wkt}\\'))\"\n",
    "hex_rural = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "\n",
    "# Concatenate urban and rural hex\n",
    "hex_city = pd.concat([hex_urban, hex_rural])\n",
    "\n",
    "# Show\n",
    "print(f'Downloaded {len(hex_city)} hexagon features')\n",
    "print(hex_city.shape)\n",
    "print(hex_city.crs)\n",
    "hex_city.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bc1ab4-c91e-46c9-8259-357b3b3d07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_len = aup.download_raster_from_pc(hex_city, index_analysis, city, freq,\n",
    "#                                     start_date, end_date, tmp_dir, band_name_dict, \n",
    "#                                     query=sat_query, satellite=satellite,\n",
    "#                                     compute_unavailable_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa70989-4b46-4cfc-bad1-7bf1d73f5f70",
   "metadata": {},
   "source": [
    "### __b - download_raster_from_pc() Step by step debug__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe5d0df4-30ca-4d70-a312-b38d734c5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variables for argument compatibility inside download_raster_from_pc function\n",
    "gdf = hex_city.copy()\n",
    "query = sat_query.copy()\n",
    "projection_crs = \"EPSG:6372\"\n",
    "compute_unavailable_dates = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4864ca0a-bad1-4f7e-b0e1-8835650136d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting bounding coordinates from hexagons\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'Polygon',\n",
       " 'coordinates': [[[-92.94489058025344, 16.46369561811796],\n",
       "   [-93.3240041185877, 16.46369561811796],\n",
       "   [-93.3240041185877, 16.898143599183356],\n",
       "   [-92.94489058025344, 16.898143599183356],\n",
       "   [-92.94489058025344, 16.46369561811796]]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create area of interest coordinates from hexagons to download raster data\n",
    "print('Extracting bounding coordinates from hexagons')\n",
    "# Create buffer around hexagons\n",
    "poly = gdf.to_crs(projection_crs).buffer(500)\n",
    "poly = poly.to_crs(\"EPSG:4326\")\n",
    "poly = gpd.GeoDataFrame(geometry=poly).dissolve().geometry\n",
    "# Extract coordinates from polygon as DataFrame\n",
    "coord_val = poly.bounds\n",
    "# Get coordinates for bounding box\n",
    "n = coord_val.maxy.max()\n",
    "s = coord_val.miny.min()\n",
    "e = coord_val.maxx.max()\n",
    "w = coord_val.minx.min()\n",
    "\n",
    "# Set the coordinates for the area of interest\n",
    "area_of_interest = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [e, s],\n",
    "            [w, s],\n",
    "            [w, n],\n",
    "            [e, n],\n",
    "            [e, s],\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "area_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0d7262-9e64-4c28-b581-696102201a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining time of interest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2018-12-01/2018-12-31']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create time of interest (Creates a list for all to-be-analysed-months with structure [start_day/end_day,(...)])\n",
    "print('Defining time of interest')\n",
    "time_of_interest = aup.create_time_of_interest(start_date, end_date, freq=freq)\n",
    "time_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a52f6fb4-4e7f-4bc2-9fad-b1ecca3fe4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering items for time and area of interest\n",
      "Fetched 5 items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Item id=S2A_MSIL2A_20181229T163701_R083_T15QWU_20201008T135817>,\n",
       " <Item id=S2B_MSIL2A_20181227T164709_R126_T15QVU_20201008T133426>,\n",
       " <Item id=S2A_MSIL2A_20181222T164711_R126_T15QVU_20201008T120904>,\n",
       " <Item id=S2A_MSIL2A_20181212T164701_R126_T15QVU_20201008T092759>,\n",
       " <Item id=S2B_MSIL2A_20181204T163639_R083_T15QWU_20201008T072807>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather items for time and area of interest (Creates of list of available image items)\n",
    "print('Gathering items for time and area of interest')\n",
    "items = aup.gather_items(time_of_interest, area_of_interest, query=query, satellite=satellite)\n",
    "print(f'Fetched {len(items)} items')\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b0d9f8-9c8d-4068-8d3a-6adac17cd56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of interest composed of 2 tile: ['15QWU', '15QVU'].\n"
     ]
    }
   ],
   "source": [
    "# Count available tiles for area of interest (Creates a list of available tiles, inside create_raster_by_month() logs available tiles per date vs total of area of interest)\n",
    "aoi_tiles = []\n",
    "for i in items:\n",
    "    # Retrieve current tile\n",
    "    if satellite == \"sentinel-2-l2a\":\n",
    "        tile = i.properties['s2:mgrs_tile']\n",
    "    elif satellite == \"landsat-c2-l2\":\n",
    "        tile = i.properties['landsat:wrs_path']+i.properties['landsat:wrs_row']\n",
    "    # Append if first find\n",
    "    if tile not in aoi_tiles:\n",
    "        aoi_tiles.append(tile)\n",
    "print(f'Area of interest composed of {len(aoi_tiles)} tile: {aoi_tiles}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad0b0f2-bc5c-477b-8ca2-489a847c91f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking available tiles for area of interest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[datetime.date(2018, 12, 22),\n",
       " datetime.date(2018, 12, 27),\n",
       " datetime.date(2018, 12, 29),\n",
       " datetime.date(2018, 12, 12),\n",
       " datetime.date(2018, 12, 4)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Checking available tiles for area of interest')\n",
    "# df_clouds, date_list = arrange_items(items, satellite=satellite)\n",
    "df_tile, date_list = aup.available_datasets(items, satellite, query)\n",
    "# log(f\"{len(date_list)} dates available with avg {round(df_clouds['avg_cloud'].mean(),2)}% clouds.\")\n",
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d1335cf-2fc4-46d4-b6e1-e7a4925288c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15QWU_cloud</th>\n",
       "      <th>15QVU_cloud</th>\n",
       "      <th>avg_cloud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026137</td>\n",
       "      <td>0.026137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094669</td>\n",
       "      <td>0.094669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-29</th>\n",
       "      <td>1.988278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.988278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.698234</td>\n",
       "      <td>5.698234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-04</th>\n",
       "      <td>11.324791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.324791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            15QWU_cloud  15QVU_cloud  avg_cloud\n",
       "2018-12-22          NaN     0.026137   0.026137\n",
       "2018-12-27          NaN     0.094669   0.094669\n",
       "2018-12-29     1.988278          NaN   1.988278\n",
       "2018-12-12          NaN     5.698234   5.698234\n",
       "2018-12-04    11.324791          NaN  11.324791"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56613f66-251a-4060-88f4-09bea9db9320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dictionary from items\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{datetime.date(2018, 12, 29): {'nir': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/WU/2018/12/29/S2A_MSIL2A_20181229T163701_N0212_R083_T15QWU_20201008T135817.SAFE/GRANULE/L2A_T15QWU_A018384_20181229T164726/IMG_DATA/R10m/T15QWU_20181229T163701_B08_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D'],\n",
       "  'red': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/WU/2018/12/29/S2A_MSIL2A_20181229T163701_N0212_R083_T15QWU_20201008T135817.SAFE/GRANULE/L2A_T15QWU_A018384_20181229T164726/IMG_DATA/R10m/T15QWU_20181229T163701_B04_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D']},\n",
       " datetime.date(2018, 12, 27): {'nir': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/VU/2018/12/27/S2B_MSIL2A_20181227T164709_N0212_R126_T15QVU_20201008T133426.SAFE/GRANULE/L2A_T15QVU_A009447_20181227T164909/IMG_DATA/R10m/T15QVU_20181227T164709_B08_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D'],\n",
       "  'red': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/VU/2018/12/27/S2B_MSIL2A_20181227T164709_N0212_R126_T15QVU_20201008T133426.SAFE/GRANULE/L2A_T15QVU_A009447_20181227T164909/IMG_DATA/R10m/T15QVU_20181227T164709_B04_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D']},\n",
       " datetime.date(2018, 12, 22): {'nir': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/VU/2018/12/22/S2A_MSIL2A_20181222T164711_N0212_R126_T15QVU_20201008T120904.SAFE/GRANULE/L2A_T15QVU_A018284_20181222T165709/IMG_DATA/R10m/T15QVU_20181222T164711_B08_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D'],\n",
       "  'red': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/VU/2018/12/22/S2A_MSIL2A_20181222T164711_N0212_R126_T15QVU_20201008T120904.SAFE/GRANULE/L2A_T15QVU_A018284_20181222T165709/IMG_DATA/R10m/T15QVU_20181222T164711_B04_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D']},\n",
       " datetime.date(2018, 12, 12): {'nir': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/VU/2018/12/12/S2A_MSIL2A_20181212T164701_N0212_R126_T15QVU_20201008T092759.SAFE/GRANULE/L2A_T15QVU_A018141_20181212T165701/IMG_DATA/R10m/T15QVU_20181212T164701_B08_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D'],\n",
       "  'red': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/VU/2018/12/12/S2A_MSIL2A_20181212T164701_N0212_R126_T15QVU_20201008T092759.SAFE/GRANULE/L2A_T15QVU_A018141_20181212T165701/IMG_DATA/R10m/T15QVU_20181212T164701_B04_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D']},\n",
       " datetime.date(2018, 12, 4): {'nir': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/WU/2018/12/04/S2B_MSIL2A_20181204T163639_N0212_R083_T15QWU_20201008T072807.SAFE/GRANULE/L2A_T15QWU_A009118_20181204T164131/IMG_DATA/R10m/T15QWU_20181204T163639_B08_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D'],\n",
       "  'red': ['https://sentinel2l2a01.blob.core.windows.net/sentinel2-l2/15/Q/WU/2018/12/04/S2B_MSIL2A_20181204T163639_N0212_R083_T15QWU_20201008T072807.SAFE/GRANULE/L2A_T15QWU_A009118_20181204T164131/IMG_DATA/R10m/T15QWU_20181204T163639_B04_10m.tif?st=2025-10-09T20%3A36%3A01Z&se=2025-10-10T21%3A21%3A01Z&sp=rl&sv=2025-07-05&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-10-10T16%3A12%3A12Z&ske=2025-10-17T16%3A12%3A12Z&sks=b&skv=2025-07-05&sig=iHdlPlFhObAggUvLbdn7KUOG/ZT/HL63L25o4X4mIx4%3D']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary from links (assets_hrefs is a dict. of dates and links with structure {available_date:{band_n:[link]}})\n",
    "band_name_list = list(band_name_dict.keys())[:-1]\n",
    "assets_hrefs = aup.link_dict(band_name_list, items, date_list)\n",
    "print('Created dictionary from items')\n",
    "assets_hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d85029-541c-42dc-b383-4a60619fb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze available data according to raster properties (Creates df_len for the first time)\n",
    "df_len, missing_months = aup.df_date_links(assets_hrefs, start_date, end_date,\n",
    "                                       band_name_list, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cab24c86-5e90-455d-950c-c5398c32b321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>data_id</th>\n",
       "      <th>able_to_download</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  data_id  able_to_download\n",
       "0  2018     12        1               NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b922db-078c-4b98-a97e-c5ca94713358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for missing months, raises errors\n",
    "if compute_unavailable_dates:\n",
    "    aup.available_data_check(df_len, missing_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00b7a15-9833-4bc3-821b-ed959326b114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bounding box for raster cropping\n"
     ]
    }
   ],
   "source": [
    "# Raster cropping with bounding box from earlier\n",
    "bounding_box = gpd.GeoDataFrame(geometry=poly).envelope\n",
    "gdf_bb = gpd.GeoDataFrame(gpd.GeoSeries(bounding_box), columns=['geometry'])\n",
    "print('Created bounding box for raster cropping')\n",
    "\n",
    "# Create GeoDataFrame to test nan values in raster\n",
    "gdf_raster_test = gdf.to_crs(projection_crs).buffer(1)\n",
    "gdf_raster_test = gdf_raster_test.to_crs(\"EPSG:4326\")\n",
    "gdf_raster_test = gpd.GeoDataFrame(geometry=gdf_raster_test)#.dissolve() #Ignore to tests nans in each hex since ignoring available_datasets() filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1abd3b4e-1269-4f18-8b8d-0d48aa7cfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raster creation - Download raster data by month\n",
    "#print('Starting raster creation for specified time')\n",
    "#df_len = create_raster_by_month(df_len, index_analysis, city, tmp_dir,\n",
    "#                                band_name_dict,date_list, gdf_raster_test,\n",
    "#                                gdf_bb, area_of_interest, satellite, aoi_tiles,\n",
    "#                                query=query,compute_unavailable_dates=compute_unavailable_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9100c38-73fd-4fe4-9826-a0e07a030ce1",
   "metadata": {},
   "source": [
    "#### __b-01 - create_raster_by_month() Step by step debug__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15cfc104-f89c-45c5-a9c3-6f4592ecc050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4544e2f4-74ed-4508-9a65-65089541a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variables for argument compatibility inside create_raster_by_month() function\n",
    "aoi = area_of_interest.copy()\n",
    "sat = satellite\n",
    "time_exc_limit = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23529c2e-81cc-4ff2-b38a-897226114a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df_len doesn't already exist, save dataframe to temporary directory\n",
    "df_file_dir = tmp_dir+index_analysis+f'_{city}_dataframe.csv'\n",
    "if os.path.exists(df_file_dir) == False: # Or folder, will return true or false\n",
    "    df_len['able_to_download'] = np.nan\n",
    "    df_len['download_method'] = ''\n",
    "    df_len.to_csv(df_file_dir, index=False)\n",
    "\n",
    "# if temporary folder doesn't already exist, create folder to store temporary raster files by iteration\n",
    "tmp_raster_dir = tmp_dir+'temporary_files/'\n",
    "if os.path.exists(tmp_raster_dir) == False: # Or folder, will return true or false\n",
    "    os.mkdir(tmp_raster_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09a018c9-82fe-4c15-b575-3ee92b54992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time measurement for both processes\n",
    "import time\n",
    "processes = ['original','improved'] # 'original' or 'improved'\n",
    "df_time_processes = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "739c84cb-ce5d-4d71-ae6e-bbef51def205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " create_raster_by_month() - Tuxtla - Starting new analysis for 12/2018\n",
      "All dates: [datetime.date(2018, 12, 22), datetime.date(2018, 12, 27), datetime.date(2018, 12, 29), datetime.date(2018, 12, 12), datetime.date(2018, 12, 4)].\n",
      "Dates ordered: [datetime.date(2018, 12, 22) datetime.date(2018, 12, 27)\n",
      " datetime.date(2018, 12, 29) datetime.date(2018, 12, 12)\n",
      " datetime.date(2018, 12, 4)].\n",
      "NOTE: Month has all available tiles within area of interest.\n",
      "12/2018 - MONTH ITERATION 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [10:00<00:00, 600.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Process original elapsed: 599.67 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " create_raster_by_month() - Tuxtla - Starting new analysis for 12/2018\n",
      "All dates: [datetime.date(2018, 12, 22), datetime.date(2018, 12, 27), datetime.date(2018, 12, 29), datetime.date(2018, 12, 12), datetime.date(2018, 12, 4)].\n",
      "Dates ordered: [datetime.date(2018, 12, 22) datetime.date(2018, 12, 27)\n",
      " datetime.date(2018, 12, 29) datetime.date(2018, 12, 12)\n",
      " datetime.date(2018, 12, 4)].\n",
      "NOTE: Month has all available tiles within area of interest.\n",
      "12/2018 - MONTH ITERATION 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [04:16<00:00, 256.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Process improved elapsed: 254.30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for process in processes:\n",
    "    \n",
    "    # Iteration over df_len rows (months)\n",
    "    for i in tqdm(range(len(df_len)), position=0, leave=True):\n",
    "    \n",
    "        # read dataframe in each iteration in case of code crash\n",
    "        df_raster = pd.read_csv(df_file_dir, index_col=False)\n",
    "    \n",
    "        # binary id - checks if current month could be processed\n",
    "        checker = 0\n",
    "    \n",
    "        # gather month and year from df to save raster\n",
    "        month_ = df_raster.loc[df_raster.index==i].month.values[0]\n",
    "        year_ = df_raster.loc[df_raster.index==i].year.values[0]\n",
    "    \n",
    "        # check if current month's raster already exists\n",
    "        if f'{city}_{index_analysis}_{month_}_{year_}.tif' in os.listdir(tmp_dir):\n",
    "            print(f'\\n create_raster_by_month() - {city} - Raster for {month_}/{year_} already downloaded. Skipping to next month.')\n",
    "            df_raster.loc[i,'data_id'] = 11\n",
    "            df_raster.to_csv(df_file_dir, index=False)\n",
    "            continue\n",
    "    \n",
    "        # check if current month has available links or could be processed (in case of a crash)\n",
    "        if df_raster.iloc[i].data_id==0:\n",
    "            print(f'\\n create_raster_by_month() - {city} - Raster for {month_}/{year_} not available. Skipping to next month.')\n",
    "            # In case of a crash, could be reading month whose links were available but could not be processed (data_id turns to 0)\n",
    "            # In that case, 'download_method' is updated to 'could_not_process'.\n",
    "            # If not, it is the first time the month is being processed. Update to 'no_links_available'.\n",
    "            if df_raster.iloc[i].download_method != 'could_not_process':\n",
    "                df_raster.loc[i,'download_method'] = 'no_links_available'\n",
    "                df_raster.to_csv(df_file_dir, index=False)\n",
    "            continue\n",
    "    \n",
    "        print(f'\\n create_raster_by_month() - {city} - Starting new analysis for {month_}/{year_}')\n",
    "    \n",
    "        # creates time range for a specific month\n",
    "        sample_date = datetime(year_, month_, 1)\n",
    "        first_day = sample_date + relativedelta(day=1)\n",
    "        last_day = sample_date + relativedelta(day=31)\n",
    "        time_of_interest = [f\"{year_}-{month_:02d}-{first_day.day:02d}/{year_}\"+\n",
    "                            f\"-{month_:02d}-{last_day.day:02d}\"]\n",
    "    \n",
    "        # create dataframe\n",
    "        #df_links = pd.DataFrame.from_dict(assets_hrefs,\n",
    "        #                                orient='Index').reset_index().rename(columns={'index':'date'})\n",
    "    \n",
    "        # dates in current month according to cloud coverage\n",
    "        date_order = [True if (d.month == month_) and (d.year == year_) else False for d in date_list]\n",
    "        date_array = np.array(date_list)\n",
    "        date_filter = np.array(date_order)\n",
    "        dates_ordered = date_array[date_filter]\n",
    "        print(f\"All dates: {date_list}.\")\n",
    "        print(f\"Dates ordered: {dates_ordered}.\")\n",
    "        \n",
    "        # mosaic raster iterations (while loop tries max_iter_count times to process all available rasters (dates) in a month)\n",
    "        max_iter_count = 1\n",
    "        iter_count = 1\n",
    "        # create skip date list used to analyze null values in raster\n",
    "        skip_date_list = []\n",
    "        \n",
    "        while iter_count <= max_iter_count:\n",
    "        \n",
    "            # --- Gather updated links - Since links expire after some time, they are gathered at each iteration\n",
    "            # gather links for the date range from planetary computer\n",
    "            items = aup.gather_items(time_of_interest, aoi, query=query, satellite=sat)\n",
    "            # gather links from dates that are within date_list\n",
    "            assets_hrefs = aup.link_dict(band_name_list, items, date_list)\n",
    "        \n",
    "            # --- For current month's gathered links, check the total amount of unique tiles and compare to aoi_tiles (logs)\n",
    "            month_tiles = []\n",
    "            for item in items:\n",
    "                # if item's date is in assets_hrefs keys, check for unique tiles\n",
    "                if item.datetime.date() in list(assets_hrefs.keys()):\n",
    "                    # For sentinel-2-l2a, gather unique mgrs_tile values\n",
    "                    if sat == \"sentinel-2-l2a\":\n",
    "                        item_tile = item.properties['s2:mgrs_tile']\n",
    "                        if item_tile not in month_tiles:\n",
    "                            month_tiles.append(item_tile)\n",
    "                    # For landsat-c2-l2, gather unique wrs_path + wrs_row values\n",
    "                    elif sat == \"landsat-c2-l2\":\n",
    "                        item_tile = item.properties['landsat:wrs_path'] + item.properties['landsat:wrs_row']\n",
    "                        if item_tile not in month_tiles:\n",
    "                            month_tiles.append(item_tile)\n",
    "        \n",
    "            if len(aoi_tiles) > len(month_tiles):\n",
    "                print(f'NOTE: Insufficient tiles to cover area of interest. Needed: {len(aoi_tiles)}, available: {len(month_tiles)}.')\n",
    "                print(f'NOTE: Available tiles: {month_tiles}. Missing tiles: {list(set(aoi_tiles) - set(month_tiles))}.')\n",
    "            else:\n",
    "                print(f'NOTE: Month has all available tiles within area of interest.')\n",
    "            \n",
    "            # --- Analyze links in two ways: ordered by cloud coverage and all available links for the month\n",
    "            # Explanation: \n",
    "            # Since satellites pass over different areas on different dates, sometimes analysis by date results in missing data.\n",
    "            # To solve this, we gather all available links for the month and use them if the date ordered by cloud coverage does not pass the null test.\n",
    "            \n",
    "            # In order to avoid duplicating code, the links_iteration() function recieves most of the current function's arguments,\n",
    "            # while only specific links and dates data are changed.\n",
    "            common_args_dct = {'skip_date_list':skip_date_list, # List of dates to be skipped because null test failed\n",
    "                               'iter_count':iter_count, # Current iteration of current month (Used in logs)\n",
    "                               'time_exc_limit':time_exc_limit, # Specified time limit for downloading a raster\n",
    "                               'band_name_dict':band_name_dict, # Bands to be used in the raster analysis\n",
    "                               'gdf_bb':gdf_bb, # Crop the raster to a specific area of interest\n",
    "                               'tmp_raster_dir':tmp_raster_dir, # Folder to store temporary raster files by iteration\n",
    "                               'index_analysis':index_analysis, # Current type of analysis\n",
    "                               'gdf_raster_test':gdf_raster_test, # GeoDataFrame to test nan values in raster\n",
    "                               'tmp_dir':tmp_dir, # Temporary directory where temporary rasters are saved\n",
    "                               'city':city, # To save the raster files based on the area of interest's name\n",
    "                               'month_':month_, # Current month of dates being processed\n",
    "                               'year_':year_, # Current year of dates being processed\n",
    "                               'checker':checker, # Checker with value '0' if month has not being processed, 1 when processed\n",
    "                               }\n",
    "        \n",
    "            # --- LINKS ANALIZYS A - ORDERED ACCORDING TO CLOUD COVERAGE [PREFERRED]\n",
    "            # --- Gather updated links - Since links expire after some time, they are gathered at each iteration\n",
    "            # Create list of links ordered according to cloud coverage\n",
    "            \n",
    "            links_dicts_ordered_lst = []\n",
    "            for data_position in range(len(dates_ordered)):\n",
    "                current_link_dct = assets_hrefs[dates_ordered[data_position]]\n",
    "                links_dicts_ordered_lst.append(current_link_dct)\n",
    "            \n",
    "            a=\"\"\"\n",
    "            # Processing by ordered dates\n",
    "            ordered_links_try = 0 #Call the current position in dates_ordered\n",
    "            for bands_links in links_dicts_ordered_lst:\n",
    "                print(f\"{dates_ordered[ordered_links_try]} - ITERATION {iter_count} - DATE {ordered_links_try+1}/{len(links_dicts_ordered_lst)}.\")\n",
    "                skip_date_list, checker = aup.links_iteration(bands_links = bands_links,\n",
    "                                                          specific_date = (True, dates_ordered[ordered_links_try]),\n",
    "                                                          common_args_dct = common_args_dct\n",
    "                                                         )\n",
    "                # If succeded current date, stop ordered dates iterations\n",
    "                if checker==1:\n",
    "                    break\n",
    "                # Else, try next date\n",
    "                ordered_links_try += 1\n",
    "            # If succeded by any date, stop month's while loop (Doesn't try whole month's available links)\n",
    "            if checker==1:\n",
    "                download_method = 'specific_date'\n",
    "                break\n",
    "            \"\"\"\n",
    "\n",
    "            # Measure processes time consumption\n",
    "            start = time.time()\n",
    "            \n",
    "            if process == 'original':\n",
    "                # --- LINKS ANALIZYS B - WHOLE MONTH'S AVAILABLE LINKS [BACKUP]\n",
    "                # Create list of ALL available links for the month\n",
    "                links_dicts_month = {}\n",
    "                for current_link_dct in links_dicts_ordered_lst:\n",
    "                    for band, links in current_link_dct.items():\n",
    "                        if band not in links_dicts_month:\n",
    "                            links_dicts_month[band] = []  # Initialize list if band not in dictionary\n",
    "                        links_dicts_month[band].extend(links) # Append links to the list for the band\n",
    "                #print(links_dicts_month)\n",
    "                \n",
    "                # Processing all available links for the month\n",
    "                print(f\"{month_}/{year_} - MONTH ITERATION {iter_count}.\")\n",
    "                skip_date_list, checker = aup.links_iteration(bands_links = links_dicts_month,\n",
    "                                                          specific_date = (False, None),\n",
    "                                                          common_args_dct = common_args_dct\n",
    "                                                          )\n",
    "            elif process == 'improved':\n",
    "                # --- LINKS ANALIZYS B - WHOLE MONTH'S AVAILABLE LINKS [BACKUP]\n",
    "                # --- Gather updated links - Since links expire after some time, they are gathered at each iteration\n",
    "                # gather links for the date range from planetary computer\n",
    "                items = aup.gather_items(time_of_interest, aoi, query=query, satellite=sat)\n",
    "        \n",
    "                # --- From month's available links, select only the dates that have min cloud pct for each tile\n",
    "                # Re-create df_tile (tiles with cloud pct dataframe) for currently explored dates\n",
    "                df_tile_current, _ = aup.available_datasets(items, satellite, query)\n",
    "                # Drop 'avg_cloud' column\n",
    "                df_tile_current.drop(columns=['avg_cloud'],inplace=True)\n",
    "                # Drop all tile columns with no data (where mean is nan) and list the rest\n",
    "                df_tile_current = df_tile_current.drop(columns=df_tile_current.columns[df_tile_current.mean(skipna=True).isna()])\n",
    "                tiles_lst = df_tile_current.columns.to_list()\n",
    "                # Reset index to place date as a column\n",
    "                df_tile_current.reset_index(inplace=True)\n",
    "                df_tile_current.rename(columns={'index':'date'},inplace=True)\n",
    "                # For each tile, find the date where the clouds percentage is lowest and append date to perform month's analysis\n",
    "                dates_month_min_cloud = []\n",
    "                for tile in tiles_lst:\n",
    "                    mincloud_idx = df_tile_current[tile].min()\n",
    "                    mincloud_date = df_tile_current.loc[df_tile_current[tile]==mincloud_idx]['date'].unique()[0]\n",
    "                    dates_month_min_cloud.append(mincloud_date)\n",
    "                \n",
    "                # gather links from dates that are within dates_month_min_cloud\n",
    "                assets_hrefs = aup.link_dict(band_name_list, items, dates_month_min_cloud)\n",
    "        \n",
    "                # Create list of BEST available links for the month\n",
    "                links_dicts_month = {}\n",
    "                links_dicts_ordered_lst = []\n",
    "                for data_position in range(len(dates_month_min_cloud)):\n",
    "                    current_link_dct = assets_hrefs[dates_month_min_cloud[data_position]]\n",
    "                    for band, links in current_link_dct.items():\n",
    "                        if band not in links_dicts_month:\n",
    "                            links_dicts_month[band] = []  # Initialize list if band not in dictionary\n",
    "                        links_dicts_month[band].extend(links) # Append links to the list for the band\n",
    "                #print(links_dicts_month)\n",
    "                \n",
    "                # Processing all available links for the month\n",
    "                print(f\"{month_}/{year_} - MONTH ITERATION {iter_count}.\")\n",
    "                skip_date_list, checker = aup.links_iteration(bands_links = links_dicts_month,\n",
    "                                                          specific_date = (False, None),\n",
    "                                                          common_args_dct = common_args_dct\n",
    "                                                          )\n",
    "            # Measure processes time consumption\n",
    "            end = time.time()\n",
    "            print(f'Iteration {iter_count} Process {process} elapsed: {end - start:.2f} seconds.')\n",
    "            df_time_processes.loc[iter_count, process] = round(end-start,2)\n",
    "            \n",
    "            # If succeded whole month, stop while loop\n",
    "            if checker==1:\n",
    "                download_method = 'full_month'\n",
    "                break\n",
    "            # Else, try next iteration (If not reached max_iter_count)\n",
    "            iter_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5604835-2747-44fc-b16b-91b4d959fd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>599.67</td>\n",
       "      <td>254.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original  improved\n",
       "1    599.67     254.3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dba3d882-220f-48ed-a294-5ed8dbc614a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>620.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>613.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original\n",
       "1    619.86\n",
       "2    196.90\n",
       "3    620.18\n",
       "4    596.81\n",
       "5    613.94"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_time_processes_original = df_time_processes.copy()\n",
    "df_time_processes_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bea762c5-52d1-4b77-afb2-725602407d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>improved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>245.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   improved\n",
       "1    272.40\n",
       "2    252.80\n",
       "3    245.70\n",
       "4    245.33\n",
       "5    256.78"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6941ee-4ec0-431d-986a-8af4957be8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS-10.0",
   "language": "python",
   "name": "gds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
