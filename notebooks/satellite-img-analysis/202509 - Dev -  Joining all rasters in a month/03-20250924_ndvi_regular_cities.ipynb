{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34da882-1610-4e69-b6c2-dccff1960031",
   "metadata": {},
   "source": [
    "# NDVI regular cities running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d7dbc-eec1-455b-b03c-18ffbab57304",
   "metadata": {},
   "source": [
    "This notebook tries to __run all missing cities__ (identified on notebook 02_missing_ndvi_temp_cities) using an ordered city list that priorices cities with less tiles. Even though all missing cities will run download_raster_from_pc(), __only cities with no full_month processing (just specific_dates processing) will be processed to hexs and uploaded to the database.__\n",
    "\n",
    "* NOTE: Cities where no full_month processing is used couldn't be previously processed not because of the availability of tiles in specific_dates, but because of a __(fixed) bug in available_datasets()__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94261724-ea33-49a2-9555-07f5d11b310c",
   "metadata": {},
   "source": [
    "## Processing summary\n",
    "#### __Cities with no full_month processing, just specific_date processing:__\n",
    "__Logs 2025-09-24__\n",
    "* __Tuxtla__ (2 tiles) started with 40% missing, could not process 2/2021 and ended up with _Missing more than 50 percent of data points_ \n",
    "* __Piedad__ (2 tiles) started with 39% missing, and ended with 39% missing, [UPLOADED TO DB]\n",
    "* __Cordoba__ (2 tiles) started with 19% missing, ended with 26%,  [UPLOADED TO DB]\n",
    "* __Orizaba__ (2 tiles) started with 25% missing, ended with 26%,  [UPLOADED TO DB]\n",
    "* __Morelia__ (3 tiles) started with 18% missing, could not process 5/2018 and ended up with _Multiple missing months together_.\n",
    "* __Cancun__ (3 tiles) started with 11% missing, ended with 32% , [UPLOADED TO DB]\n",
    "* __Playa__ (3 tiles) started with 18% missing, could not process 10/2019 and ended up with _Multiple missing months together_.\n",
    "* __Culiacan__ (3 tiles) started with 1% missing, ended with 19%  [UPLOADED TO DB, BUT ERROR IN RES 11, FROM HEX SOURCE]\n",
    "\n",
    "__Logs 2025-09-25__\n",
    "* __Guaymas__ (3 tiles) started with 1% missing, ended with 8%  [UPLOADED TO DB]\n",
    "#### __Finally testing with this city:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21166f-6b16-4bbb-919a-46fbff441c66",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f97a65-60c1-42dd-bdbd-33111538ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "current_path = Path().resolve()\n",
    "for parent in current_path.parents:\n",
    "    if parent.name == \"accesibilidad-urbana\":\n",
    "        module_path = str(parent)+'/'\n",
    "        break\n",
    "print(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e469adc-da66-4153-87e0-f5d7df6ae108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import aup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f1b86-41ff-419b-8bb2-3136750c3985",
   "metadata": {},
   "source": [
    "## __Notebook config__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc6ab21-6522-4934-b7f4-5526623d40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing processing from\n",
    "ndvi_3_tiles = ['Tampico']\n",
    "ndvi_4_tiles = ['Campeche','Celaya','Guanajuato','Leon','Irapuato','SLP','Merida']\n",
    "city_list = ndvi_3_tiles + ndvi_4_tiles\n",
    "# Saving\n",
    "save_output_database = True\n",
    "save_output_locally = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72343e1e-ebd2-4af2-8cff-ecfaa1778180",
   "metadata": {},
   "source": [
    "## __NDVI config__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af39201-438a-4556-804f-4375734a1509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/accesibilidad-urbana/data/processed/tmp_ndvi/\n"
     ]
    }
   ],
   "source": [
    "band_name_dict = {'nir08':[False], #If GSD(resolution) of band is different, set True.\n",
    "                   'red':[False], #If GSD(resolution) of band is different, set True.\n",
    "                   'eq':['(nir08-red)/(nir08+red)']}\n",
    "query_sat = {\"eo:cloud_cover\": {\"lt\": 15},\n",
    "          \"platform\": {\"in\": [\"landsat-8\", \"landsat-9\"]}}\n",
    "index_analysis = 'ndvi'\n",
    "tmp_dir = module_path + f'data/processed/tmp_{index_analysis}/'\n",
    "res = [8,11]\n",
    "freq = 'MS'\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31'\n",
    "satellite = 'landsat-c2-l2'\n",
    "\n",
    "print(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809d1e0-24b3-41a8-bd21-0b5f2b3f256d",
   "metadata": {},
   "source": [
    "## __Secondary functions -__ raster_to_save_hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abbcb73d-01ad-4446-999d-de878748ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_hex_save(hex_gdf_i, df_len, index_analysis, tmp_dir, city, r, save, local_save=False, i=0):\n",
    "    print(f'Translating raster to hexagon for res: {r}')\n",
    "\n",
    "    hex_raster_analysis, df_raster_analysis = aup.raster_to_hex_analysis(hex_gdf_i, df_len, index_analysis,\n",
    "                                                                tmp_dir, city, r)\n",
    "    print('Finished assigning raster data to hexagons')\n",
    "    print(f'df nan values: {df_raster_analysis[index_analysis].isna().sum()}')\n",
    "    if df_raster_analysis[index_analysis].isna().sum() > 0:\n",
    "        raise NanValues('NaN values are still present after processing')\n",
    "    \n",
    "    # local save (test)\n",
    "    if local_save:\n",
    "        # Create folder to store local save\n",
    "        localsave_dir = tmp_dir+'local_save/'\n",
    "        if os.path.exists(localsave_dir) == False:\n",
    "            os.mkdir(localsave_dir)\n",
    "\n",
    "        # Local save\n",
    "        #hex_raster_analysis.to_file(tmp_dir+'local_save/'+f'{city}_{index_analysis}_HexRes{r}_v{i}.geojson')\n",
    "        df_raster_analysis.to_csv(localsave_dir+f'{city}_{index_analysis}_HexRes{r}_v{i}.csv')\n",
    "\n",
    "    # Save - upload to database\n",
    "    if save:\n",
    "        upload_chunk = 150000\n",
    "        print(f'Starting upload for res: {r}')\n",
    "\n",
    "        if r == 8:\n",
    "            # df upload\n",
    "            #aup.df_to_db_slow(df_raster_analysis, f'{index_analysis}_complete_dataset_hex',\n",
    "            #                'raster_analysis', if_exists='append', chunksize=upload_chunk)\n",
    "            # gdf upload\n",
    "            aup.gdf_to_db_slow(hex_raster_analysis, f'{index_analysis}_analysis_hex',\n",
    "                            'raster_analysis', if_exists='append')\n",
    "\n",
    "        else:\n",
    "            # df upload\n",
    "            #limit_len = 5000000\n",
    "            #if len(df_raster_analysis)>limit_len:\n",
    "            #    c_upload = len(df_raster_analysis)/limit_len\n",
    "            #    for k in range(int(c_upload)+1):\n",
    "            #        print(f\"Starting range k = {k} of {int(c_upload)}\")\n",
    "            #        df_inter_upload = df_raster_analysis.iloc[int(limit_len*k):int(limit_len*(1+k))].copy()\n",
    "            #        aup.df_to_db(df_inter_upload,f'{index_analysis}_complete_dataset_hex',\n",
    "            #                        'raster_analysis', if_exists='append')\n",
    "            #else:\n",
    "            #    aup.df_to_db(df_raster_analysis,f'{index_analysis}_complete_dataset_hex',\n",
    "            #                        'raster_analysis', if_exists='append')\n",
    "            # gdf upload\n",
    "            aup.gdf_to_db_slow(hex_raster_analysis, f'{index_analysis}_analysis_hex',\n",
    "                            'raster_analysis', if_exists='append')\n",
    "        print(f'Finished uploading data for res{r}')\n",
    "        \n",
    "    # delete variables\n",
    "    del df_raster_analysis\n",
    "    del hex_raster_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a364733-d324-45a7-859f-9982d0cc6a58",
   "metadata": {},
   "source": [
    "## __Main function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6ee23b-dc87-4309-8051-dfefc09071da",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_cities = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a62284-1677-41df-9f29-31b565aaac43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING Guaymas.\n",
      "Guaymas - Created hex_city.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 72/72 [00:00<00:00, 433.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guaymas - Created df_len.\n",
      "Guaymas - Started loading hexagons at different resolutions.\n",
      "Loaded hexgrid res 8\n",
      "Loaded hexgrid res 9\n",
      "Loaded hexgrid res 10\n",
      "Loaded hexgrid res 11\n",
      "Guaymas - Finished creating hexagons at different resolutions.\n",
      "---------------------------------------\n",
      "STARTING processing for resolution 8.\n",
      "hex_gdf len smaller than processing chunk\n",
      "Translating raster to hexagon for res: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                  | 0/6 [00:00<?, ?it/s]\n",
      " 17%|████████████████████▎                                                                                                     | 1/6 [00:01<00:05,  1.15s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      " 33%|████████████████████████████████████████▋                                                                                 | 2/6 [00:02<00:04,  1.06s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████████████████████████                                                             | 3/6 [00:03<00:03,  1.01s/it]\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL error: wrong version number\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL error: wrong version number\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL error: wrong version number\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL error: wrong version number\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL error: wrong version number\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL error: cipher operation failed\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL error: wrong version number\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 988, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 1438, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/opt/conda/envs/gds/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 692, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████▎                                        | 4/6 [00:04<00:02,  1.28s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:01<?, ?it/s]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 5/6 [00:07<00:01,  1.81s/it]\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning raster data to hexagons\n",
      "df nan values: 0\n",
      "Starting upload for res: 8\n",
      "Finished uploading data for res8\n",
      "---------------------------------------\n",
      "STARTING processing for resolution 9.\n",
      "hex_gdf len smaller than processing chunk\n",
      "Translating raster to hexagon for res: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                  | 0/6 [00:00<?, ?it/s]\n",
      " 17%|████████████████████▎                                                                                                     | 1/6 [00:04<00:23,  4.69s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:04<?, ?it/s]\u001b[A\u001b[A\n",
      " 33%|████████████████████████████████████████▋                                                                                 | 2/6 [00:09<00:19,  4.81s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:04<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████████████████████████                                                             | 3/6 [00:14<00:14,  4.92s/it]\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:05<?, ?it/s]\u001b[A\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████▎                                        | 4/6 [00:19<00:10,  5.05s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:05<?, ?it/s]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 5/6 [00:25<00:05,  5.34s/it]\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:05<?, ?it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:31<00:00,  5.21s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning raster data to hexagons\n",
      "df nan values: 0\n",
      "Starting upload for res: 9\n",
      "Finished uploading data for res9\n",
      "---------------------------------------\n",
      "STARTING processing for resolution 10.\n",
      "hex_gdf len smaller than processing chunk\n",
      "Translating raster to hexagon for res: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                  | 0/6 [00:00<?, ?it/s]\n",
      " 17%|████████████████████▎                                                                                                     | 1/6 [00:33<02:46, 33.25s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:33<?, ?it/s]\u001b[A\u001b[A\n",
      " 33%|████████████████████████████████████████▋                                                                                 | 2/6 [01:08<02:17, 34.32s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:35<?, ?it/s]\u001b[A\n",
      " 50%|█████████████████████████████████████████████████████████████                                                             | 3/6 [01:44<01:44, 34.98s/it]\n",
      "\n",
      "  0%|                                                                                                                                 | 0/12 [00:35<?, ?it/s]\u001b[A\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████▎                                        | 4/6 [02:20<01:10, 35.48s/it]\n",
      "  0%|                                                                                                                                 | 0/12 [00:36<?, ?it/s]             | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 5/6 [02:57<00:36, 36.11s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [00:37<?, ?it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [03:44<00:00, 37.36s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [00:46<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning raster data to hexagons\n",
      "df nan values: 0\n",
      "Starting upload for res: 10\n",
      "Finished uploading data for res10\n",
      "---------------------------------------\n",
      "STARTING processing for resolution 11.\n",
      "hex_gdf_res len: 75049 is bigger than processing chunk: 20000\n",
      "There are 4 processes\n",
      "Processing from 0 to 20000\n",
      "Translating raster to hexagon for res: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/6 [00:00<?, ?it/s]\n",
      " 17%|██████████████████████████▎                                                                                                                                   | 1/6 [01:25<07:08, 85.66s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:25<?, ?it/s]\u001b[A\u001b[A\n",
      " 33%|████████████████████████████████████████████████████▋                                                                                                         | 2/6 [02:49<05:39, 84.81s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:24<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 3/6 [04:10<04:09, 83.12s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:21<?, ?it/s]\u001b[A\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 4/6 [05:22<02:36, 78.50s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:11<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 5/6 [06:33<01:15, 75.80s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:11<?, ?it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [07:44<00:00, 77.42s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:11<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning raster data to hexagons\n",
      "df nan values: 0\n",
      "Starting upload for res: 11\n",
      "Finished uploading data for res11\n",
      "Processing from 20000 to 40000\n",
      "Translating raster to hexagon for res: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/6 [00:00<?, ?it/s]\n",
      " 17%|██████████████████████████▎                                                                                                                                   | 1/6 [01:12<06:00, 72.06s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:12<?, ?it/s]\u001b[A\u001b[A\n",
      " 33%|████████████████████████████████████████████████████▋                                                                                                         | 2/6 [02:26<04:54, 73.64s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:14<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 3/6 [03:50<03:54, 78.14s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:23<?, ?it/s]\u001b[A\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 4/6 [05:05<02:33, 76.98s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:15<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 5/6 [06:22<01:17, 77.11s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:17<?, ?it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [07:37<00:00, 76.31s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:15<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning raster data to hexagons\n",
      "df nan values: 0\n",
      "Starting upload for res: 11\n",
      "Finished uploading data for res11\n",
      "Processing from 40000 to 60000\n",
      "Translating raster to hexagon for res: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/6 [00:00<?, ?it/s]\n",
      " 17%|██████████████████████████▎                                                                                                                                   | 1/6 [01:12<06:03, 72.70s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:12<?, ?it/s]\u001b[A\u001b[A\n",
      " 33%|████████████████████████████████████████████████████▋                                                                                                         | 2/6 [02:27<04:54, 73.72s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:14<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 3/6 [03:43<03:44, 74.90s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:16<?, ?it/s]\u001b[A\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 4/6 [05:00<02:31, 75.82s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:17<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 5/6 [06:16<01:15, 75.72s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:15<?, ?it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [07:31<00:00, 75.18s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:14<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning raster data to hexagons\n",
      "df nan values: 0\n",
      "Starting upload for res: 11\n",
      "Finished uploading data for res11\n",
      "Processing from 60000 to 80000\n",
      "Translating raster to hexagon for res: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/6 [00:00<?, ?it/s]\n",
      " 17%|██████████████████████████▎                                                                                                                                   | 1/6 [01:02<05:11, 62.25s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:02<?, ?it/s]\u001b[A\u001b[A\n",
      " 33%|████████████████████████████████████████████████████▋                                                                                                         | 2/6 [02:05<04:12, 63.09s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:03<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 3/6 [03:22<03:27, 69.07s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:16<?, ?it/s]\u001b[A\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 4/6 [04:23<02:12, 66.11s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [01:01<?, ?it/s]\u001b[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 5/6 [05:19<01:02, 62.40s/it]\n",
      "\n",
      "  0%|                                                                                                                                                                     | 0/12 [00:55<?, ?it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [06:13<00:00, 62.31s/it]\n",
      "  0%|                                                                                                                                                                     | 0/12 [00:54<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assigning raster data to hexagons\n",
      "df nan values: 0\n",
      "Starting upload for res: 11\n",
      "Finished uploading data for res11\n"
     ]
    }
   ],
   "source": [
    "for city in city_list:\n",
    "    print(f\"STARTING {city}.\")\n",
    "    ############################### CREATE AREA OF INTEREST\n",
    "    ### Create city area of interest with biggest hexs\n",
    "    big_res = min(res)\n",
    "    schema_hex = 'hexgrid'\n",
    "    table_hex = f'hexgrid_{big_res}_city_2020'\n",
    "    \n",
    "    # Download hexagons with type=urban\n",
    "    type = 'urban'\n",
    "    query = f\"SELECT hex_id_{big_res},geometry FROM {schema_hex}.{table_hex} WHERE \\\"city\\\" = '{city}\\' AND \\\"type\\\" = '{type}\\'\"\n",
    "    hex_urban = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "    \n",
    "    # Download hexagons with type=rural within 500m buffer\n",
    "    poly = hex_urban.to_crs(\"EPSG:6372\").buffer(500).reset_index()\n",
    "    poly = poly.to_crs(\"EPSG:4326\")\n",
    "    poly_wkt = poly.dissolve().geometry.to_wkt()[0]\n",
    "    type = 'rural'\n",
    "    query = f\"SELECT hex_id_{big_res},geometry FROM {schema_hex}.{table_hex} WHERE \\\"city\\\" = '{city}\\' AND \\\"type\\\" = '{type}\\' AND (ST_Intersects(geometry, \\'SRID=4326;{poly_wkt}\\'))\"\n",
    "    hex_rural = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "    \n",
    "    # Concatenate urban and rural hex\n",
    "    hex_city = pd.concat([hex_urban, hex_rural])\n",
    "\n",
    "    print(f\"{city} - Created hex_city.\")\n",
    "    \n",
    "    ############################### DOWNLOAD AND INTERPOLATE RASTERS\n",
    "    try:\n",
    "        df_len = aup.download_raster_from_pc(hex_city, index_analysis, city, freq,\n",
    "                                     start_date, end_date, tmp_dir, band_name_dict, \n",
    "                                     query=query_sat, satellite = satellite,\n",
    "                                     compute_unavailable_dates=True)\n",
    "        print(f\"{city} - Created df_len.\")\n",
    "    except:\n",
    "        print(f\"{city} - Failed df_len.\")\n",
    "        failed_cities[city] = 'df_len'\n",
    "        continue\n",
    "\n",
    "    ############################### RASTERS TO HEX\n",
    "    # Do NOT process and upload if used full_month processing since it is still a WIP.\n",
    "    if 'full_month' in df_len.download_method.unique():\n",
    "        full_months = len(df_len.loc[df_len.download_method == 'full_month'].copy())\n",
    "        print(f\"---------------------------------------\")\n",
    "        print(f\"{city} - Has {full_months} months that used 'full_month' processing.\")\n",
    "        print(f\"{city} - NOT PROCESSING TO HEXS AND NOT SAVING TO DATABASE.\")\n",
    "        print(f\"---------------------------------------\")\n",
    "        continue\n",
    "    \n",
    "    ### hex preprocessing\n",
    "    print(f\"{city} - Started loading hexagons at different resolutions.\")\n",
    "    \n",
    "    # Create res_list\n",
    "    res_list=[]\n",
    "    for r in range(res[0],res[-1]+1):\n",
    "        res_list.append(r)\n",
    "    \n",
    "    # Load hexgrids\n",
    "    hex_gdf = hex_city.copy()\n",
    "    hex_gdf.rename(columns={f'hex_id_{big_res}':'hex_id'}, inplace=True)\n",
    "    hex_gdf['res'] = big_res\n",
    "    \n",
    "    print(f\"{city} Loaded hexgrid res {big_res}.\")\n",
    "    \n",
    "    for r in res_list:\n",
    "        # biggest resolution already loaded\n",
    "        if r == big_res:\n",
    "            continue\n",
    "        \n",
    "        # Load hexgrid\n",
    "        table_hex = f'hexgrid_{r}_city_2020'\n",
    "        query = f\"SELECT hex_id_{r},geometry FROM {schema_hex}.{table_hex} WHERE \\\"city\\\"=\\'{city}\\' AND  (ST_Intersects(geometry, \\'SRID=4326;{poly_wkt}\\'))\"\n",
    "        hex_tmp = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "        # Format hexgrid\n",
    "        hex_tmp.rename(columns={f'hex_id_{r}':'hex_id'}, inplace=True)\n",
    "        hex_tmp['res'] = r\n",
    "        # Concatenate to hex_gdf\n",
    "        hex_gdf = pd.concat([hex_gdf, hex_tmp])\n",
    "    \n",
    "        print(f\"{city} - Loaded hexgrid res {r}.\")\n",
    "    \n",
    "        del hex_tmp\n",
    "    \n",
    "    print(f\"{city} - Finished creating hexagons at different resolutions.\")\n",
    "    \n",
    "    # Raster to hex function for each resolution (saves output)\n",
    "    for r in list(hex_gdf.res.unique()):\n",
    "    \n",
    "        print(f\"---------------------------------------\")\n",
    "        print(f\"{city} - STARTING processing for resolution {r}.\")\n",
    "    \n",
    "        processing_chunk = 20000 # Use 20,000 max, crashed on DELL laptop with 50,000\n",
    "    \n",
    "        # filters hexagons at specified resolution\n",
    "        hex_gdf_res = hex_gdf.loc[hex_gdf.res==r].copy()\n",
    "        hex_gdf_res = hex_gdf_res.reset_index(drop=True)\n",
    "    \n",
    "        if len(hex_gdf_res)>processing_chunk:\n",
    "            print(f'hex_gdf_res len: {len(hex_gdf_res)} is bigger than processing chunk: {processing_chunk}')\n",
    "            c_processing = len(hex_gdf_res)/processing_chunk\n",
    "            print(f'There are {round(c_processing)} processes')\n",
    "            for i in range(int(c_processing)+1):\n",
    "                print(f'Processing from {i*processing_chunk} to {(i+1)*processing_chunk}')\n",
    "                hex_gdf_i = hex_gdf_res.iloc[int(processing_chunk*i):int(processing_chunk*(1+i))].copy()\n",
    "                raster_to_hex_save(hex_gdf_i, df_len, index_analysis, tmp_dir, city, r, \n",
    "                                   save = save_output_database, \n",
    "                                   local_save = save_output_locally, \n",
    "                                   i = i\n",
    "                                  )\n",
    "        else:\n",
    "            print('hex_gdf len smaller than processing chunk')\n",
    "            hex_gdf_i = hex_gdf_res.copy()\n",
    "            raster_to_hex_save(hex_gdf_i, df_len, index_analysis, tmp_dir, city, r, \n",
    "                               save = save_output_database, \n",
    "                               local_save = save_output_locally, \n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820ca42-5ae9-4e15-af33-402782c3b4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDS-10.0",
   "language": "python",
   "name": "gds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
