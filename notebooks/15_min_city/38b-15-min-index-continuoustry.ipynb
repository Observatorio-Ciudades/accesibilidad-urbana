{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60aaac8",
   "metadata": {},
   "source": [
    "# Ciudades de 15 minutos - resolución 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae7cf7-c7f7-4aac-af04-8f6b3e5e0503",
   "metadata": {},
   "source": [
    "Notebook para la prueba de la metodología de ciudades de 15 minutos. El acercamiento del Observatorio de Ciudades se basa en agrupar las amenidades en 4 ejes:\n",
    "* Educación\n",
    "* Servicios comunitarios\n",
    "* Comercio\n",
    "* Entretenimiento\n",
    "\n",
    "Cada uno de estos ejes se subdivide en amenidades específicas:\n",
    "\n",
    "* Educación\n",
    "    * Preescolar\n",
    "    * Primaria\n",
    "    * Secundaria\n",
    "* Servicios comunitarios:\n",
    "    * Centro de salud - lo traducimos como primer contacto a salud (que incluye farmacias con médicos)\n",
    "    * Gobierno - oficinas de gobierno\n",
    "    * Asistencia social - DIF\n",
    "    * Cuidados - Guarderías\n",
    "* Comercio:\n",
    "    * Alimentos - sitios para la adquisición de alimentos\n",
    "    * Comercio personal - peluquerías y venta de ropa\n",
    "    * Farmacias\n",
    "    * Hogar - Ferretería y tlapalería y artículos de limpieza\n",
    "    * Complementario - sitios de comercio complementario como venta de ropa, calzado, muebles, lavandería, pintura y revistas\n",
    "* Entretenimiento\n",
    "    * Actividad física - espacios de recreación al aire libre como parques, canchas, unidades deportivas o parques naturales\n",
    "    * Social - sitios de esparcimiento social como restaurantes, bares y cafés\n",
    "    * Cultural - espacios de recreación cultural como museos o cines\n",
    "\n",
    "Para calcular si un hexágono cumple o no con lo neceasrio para ser ciudad de 15 minutos se toma el tiempo máximo a una de las amenidades y esa se registra en el hexágono, si ese tiempo es menor a 15, se considera que cumple, de lo contrario no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41393dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/lib/python3.10/site-packages/osmnx/utils.py:192: UserWarning: The `utils.config` function is deprecated and will be removed in a future release. Instead, use the `settings` module directly to configure a global setting's value. For example, `ox.settings.log_console=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    import aup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba12f761-cb55-43fb-bffb-3e9de9d3fdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(city, save=False, save_disk_space = True):\n",
    "    \n",
    "    print('STARTING ANALYSIS FOR {}'.format(city))\n",
    "    \n",
    "    #--------------- DOWNLOAD DATA\n",
    "    #Download hexagons with pop data (Based on cvegeo)\n",
    "    hex_pop = gpd.GeoDataFrame()\n",
    "    hex_schema = 'censo'\n",
    "    hex_table = 'hex_censo_mza_2020_res9'\n",
    "    \n",
    "    query = f\"SELECT * FROM {hex_schema}.{hex_table} WHERE \\\"metropolis\\\" LIKE \\'{city}\\'\"\n",
    "    hex_pop = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "    \n",
    "    pob_tot = hex_pop.pobtot.sum()\n",
    "    print('Downloaded hex data with a total of {} persons'.format(pob_tot))\n",
    "        \n",
    "    #Download nodes (Based on city)\n",
    "    nodes_schema = 'prox_analysis'\n",
    "    nodes_table = 'nodes_proximity_2020'\n",
    "    \n",
    "    query = f\"SELECT * FROM {nodes_schema}.{nodes_table} WHERE \\\"metropolis\\\" LIKE \\'{city}\\'\"\n",
    "    nodes = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "    \n",
    "    print('Downloaded a total of {} nodes'.format(nodes.shape[0]))\n",
    "    \n",
    "    #--------------- PREPARE DATA\n",
    "    #--------------- PREPARE DATA ---------- DELETE DUPLICATES AND CLEAN NODES\n",
    "    #This step keeps osmid, geometry and metropolis (without duplicates, keeping only one point for each node) to store times to each amenity source by node in following loop.\n",
    "    nodes_geom = nodes.drop_duplicates(subset='osmid', keep=\"last\")[['osmid','geometry','metropolis']].copy()\n",
    "    \n",
    "    #--------------- PREPARE DATA ---------- REORGANIZE NODES DATA\n",
    "    #This step organizes data by nodes by changing (time to source amenities) from rows (1 column with source amenity name + 1 column with time data) \n",
    "    #to columns (1 column with time data named after its source amenity)\n",
    "    nodes_analysis = nodes_geom.copy()\n",
    "\n",
    "    for source_amenity in list(nodes.amenity.unique()):\n",
    "        nodes_tmp = nodes.loc[nodes.amenity == source_amenity,['osmid','time']]\n",
    "        nodes_tmp = nodes_tmp.rename(columns={'time':source_amenity})\n",
    "        # Search for amenities that aren't present in the city (with all values marked as 0) and change them to NaN\n",
    "        if nodes_tmp[source_amenity].mean() == 0:\n",
    "            nodes_tmp[source_amenity] = np.nan\n",
    "        nodes_analysis = nodes_analysis.merge(nodes_tmp, on='osmid')\n",
    "\n",
    "    if save_disk_space:\n",
    "        del nodes_geom\n",
    "        del nodes_tmp\n",
    "        \n",
    "    print(\"Transformed nodes data\")\n",
    "        \n",
    "    #--------------- PREPARE DATA ---------- SET PARAMETER DEFINITIONS\n",
    "    #This step sets the ejes, amenidades, sources and weights for further analysis\n",
    "    #{Eje (e):\n",
    "    #         {Amenidad (a):\n",
    "    #                       {Source (s))}}}\n",
    "\n",
    "    idx_15_min = {'Escuelas':{'Preescolar':['denue_preescolar'],\n",
    "                             'Primaria':['denue_primaria'],\n",
    "                             'Secundaria':['denue_secundaria']},\n",
    "                 'Servicios comunitarios':{'Salud':['clues_primer_nivel'],\n",
    "                                           'Guarderías':['denue_guarderias'],\n",
    "                                           'Asistencia social':['denue_dif']},\n",
    "                  'Comercio':{'Alimentos':['denue_supermercado','denue_abarrotes',\n",
    "                                           'denue_carnicerias','sip_mercado'],\n",
    "                              'Personal':['denue_peluqueria'],\n",
    "                              'Farmacias':['denue_farmacias'],\n",
    "                              'Hogar':['denue_ferreteria_tlapaleria','denue_art_limpieza'],\n",
    "                              'Complementarios':['denue_ropa','denue_calzado','denue_muebles',\n",
    "                                                 'denue_lavanderia','denue_revistas_periodicos',\n",
    "                                                 'denue_pintura']},\n",
    "                  'Entretenimiento':{'Social':['denue_restaurante_insitu','denue_restaurante_llevar',\n",
    "                                               'denue_bares','denue_cafe'],\n",
    "                                    'Actividad física':['sip_cancha','sip_unidad_deportiva',\n",
    "                                                        'sip_espacio_publico','denue_parque_natural'],\n",
    "                                    'Cultural':['denue_cines','denue_museos']} \n",
    "                 }\n",
    "\n",
    "    #If weight of amenity is less than number of sources, the algorith chooses the minimum time to source. Else (if equall or greater), chooses max time.\n",
    "    wegiht_idx = {'Escuelas':{'Preescolar':1,\n",
    "                            'Primaria':1,\n",
    "                            'Secundaria':1},\n",
    "                'Servicios comunitarios':{'Salud':1,\n",
    "                                        'Guarderías':1,\n",
    "                                        'Asistencia social':1},\n",
    "                'Comercio':{'Alimentos':1,\n",
    "                            'Personal':1,\n",
    "                            'Farmacias':1,\n",
    "                            'Hogar':1,\n",
    "                            'Complementarios':1},\n",
    "                'Entretenimiento':{'Social':4,\n",
    "                                    'Actividad física':1,\n",
    "                                    'Cultural':1}\n",
    "                }\n",
    "    \n",
    "    #--------------- PREPARE DATA ---------- FILL MISSING COLUMNS (In case there is a source amenity not available in a city)\n",
    "    sources = []\n",
    "\n",
    "    # Gather all possible sources\n",
    "    for eje in idx_15_min.keys():\n",
    "        for amenity in idx_15_min[eje].values():\n",
    "            for source in amenity:\n",
    "                sources.append(source)\n",
    "\n",
    "    # If source not in currently analized city, fill column with np.nan\n",
    "    column_list = list(nodes_analysis.columns)\n",
    "    missing_sourceamenities = []\n",
    "\n",
    "    for s in sources:\n",
    "            if s not in column_list:\n",
    "                nodes_analysis[s] = np.nan\n",
    "                missing_sourceamenities.append(a)\n",
    "\n",
    "    print(\"There are {} non present source amenities in {}\".format(len(missing_sourceamenities),city))\n",
    "    \n",
    "    #--------------- PROCESS DATA \n",
    "    #--------------- PROCESS DATA ---------- Max time calculation\n",
    "    #This step calculates times by amenity\n",
    "\n",
    "    column_max_all = [] # list with all max index column names\n",
    "    column_max_ejes = [] # list with ejes index column names\n",
    "\n",
    "    #Goes through each eje in dictionary:\n",
    "    for e in idx_15_min.keys():\n",
    "\n",
    "        #Appends to 3 lists currently examined eje\n",
    "        column_max_all.append('max_'+ e.lower())\n",
    "        column_max_ejes.append('max_'+ e.lower())\n",
    "        column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "        #Goes through each amenity of current eje:\n",
    "        for a in idx_15_min[e].keys():\n",
    "\n",
    "            #Appends to 2 lists currently examined amenity:\n",
    "            column_max_all.append('max_'+ a.lower())\n",
    "            column_max_amenities.append('max_'+ a.lower())\n",
    "\n",
    "            #Calculates time to currently examined amenity:\n",
    "            #If weight is less than number of sources of amenity, choose minimum time to sources.\n",
    "            if wegiht_idx[e][a] < len(idx_15_min[e][a]): \n",
    "                nodes_analysis['max_'+ a.lower()] = nodes_analysis[idx_15_min[e][a]].min(axis=1)\n",
    "            #Else, choose maximum time to sources.\n",
    "            else:\n",
    "                nodes_analysis['max_'+ a.lower()] = nodes_analysis[idx_15_min[e][a]].max(axis=1)\n",
    "\n",
    "        #Calculates time to currently examined eje (max time of its amenities):\n",
    "        nodes_analysis['max_'+ e.lower()] = nodes_analysis[column_max_amenities].max(axis=1) \n",
    "\n",
    "    index_column = 'max_time' # column name for maximum time data\n",
    "\n",
    "    #Add to column_max_all list the attribute 'max_time'\n",
    "    column_max_all.append(index_column)\n",
    "\n",
    "    #Assigns \"max_time\" the max time for all ejes\n",
    "    nodes_analysis[index_column] = nodes_analysis[column_max_ejes].max(axis=1)     \n",
    "    \n",
    "    #Add to column_max_all list the attributes 'osmid' and 'geometry' to filter nodes_analysis with the column_max_all list.\n",
    "    column_max_all.append('osmid')\n",
    "    column_max_all.append('geometry')\n",
    "    nodes_analysis_filter = nodes_analysis[column_max_all].copy()\n",
    "\n",
    "    if save_disk_space:\n",
    "        del nodes_analysis\n",
    "          \n",
    "    print('Calculated proximity to amenities data by node')\n",
    "        \n",
    "    #--------------- PROCESS DATA ---------- GROUP TIMES BY HEXAGONS\n",
    "    # group data by hex\n",
    "    res = 9\n",
    "    hex_tmp = hex_pop[['hex_id_9','geometry']]\n",
    "    hex_res_9_idx = aup.group_by_hex_mean(nodes_analysis_filter, hex_tmp, res, index_column)\n",
    "    hex_res_9_idx = hex_res_9_idx.loc[hex_res_9_idx[index_column]>0].copy()\n",
    "\n",
    "    if save_disk_space:\n",
    "        del hex_tmp\n",
    "        del nodes_analysis_filter\n",
    "        \n",
    "    print('Grouped nodes data by hexagons')\n",
    "          \n",
    "    #--------------- PROCESS DATA ---------- RE-CALCULATE MAX TIMES BY HEXAGON\n",
    "    # This step recalculates max time to each eje from max times to calculated amenities and max_time from max eje\n",
    "    column_max_ejes = [] # list with ejes index column names\n",
    "\n",
    "    #Goes (again) through each eje in dictionary:\n",
    "    for e in idx_15_min.keys():\n",
    "\n",
    "        column_max_ejes.append('max_'+ e.lower())\n",
    "        column_max_amenities = [] # list with amenities in current eje\n",
    "\n",
    "        #Goes (again) through each amenity of current eje:    \n",
    "        for a in idx_15_min[e].keys():\n",
    "\n",
    "            column_max_amenities.append('max_'+ a.lower())\n",
    "\n",
    "        #Re-calculates time to currently examined eje (max time of its amenities):        \n",
    "        hex_res_9_idx['max_'+ e.lower()] = hex_res_9_idx[column_max_amenities].max(axis=1)\n",
    "\n",
    "    hex_res_9_idx[index_column] = hex_res_9_idx[column_max_ejes].max(axis=1)\n",
    "\n",
    "    #Add to column_max_all list the attribute 'max_time'\n",
    "    column_max_ejes.append(index_column)\n",
    "          \n",
    "    print('Finished recalculating times in hexagons')\n",
    "    \n",
    "    #--------------- PROCESS DATA ---------- INDEX, MEDIAN AND MEAN CALCULATION\n",
    "    # This step adds data\n",
    "    \n",
    "    #Define function\n",
    "    def apply_sigmoidal(x):\n",
    "        if x == -1:\n",
    "            return -1\n",
    "        elif x > 1000:\n",
    "            return 0\n",
    "        else:\n",
    "            val = aup.sigmoidal_function(0.1464814753435666, x, 30)\n",
    "            return val\n",
    "    \n",
    "    #Apply function\n",
    "    amenities_col = ['max_preescolar','max_primaria','max_secundaria',\n",
    "               'max_salud','max_guarderías','max_asistencia social',\n",
    "               'max_alimentos','max_personal','max_farmacias','max_hogar',\n",
    "               'max_complementarios','max_social','max_actividad física',\n",
    "               'max_cultural']\n",
    "    for ac in amenities_col:\n",
    "        idx_col = ac.replace('max','idx')\n",
    "        hex_res_9_idx[idx_col] = hex_res_9_idx[ac].apply(apply_sigmoidal)\n",
    "    \n",
    "    #Add data\n",
    "    idx_colname = []\n",
    "    for ac in amenities_col:\n",
    "        idx_col = ac.replace('max','idx')\n",
    "        idx_colname.append(idx_col)\n",
    "    \n",
    "    hex_res_9_idx['mean_time'] = hex_res_9_idx[amenities_col].mean(axis=1)\n",
    "    hex_res_9_idx['median_time'] = hex_res_9_idx[amenities_col].median(axis=1)\n",
    "    hex_res_9_idx['idx_sum'] = hex_res_9_idx[idx_colname].sum(axis=1)\n",
    "          \n",
    "    print('Finished calculating index, mean and median time')\n",
    "    \n",
    "    #--------------- PROCESS DATA ---------- ADD POP AND CITY DATA\n",
    "    # calculate population density\n",
    "    hex_pop = hex_pop.to_crs(\"EPSG:6372\")\n",
    "    hex_pop['dens_pobha'] = hex_pop['pobtot'] / (hex_pop.area/10000)\n",
    "    hex_pop = hex_pop.to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Add pop data\n",
    "    pop_list = ['hex_id_9','pobtot','dens_pobha']\n",
    "    hex_res_9_idx = pd.merge(hex_res_9_idx, hex_pop[pop_list], on='hex_id_9')\n",
    "\n",
    "    if save_disk_space:\n",
    "        del hex_pop\n",
    "    \n",
    "    # Add city data\n",
    "    hex_res_9_idx['city'] = city\n",
    "          \n",
    "    print('Finished adding pop and city data')\n",
    "    \n",
    "    #--------------- FINAL FORMAT ----------\n",
    "    #--------------- FINAL FORMAT ---------- REORDER COLUMNS    \n",
    "    #Final format\n",
    "    final_column_ordered_list = ['hex_id_9', 'geometry', \n",
    "                             'max_escuelas', 'max_preescolar', 'max_primaria', 'max_secundaria',\n",
    "                             'max_servicios comunitarios', 'max_salud', 'max_guarderías', 'max_asistencia social',\n",
    "                             'max_comercio', 'max_alimentos', 'max_personal', 'max_farmacias', 'max_hogar', 'max_complementarios',\n",
    "                             'max_entretenimiento', 'max_social', 'max_actividad física', 'max_cultural', \n",
    "                             'idx_preescolar', 'idx_primaria', 'idx_secundaria',\n",
    "                             'idx_salud', 'idx_guarderías', 'idx_asistencia social',\n",
    "                             'idx_alimentos', 'idx_personal', 'idx_farmacias', 'idx_hogar', 'idx_complementarios',\n",
    "                             'idx_social', 'idx_actividad física', 'idx_cultural',\n",
    "                             'mean_time', 'median_time', 'max_time', 'idx_sum',\n",
    "                             'pobtot', 'dens_pobha','city']\n",
    "\n",
    "    hex_res_9_idx_reordered = hex_res_9_idx[final_column_ordered_list]\n",
    "\n",
    "    if save_disk_space:\n",
    "        del hex_res_9_idx\n",
    "          \n",
    "    print('Finished final format')\n",
    "        \n",
    "    #--------------- SAVE TO DB ----------\n",
    "    if save:\n",
    "        #Load previously loaded data\n",
    "        prox_schema = 'prox_analysis'\n",
    "        prox_table = 'proximityanalysis_hexres9'\n",
    "        query = f\"SELECT * FROM {prox_schema}.{prox_table}\"\n",
    "        prox_all = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "        print('Loaded already loaded data')    \n",
    "\n",
    "        #Concatenate data\n",
    "        dfs = [hex_res_9_idx_reordered,prox_all]\n",
    "        prox = pd.concat(dfs)\n",
    "        \n",
    "        if save_disk_space:\n",
    "            del hex_res_9_idx_reordered\n",
    "            del prox_all\n",
    "            \n",
    "        print('Concatented {} data to already loaded data'.format(city))\n",
    "\n",
    "        #Upload data\n",
    "        aup.gdf_to_db_slow(prox,\"proximityanalysis_hexres9\", 'prox_analysis', if_exists='replace')\n",
    "        print('Uploaded {} data to db'.format(city))\n",
    "    \n",
    "    print('FINISHED ANALYSIS FOR {}'.format(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22a10795-ddfd-49db-aa0f-43799ecbb466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 991, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1440, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 657, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ANALYSIS FOR Ensenada\n",
      "Downloaded hex data with a total of 396709.0 persons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 991, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1440, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 657, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 991, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1440, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 657, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL SYSCALL error: EOF detected\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded a total of 1065960 nodes\n",
      "Transformed nodes data\n",
      "There are 0 non present source amenities in Ensenada\n",
      "Calculated proximity to amenities data by node\n",
      "Grouped nodes data by hexagons\n",
      "Finished recalculating times in hexagons\n",
      "Finished calculating index, mean and median time\n",
      "Finished adding pop and city data\n",
      "Finished final format\n",
      "Loaded already loaded data\n",
      "Concatented Ensenada data to already loaded data\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\nserver closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n\n[SQL: \nDROP TABLE prox_analysis.proximityanalysis_hexres9]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1964\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 748\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\nserver closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m gdf_mun\u001b[38;5;241m.\u001b[39mcity\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m city \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_city_list:\n\u001b[0;32m---> 17\u001b[0m             \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_disk_space\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 298\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(city, save, save_disk_space)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcatented \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m data to already loaded data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(city))\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m#Upload data\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[43maup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgdf_to_db_slow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprox\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproximityanalysis_hexres9\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprox_analysis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUploaded \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m data to db\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(city))\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFINISHED ANALYSIS FOR \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(city))\n",
      "File \u001b[0;32m~/accesibilidad-urbana/aup/data.py:230\u001b[0m, in \u001b[0;36mgdf_to_db_slow\u001b[0;34m(gdf, name, schema, if_exists)\u001b[0m\n\u001b[1;32m    228\u001b[0m engine \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdb_engine()\n\u001b[1;32m    229\u001b[0m utils\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to database\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 230\u001b[0m \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_postgis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m utils\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in DB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    239\u001b[0m engine\u001b[38;5;241m.\u001b[39mdispose()\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/geopandas/geodataframe.py:1931\u001b[0m, in \u001b[0;36mGeoDataFrame.to_postgis\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_postgis\u001b[39m(\n\u001b[1;32m   1872\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1873\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1880\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1881\u001b[0m ):\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;124;03m    Upload GeoDataFrame into PostGIS database.\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1929\u001b[0m \n\u001b[1;32m   1930\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1931\u001b[0m     \u001b[43mgeopandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_postgis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/geopandas/io/sql.py:445\u001b[0m, in \u001b[0;36m_write_postgis\u001b[0;34m(gdf, name, con, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _get_conn(con) \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[0;32m--> 445\u001b[0m     \u001b[43mgdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_psql_insert_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/pandas/core/generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2831\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2832\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2983\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 2987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2998\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/pandas/io/sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    693\u001b[0m     )\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/pandas/io/sql.py:1728\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;124;03m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1726\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m-> 1728\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1738\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[1;32m   1739\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m   1740\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m   1748\u001b[0m )\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/pandas/io/sql.py:1631\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a SQLAlchemy type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1621\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLTable(\n\u001b[1;32m   1622\u001b[0m     name,\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1630\u001b[0m )\n\u001b[0;32m-> 1631\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/pandas/io/sql.py:831\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_create()\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/pandas/io/sql.py:1782\u001b[0m, in \u001b[0;36mSQLDatabase.drop_table\u001b[0;34m(self, table_name, schema)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_table(table_name, schema):\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mreflect(bind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable, only\u001b[38;5;241m=\u001b[39m[table_name], schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m-> 1782\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/sql/schema.py:1161\u001b[0m, in \u001b[0;36mTable.drop\u001b[0;34m(self, bind, checkfirst)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\u001b[38;5;28mself\u001b[39m, bind: _CreateDropBind, checkfirst: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Issue a ``DROP`` statement for this\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m    :class:`_schema.Table`, using the given\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    :class:`.Connection` or :class:`.Engine` for connectivity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1161\u001b[0m     \u001b[43mbind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_ddl_visitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mddl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSchemaDropper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckfirst\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2430\u001b[0m, in \u001b[0;36mConnection._run_ddl_visitor\u001b[0;34m(self, visitorcallable, element, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_ddl_visitor\u001b[39m(\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2420\u001b[0m     visitorcallable: Type[Union[SchemaGenerator, SchemaDropper]],\n\u001b[1;32m   2421\u001b[0m     element: SchemaItem,\n\u001b[1;32m   2422\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   2423\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"run a DDL visitor.\u001b[39;00m\n\u001b[1;32m   2425\u001b[0m \n\u001b[1;32m   2426\u001b[0m \u001b[38;5;124;03m    This method is only here so that the MockConnection can change the\u001b[39;00m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;124;03m    options given to the visitor so that \"checkfirst\" is skipped.\u001b[39;00m\n\u001b[1;32m   2428\u001b[0m \n\u001b[1;32m   2429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2430\u001b[0m     \u001b[43mvisitorcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/sql/visitors.py:670\u001b[0m, in \u001b[0;36mExternalTraversal.traverse_single\u001b[0;34m(self, obj, **kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m obj\u001b[38;5;241m.\u001b[39m__visit_name__, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meth:\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/sql/ddl.py:1150\u001b[0m, in \u001b[0;36mSchemaDropper.visit_table\u001b[0;34m(self, table, drop_ok, _is_metadata_operation, _ignore_sequences)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_ddl_events(\n\u001b[1;32m   1145\u001b[0m     table,\n\u001b[1;32m   1146\u001b[0m     checkfirst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckfirst,\n\u001b[1;32m   1147\u001b[0m     _is_metadata_operation\u001b[38;5;241m=\u001b[39m_is_metadata_operation,\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1150\u001b[0m     \u001b[43mDropTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# traverse client side defaults which may refer to server-side\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;66;03m# sequences. noting that some of these client side defaults may\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;66;03m# also be set up as server side defaults\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# #associating-a-sequence-as-the-server-side-\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;66;03m# default), so have to be dropped after the table is dropped.\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/sql/ddl.py:315\u001b[0m, in \u001b[0;36mExecutableDDLElement._invoke_with\u001b[0;34m(self, bind)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke_with\u001b[39m(\u001b[38;5;28mself\u001b[39m, bind):\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_execute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, bind):\n\u001b[0;32m--> 315\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1414\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/sql/ddl.py:181\u001b[0m, in \u001b[0;36mExecutableDDLElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, distilled_params, execution_options\n\u001b[1;32m    180\u001b[0m ):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_ddl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1526\u001b[0m, in \u001b[0;36mConnection._execute_ddl\u001b[0;34m(self, ddl, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1521\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m   1523\u001b[0m compiled \u001b[38;5;241m=\u001b[39m ddl\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1524\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect, schema_translate_map\u001b[38;5;241m=\u001b[39mschema_translate_map\n\u001b[1;32m   1525\u001b[0m )\n\u001b[0;32m-> 1526\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_ddl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1536\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1537\u001b[0m         ddl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         ret,\n\u001b[1;32m   1542\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1842\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1838\u001b[0m         dialect,\n\u001b[1;32m   1839\u001b[0m         context,\n\u001b[1;32m   1840\u001b[0m     )\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1983\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2326\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2325\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2328\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1962\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1964\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1971\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1975\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1976\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/python/lib/python3.10/site-packages/sqlalchemy/engine/default.py:748\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 748\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) server closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\nserver closed the connection unexpectedly\n\tThis probably means the server terminated abnormally\n\tbefore or while processing the request.\n\n[SQL: \nDROP TABLE prox_analysis.proximityanalysis_hexres9]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "#Load mun data\n",
    "mun_schema = 'metropolis'\n",
    "mun_table = 'metro_gdf'\n",
    "query = f\"SELECT * FROM {mun_schema}.{mun_table}\" \n",
    "gdf_mun = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "\n",
    "#Find already loaded cities\n",
    "prox_schema = 'prox_analysis'\n",
    "prox_table = 'proximityanalysis_hexres9'\n",
    "query = f\"SELECT * FROM {prox_schema}.{prox_table}\"\n",
    "prox_all = aup.gdf_from_query(query, geometry_col='geometry')\n",
    "processed_city_list = list(prox_all.city.unique())\n",
    "\n",
    "#Run main function\n",
    "for city in gdf_mun.city.unique():\n",
    "        if city not in processed_city_list:\n",
    "            main(city, save=True, save_disk_space = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69062d34-c982-4300-aa5b-7c15b35c5594",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c37d8-bb16-4463-9313-ddf96fde3d83",
   "metadata": {
    "tags": []
   },
   "source": [
    "#for city in gdf_mun.city.unique():\n",
    "    if city not in processed_city_list:\n",
    "        print(city)\n",
    "    else:\n",
    "        print(\"{} ya está procesada\".format(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051514aa-536a-412b-becb-024edfe99e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
